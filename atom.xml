<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>qsing`s blog</title>
  
  <subtitle>qsing`s blog</subtitle>
  <link href="https://iqsing.github.io/atom.xml" rel="self"/>
  
  <link href="https://iqsing.github.io/"/>
  <updated>2022-03-03T12:17:16.509Z</updated>
  <id>https://iqsing.github.io/</id>
  
  <author>
    <name>qsing</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>prometheus k8s服务发现</title>
    <link href="https://iqsing.github.io/2022/03/03/prometheus%20k8s%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0/"/>
    <id>https://iqsing.github.io/2022/03/03/prometheus%20k8s%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0/</id>
    <published>2022-03-03T12:16:21.000Z</published>
    <updated>2022-03-03T12:17:16.509Z</updated>
    
    <content type="html"><![CDATA[<h4 id="Prometheus的服务发现在解决什么问题？"><a href="#Prometheus的服务发现在解决什么问题？" class="headerlink" title="Prometheus的服务发现在解决什么问题？"></a>Prometheus的服务发现在解决什么问题？</h4><hr><p>被监控的目标（target）是整个监控体系中重要组成部分，传统监控系统zabbix通过 <code>网络发现</code>的机制自动创建主机到zabbix-server，进而快速的对目标进行监控。同样在Prometheus监控中存在一个叫<code>服务发现</code>的机制，在k8s容器环境中由于集群内实例网络地址是动态的，我们不可能每次创建或修改实例都将实例IP写入Prometheus的target中，借助<code>服务发现</code>我们可以快速的将集群内的资源注册到Prometheus-server中。</p><h4 id="Prometheus-中的-scrape-config-是什么？"><a href="#Prometheus-中的-scrape-config-是什么？" class="headerlink" title="Prometheus 中的 scrape_config 是什么？"></a>Prometheus 中的 scrape_config 是什么？</h4><hr><p>Prometheus通过yml文件来存储配置文件，通过scrape_config（抓取配置）域来配置抓取目标和抓取服务发现方式。</p><p><code>scrape_config</code>指定了一组target和抓取参数。在一般情况下，一个scrape_config指定一个作业。</p><p>如下指定了两个静态服务发现prometheus、kube-state-metrics，</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">scrape_configs:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">prometheus</span></span><br><span class="line">  <span class="attr">static_configs:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">targets:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">localhost:9090</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">kube-state-metrics</span></span><br><span class="line">  <span class="attr">static_configs:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">targets:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">prometheus-kube-state-metrics.monitoring.svc:8080</span></span><br></pre></td></tr></table></figure><p>Prometheus支持的服务发现非常多：</p><ul><li>static_configs: 静态服务发现</li><li>dns_sd_configs: DNS 服务发现</li><li>file_sd_configs: 文件服务发现</li><li>kubernetes_sd_configs: Kubernetes 服务发现</li><li>gce_sd_configs: GCE 服务发现</li><li>ec2_sd_configs: EC2 服务发现</li><li>openstack_sd_configs: OpenStack 服务发现</li><li>azure_sd_configs: Azure 服务发现</li></ul><p>前面4个是比较常用的，这里我们主要介绍kubernetes_sd_configs，其他的比较简单可查看Prometheus官方文档<a href="https://prometheus.io/docs/prometheus/latest/configuration/configuration/"> prometheus configuration</a></p><h4 id="什么是-Kubernetes-sd-configs？"><a href="#什么是-Kubernetes-sd-configs？" class="headerlink" title="什么是 Kubernetes_sd_configs？"></a>什么是 Kubernetes_sd_configs？</h4><hr><p>Prometheus中k8s服务发现的原理是通过 Kubernetes 的REST API 检索抓取目标，并始终与集群状态保持同步。所以我们需要配置Kubernetes_sd_configs来访问K8s API</p><p>比如我们要抓取k8s ingress，应为Prometheus指定用于RBAC认证证书和serviceaccount的token</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">&#x27;kubernetes-ingress&#x27;</span></span><br><span class="line">  <span class="attr">scheme:</span> <span class="string">https</span></span><br><span class="line">  <span class="attr">tls_config:</span></span><br><span class="line">    <span class="attr">ca_file:</span> <span class="string">/var/run/secrets/kubernetes.io/serviceaccount/ca.crt</span></span><br><span class="line">    <span class="attr">insecure_skip_verify:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">bearer_token_file:</span> <span class="string">/var/run/secrets/kubernetes.io/serviceaccount/token</span></span><br><span class="line">  <span class="attr">kubernetes_sd_configs:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">role:</span> <span class="string">ingress</span></span><br></pre></td></tr></table></figure><p>这里的role为k8s中资源实体如 endpoints、service,、pod,、node或 ingress</p><p>当指定ingress时，Prometheus将每个入口地址发现为一个目标。</p><p>重载配置文件后可以在Prometheus Service Discovery查看发现的target</p><p><img src="https://markdown-1257692304.cos.ap-nanjing.myqcloud.com/markdown_img/image-20220303195620411.png" alt="image-20220303195620411"></p><p>发现apiserver配置</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">kubernetes-apiservers</span></span><br><span class="line">  <span class="attr">scheme:</span> <span class="string">https</span></span><br><span class="line">  <span class="attr">tls_config:</span></span><br><span class="line">    <span class="attr">ca_file:</span> <span class="string">/var/run/secrets/kubernetes.io/serviceaccount/ca.crt</span> </span><br><span class="line">    <span class="attr">insecure_skip_verify:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">bearer_token_file:</span> <span class="string">/var/run/secrets/kubernetes.io/serviceaccount/token</span> </span><br><span class="line">  <span class="attr">kubernetes_sd_configs:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">role:</span> <span class="string">endpoints</span></span><br><span class="line">  <span class="attr">relabel_configs:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">action:</span> <span class="string">keep</span></span><br><span class="line">    <span class="attr">regex:</span> <span class="string">default;kubernetes;https</span></span><br><span class="line">    <span class="attr">source_labels:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">__meta_kubernetes_namespace</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">__meta_kubernetes_service_name</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">__meta_kubernetes_endpoint_port_name</span></span><br></pre></td></tr></table></figure><p>这里我们用到了<code>relabel_configs</code>即重新打标，动作为<code>keep</code> 啥意思呢？ 首先我们通过k8s API获取到所有endpoints，将endpoints中的含元数据 namespace、service_name、endpoint_port_name的实例和regex匹配，如果匹配成功就保留。这用来过滤一下不需要的实例时很有用。</p><p>通过kubectl 查看的kubernetes这个endpoints的信息</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> kubectl describe endpoints kubernetes</span></span><br><span class="line">Name:         kubernetes</span><br><span class="line">Namespace:    default</span><br><span class="line">Labels:       &lt;none&gt;</span><br><span class="line">Annotations:  &lt;none&gt;</span><br><span class="line">Subsets:</span><br><span class="line">  Addresses:          192.168.1.82,192.168.1.83,192.168.1.84</span><br><span class="line">  NotReadyAddresses:  &lt;none&gt;</span><br><span class="line">  Ports:</span><br><span class="line">    Name   Port  Protocol</span><br><span class="line">    ----   ----  --------</span><br><span class="line">    https  6443  TCP</span><br></pre></td></tr></table></figure><p>发出来的target如下</p><p><img src="https://markdown-1257692304.cos.ap-nanjing.myqcloud.com/markdown_img/image-20220303190902069.png" alt="image-20220303190902069"></p><p>这里有一个隐藏点，Prometheus会把元数据中的<code>__address__</code> 和<code>__metrics_path__</code>作为endpoint，下面我们来看一个替换元数据的node实例</p><p>发现node配置</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">kubernetes-nodes</span></span><br><span class="line">  <span class="attr">scheme:</span> <span class="string">https</span></span><br><span class="line">  <span class="attr">tls_config:</span></span><br><span class="line">    <span class="attr">ca_file:</span> <span class="string">/var/run/secrets/kubernetes.io/serviceaccount/ca.crt</span></span><br><span class="line">    <span class="attr">insecure_skip_verify:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">bearer_token_file:</span> <span class="string">/var/run/secrets/kubernetes.io/serviceaccount/token</span></span><br><span class="line">  <span class="attr">kubernetes_sd_configs:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">role:</span> <span class="string">node</span></span><br><span class="line">  <span class="attr">relabel_configs:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">action:</span> <span class="string">labelmap</span></span><br><span class="line">    <span class="attr">regex:</span> <span class="string">__meta_kubernetes_node_label_(.+)</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">replacement:</span> <span class="string">kubernetes.default.svc:443</span></span><br><span class="line">    <span class="attr">target_label:</span> <span class="string">__address__</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">regex:</span> <span class="string">(.+)</span></span><br><span class="line">    <span class="attr">replacement:</span> <span class="string">/api/v1/nodes/$1/proxy/metrics</span></span><br><span class="line">    <span class="attr">source_labels:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">__meta_kubernetes_node_name</span></span><br><span class="line">    <span class="attr">target_label:</span> <span class="string">__metrics_path__</span></span><br></pre></td></tr></table></figure><p>这里的动作为<code>labelmap</code>,可用于标签替换。首先获取所有node，对元数据<code>__address__</code>中的value替换为replacement的值<code>kubernetes.default.svc:443</code></p><p>在replacement的值中可以通过$1,$2,$3…的方式引用source_labels的key-value，所以元数据<code>__metrics_path__</code>的值将会被/api/v1/nodes/{node_name}/proxy/metrics替换。</p><p>发现出的node如下所示，此时target的address和metrics_path已被替换了。</p><p><img src="https://markdown-1257692304.cos.ap-nanjing.myqcloud.com/markdown_img/image-20220303195053113.png" alt="image-20220303195053113"></p><p>以上通过kubernetes-apiservers、kubernetes-nodes的实例简单介绍了Prometheus中如何实现k8s集群资源的服务发现以及相应的配置和操作。亦可参考Prometheus示例配置<a href="https://github.com/prometheus/prometheus/blob/release-2.33/documentation/examples/prometheus-kubernetes.yml">prometheus-kubernetes</a></p><p><strong>希望小作文对你有些许帮助，如果内容有误请指正。</strong>通过博客阅读：<a href="https://iqsing.github.io/">iqsing.github.io</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h4 id=&quot;Prometheus的服务发现在解决什么问题？&quot;&gt;&lt;a href=&quot;#Prometheus的服务发现在解决什么问题？&quot; class=&quot;headerlink&quot; title=&quot;Prometheus的服务发现在解决什么问题？&quot;&gt;&lt;/a&gt;Prometheus的服务发现在解</summary>
      
    
    
    
    <category term="k8s" scheme="https://iqsing.github.io/categories/k8s/"/>
    
    <category term="prometheus" scheme="https://iqsing.github.io/categories/k8s/prometheus/"/>
    
    
    <category term="service-discovery" scheme="https://iqsing.github.io/tags/service-discovery/"/>
    
  </entry>
  
  <entry>
    <title>k8s 通过helm发布应用</title>
    <link href="https://iqsing.github.io/2022/02/14/k8s%20%E9%80%9A%E8%BF%87%E5%8C%85%E7%AE%A1%E7%90%86%E5%99%A8helm%E5%8F%91%E5%B8%83%E5%BA%94%E7%94%A8/"/>
    <id>https://iqsing.github.io/2022/02/14/k8s%20%E9%80%9A%E8%BF%87%E5%8C%85%E7%AE%A1%E7%90%86%E5%99%A8helm%E5%8F%91%E5%B8%83%E5%BA%94%E7%94%A8/</id>
    <published>2022-02-13T16:47:21.000Z</published>
    <updated>2022-02-13T18:45:16.267Z</updated>
    
    <content type="html"><![CDATA[<h4 id="什么是helm？"><a href="#什么是helm？" class="headerlink" title="什么是helm？"></a>什么是helm？</h4><hr><blockquote><p>Helm 是 Kubernetes 的包管理器。Helm 是查找、分享和使用软件构建 Kubernetes 的最优方式。</p></blockquote><p>在红帽系的Linux中我们使用yum来管理RPM包，类似的，在K8s中我们可以使用helm来管理资源对象（Deployment、Service、Ingress…）实现K8s中应用的快速发布、升级、维护和分享。<a href="https://helm.sh/zh/docs/">helm官方文档</a></p><h4 id="helm中的几个关键概念"><a href="#helm中的几个关键概念" class="headerlink" title="helm中的几个关键概念"></a>helm中的几个关键概念</h4><hr><ul><li><strong>Chart</strong>  是Helm 中的包。包含一组用于部署应用程序的 K8s 资源对象定义（即资源清单的集合）。</li><li><strong>Repository</strong> 即chart图表的仓库。我们可以从网络仓库中搜索、下载和安装chart。</li><li><strong>Release</strong> 即chart部署后的实例。通过<code>helm install</code>命令，在 Kubernetes 集群上安装该chart的新版本。</li></ul><h4 id="helm实现哪些功能？"><a href="#helm实现哪些功能？" class="headerlink" title="helm实现哪些功能？"></a>helm实现哪些功能？</h4><hr><p>Helm (v3版本)为 K8s 提供的功能包括：</p><ol><li>通过单个 CLI 命令部署 Kubernetes 应用（chart）。实现本地chart的创建、管理和发布。</li><li>Helm 将chart中资源对象配置文件模板化，实现在多个集群环境中重用一个 Helm chart，同时可打包进行网络共享。</li><li>Helm 通过自动维护发布的所有版本来简化 Kubernetes 应用程序的回滚，防止部署问题。</li><li>通过helm轻松实现 Kubernetes 中工作负载的 CI/CD 管道。</li></ol><h4 id="helm-基本使用"><a href="#helm-基本使用" class="headerlink" title="helm 基本使用"></a>helm 基本使用</h4><hr><p>Helm可以用源码或构建的二进制版本安装。参考：<a href="https://helm.sh/zh/docs/intro/install/">安装Helm</a></p><p><a href="https://artifacthub.io/">Artifact Hub</a> 是一个开源项目,我们通过它来查找、安装或发布k8s应用。<img src="https://markdown-1257692304.cos.ap-nanjing.myqcloud.com/markdown_img/image-20220213193213721.png" alt="image-20220213193213721"></p><p>除了通过web搜索，也可以通过helm命令行方式：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">helm search hub redis</span></span><br><span class="line">URL                                               CHART VERSIONAPP VERSION     DESCRIPTION</span><br><span class="line">https://hub.helm.sh/charts/bitnami/redis          16.4.0       6.2.6           Redis(TM) is an opensource, advanced key-value...</span><br><span class="line">https://hub.helm.sh/charts/wenerme/redis          16.4.0       6.2.6           Redis(TM) is an opensource, advanced key-value...</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>找到redis版本为6.2.6，chart版本16.4.0的包，访问 url <code>https://hub.helm.sh/charts/bitnami/redis</code> 新版本已被重定向到<code>artifacthub.io</code></p><p><img src="https://markdown-1257692304.cos.ap-nanjing.myqcloud.com/markdown_img/image-20220213195117548.png" alt="image-20220213195117548"></p><p>由图上信息可以知redis是一个来自Bitnami仓库（由VMware主导的开源软件仓库），通过验证的版本，仓库地址<code>https://charts.bitnami.com/bitnami</code></p><p>要安装这个应用我们应先将Bitnami仓库添加到本地配置中。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">helm repo add bitnami https://charts.bitnami.com/bitnami</span></span><br></pre></td></tr></table></figure><p>安装redis，release名称为<code>redis-dev</code></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> helm install redis-dev bitnami/redis</span></span><br><span class="line">NAME: redis-dev</span><br><span class="line">LAST DEPLOYED: Sun Feb 13 20:09:30 2022</span><br><span class="line">NAMESPACE: default</span><br><span class="line">STATUS: deployed</span><br><span class="line">REVISION: 1</span><br><span class="line">TEST SUITE: None</span><br><span class="line">NOTES:</span><br><span class="line">CHART NAME: redis</span><br><span class="line">CHART VERSION: 16.4.0</span><br><span class="line">APP VERSION: 6.2.6</span><br></pre></td></tr></table></figure><p>这样我们可以轻松发布一个一主三从的redis集群到k8s中</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> helm list</span></span><br><span class="line">NAME                           NAMESPACEREVISIONUPDATED                                STATUS  CHART APP VERSION</span><br><span class="line">redis-dev                      default  1       2022-02-13 20:09:30.755534484 +0800 CSTdeployedredis-16.4.0</span><br></pre></td></tr></table></figure><p>Helm 通过向资源对象中添加标签来跟踪安装在 Kubernetes 集群上的chart。这些标签看起来像<code>app.kubernetes.io/managed-by=Helm</code>和<code>app.kubernetes.io/instance: myapp</code>。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">  kubectl get all -l app.kubernetes.io/instance=redis-dev</span></span><br><span class="line">NAME                       READY   STATUS    RESTARTS   AGE</span><br><span class="line">pod/redis-dev-master-0     1/1     Running   0          27m</span><br><span class="line">pod/redis-dev-replicas-0   1/1     Running   0          27m</span><br><span class="line">pod/redis-dev-replicas-1   1/1     Running   0          24m</span><br><span class="line">pod/redis-dev-replicas-2   1/1     Running   0          23m</span><br><span class="line"></span><br><span class="line">NAME                         TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)    AGE</span><br><span class="line">service/redis-dev-headless   ClusterIP   None            &lt;none&gt;        6379/TCP   27m</span><br><span class="line">service/redis-dev-master     ClusterIP   10.96.52.104    &lt;none&gt;        6379/TCP   27m</span><br><span class="line">service/redis-dev-replicas   ClusterIP   10.96.230.162   &lt;none&gt;        6379/TCP   27m</span><br><span class="line"></span><br><span class="line">NAME                                  READY   AGE</span><br><span class="line">statefulset.apps/redis-dev-master     1/1     27m</span><br><span class="line">statefulset.apps/redis-dev-replicas   3/3     27m</span><br></pre></td></tr></table></figure><p>删除<code>redis-dev</code>的发布，将会移除标签跟踪的所有资源对象。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> helm uninstall redis-dev</span></span><br><span class="line">release &quot;redis-dev&quot; uninstalled</span><br></pre></td></tr></table></figure><h4 id="创建自己的helm-chart"><a href="#创建自己的helm-chart" class="headerlink" title="创建自己的helm chart"></a>创建自己的helm chart</h4><hr><p>显然大多数时候我们更想发布自己的应用到K8s中或者需要对将要发布的开源软件做一些配置上的修改，所以我们可以通过helm自己构建一个chart或者使用<code>helm pull</code>下载一个chart做修改后再上传的内部或外部仓库中。</p><p>下面来创建一个简易的nginx chart</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> helm create chart-nginx</span></span><br><span class="line">Creating chart-nginx</span><br></pre></td></tr></table></figure><p>chart的目录结构，你可以删除模板中的所有文件自建或使用默认模板</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> tree chart-nginx/</span></span><br><span class="line">chart-nginx/</span><br><span class="line">├── charts  #依赖的chart目录</span><br><span class="line">├── Chart.yaml #chart版本信息</span><br><span class="line">├── templates #资源对象模板目录</span><br><span class="line">│   ├── deployment.yaml</span><br><span class="line">│   ├── _helpers.tpl</span><br><span class="line">│   ├── hpa.yaml</span><br><span class="line">│   ├── ingress.yaml</span><br><span class="line">│   ├── NOTES.txt #提示信息</span><br><span class="line">│   ├── serviceaccount.yaml</span><br><span class="line">│   ├── service.yaml</span><br><span class="line">│   └── tests</span><br><span class="line">│       └── test-connection.yaml</span><br><span class="line">└── values.yaml #模板值</span><br><span class="line"></span><br><span class="line">3 directories, 10 files</span><br></pre></td></tr></table></figure><p>Chart.yaml声明了版本信息，我们可以进行自定义</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Chart.yaml</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v2</span></span><br><span class="line"><span class="attr">name:</span> <span class="string">chart-nginx</span></span><br><span class="line"><span class="attr">description:</span> <span class="string">A</span> <span class="string">Helm</span> <span class="string">chart</span> <span class="string">for</span> <span class="string">Kubernetes</span></span><br><span class="line"><span class="attr">type:</span> <span class="string">application</span></span><br><span class="line"><span class="attr">version:</span> <span class="number">0.1</span><span class="number">.0</span> <span class="comment">#chart版本</span></span><br><span class="line"><span class="attr">appVersion:</span> <span class="number">1.0</span><span class="number">.0</span> <span class="comment">#app版本</span></span><br></pre></td></tr></table></figure><p>helm默认创建的模板文件deployment.yaml如下：</p><p><img src="https://markdown-1257692304.cos.ap-nanjing.myqcloud.com/markdown_img/image-20220213233227742.png" alt="image-20220213233227742"></p><p>helm 采用go模板，官方文档<a href="https://helm.sh/zh/docs/chart_template_guide/">Chart模板</a></p><p>通过deployment模板中可以看到<code>image</code>的值会引用value文件中定义的image.repository和tag，如果tag值为空则返回默认引用Chart.appVersion的值。</p><p>接着根据需要更新value.yaml文件中<code>image</code>和<code>service</code>等相关信息，同时关闭serviceAccount、ingress、hpa的创建。</p><p><img src="https://markdown-1257692304.cos.ap-nanjing.myqcloud.com/markdown_img/image-20220214001633434.png" alt="image-20220214001633434"></p><p>模板文件service.yaml定义好了type和pod的引用。</p><p><img src="https://markdown-1257692304.cos.ap-nanjing.myqcloud.com/markdown_img/image-20220214001344997.png" alt="image-20220214001344997"></p><p>一个基本的nginx的chart创建好了。通过<code>helm template</code> 命令渲染模板查看一下</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># helm template chart-nginx</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="comment"># Source: chart-nginx/templates/service.yaml</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">RELEASE-NAME-chart-nginx</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">helm.sh/chart:</span> <span class="string">chart-nginx-0.1.0</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/name:</span> <span class="string">chart-nginx</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/instance:</span> <span class="string">RELEASE-NAME</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/version:</span> <span class="string">&quot;1.0.0&quot;</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/managed-by:</span> <span class="string">Helm</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">NodePort</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">port:</span> <span class="number">80</span></span><br><span class="line">      <span class="attr">targetPort:</span> <span class="string">http</span></span><br><span class="line">      <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line">      <span class="attr">name:</span> <span class="string">http</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/name:</span> <span class="string">chart-nginx</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/instance:</span> <span class="string">RELEASE-NAME</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="comment"># Source: chart-nginx/templates/deployment.yaml</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">RELEASE-NAME-chart-nginx</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">helm.sh/chart:</span> <span class="string">chart-nginx-0.1.0</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/name:</span> <span class="string">chart-nginx</span></span><br><span class="line"><span class="string">...</span></span><br></pre></td></tr></table></figure><p>再通过<code>helm lint</code>检查语法</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">==&gt; Linting chart-nginx</span><br><span class="line">[INFO] Chart.yaml: icon is recommended</span><br><span class="line"></span><br><span class="line">1 chart(s) linted, 0 chart(s) failed</span><br></pre></td></tr></table></figure><p>ok，通过<code>helm install</code>发布到k8s，参照<strong>NOTES说明</strong>可进行访问。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> helm install chart-nginx --generate-name</span></span><br><span class="line">NAME: chart-nginx-1644771770</span><br><span class="line">LAST DEPLOYED: Mon Feb 14 01:02:50 2022</span><br><span class="line">NAMESPACE: default</span><br><span class="line">STATUS: deployed</span><br><span class="line">REVISION: 1</span><br><span class="line">NOTES:</span><br><span class="line">1. Get the application URL by running these commands:</span><br><span class="line">  export NODE_PORT=$(kubectl get --namespace default -o jsonpath=&quot;&#123;.spec.ports[0].nodePort&#125;&quot; services chart-nginx-1644771770)</span><br><span class="line">  export NODE_IP=$(kubectl get nodes --namespace default -o jsonpath=&quot;&#123;.items[0].status.addresses[0].address&#125;&quot;)</span><br><span class="line">  echo http://$NODE_IP:$NODE_PORT</span><br></pre></td></tr></table></figure><p>查看资源正常。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> kubectl get all -l app.kubernetes.io/name=chart-nginx</span></span><br><span class="line">NAME                                          READY   STATUS    RESTARTS   AGE</span><br><span class="line">pod/chart-nginx-1644771770-69bbb4fdf8-gqdk7   1/1     Running   0          3m59s</span><br><span class="line">pod/chart-nginx-1644771770-69bbb4fdf8-wwxw2   1/1     Running   0          3m59s</span><br><span class="line"></span><br><span class="line">NAME                             TYPE       CLUSTER-IP     EXTERNAL-IP   PORT(S)        AGE</span><br><span class="line">service/chart-nginx-1644771770   NodePort   10.96.231.61   &lt;none&gt;        80:32631/TCP   3m59s</span><br><span class="line"></span><br><span class="line">NAME                                     READY   UP-TO-DATE   AVAILABLE   AGE</span><br><span class="line">deployment.apps/chart-nginx-1644771770   2/2     2            2           3m59s</span><br><span class="line"></span><br><span class="line">NAME                                                DESIRED   CURRENT   READY   AGE</span><br><span class="line">replicaset.apps/chart-nginx-1644771770-69bbb4fdf8   2         2         2       3m59s</span><br></pre></td></tr></table></figure><h4 id="通过仓库分发应用"><a href="#通过仓库分发应用" class="headerlink" title="通过仓库分发应用"></a>通过仓库分发应用</h4><hr><p>首先通过<code>helm packge</code>将chart-nginx打包</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> helm package chart-nginx</span></span><br><span class="line">Successfully packaged chart and saved it to: .../../chart-nginx-0.1.0.tgz</span><br></pre></td></tr></table></figure><p>建立chart私有仓库，可参考开源项目<a href="https://github.com/helm/chartmuseum">chartmuseum</a>，如有必要你也可将仓库提交至<code>artifacthub</code>发布到互联网。</p><p>将<code>chart-nginx-0.1.0.tgz</code>上传至仓库后，通过curl列出chart信息如下：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"># curl http:<span class="comment">//192.168.1.123:8088/api/charts |python -m json.tool</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="attr">&quot;chart-nginx&quot;</span>: [</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="attr">&quot;apiVersion&quot;</span>: <span class="string">&quot;v2&quot;</span>,</span><br><span class="line">            <span class="attr">&quot;appVersion&quot;</span>: <span class="string">&quot;1.0.0&quot;</span>,</span><br><span class="line">            <span class="attr">&quot;created&quot;</span>: <span class="string">&quot;2022-02-13T17:37:43.653117345Z&quot;</span>,</span><br><span class="line">            <span class="attr">&quot;description&quot;</span>: <span class="string">&quot;A Helm chart for Kubernetes&quot;</span>,</span><br><span class="line">            <span class="attr">&quot;digest&quot;</span>: <span class="string">&quot;58a687be62a2a2a2b1dd177675bbc5aa49ac754df2219149bb4798636662b57c&quot;</span>,</span><br><span class="line">            <span class="attr">&quot;name&quot;</span>: <span class="string">&quot;chart-nginx&quot;</span>,</span><br><span class="line">            <span class="attr">&quot;type&quot;</span>: <span class="string">&quot;application&quot;</span>,</span><br><span class="line">            <span class="attr">&quot;urls&quot;</span>: [</span><br><span class="line">                <span class="string">&quot;charts/chart-nginx-0.1.0.tgz&quot;</span></span><br><span class="line">            ],</span><br><span class="line">            <span class="attr">&quot;version&quot;</span>: <span class="string">&quot;0.1.0&quot;</span></span><br><span class="line">        &#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>将仓库添加到你的其他k8s集群helm中，实现应用共享和发布。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> helm repo add chartmuseum http://192.168.1.123:8088</span></span><br><span class="line">&quot;chartmuseum&quot; has been added to your repositories</span><br></pre></td></tr></table></figure><p>搜索<code>chart-nginx</code></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> helm search repo chart-nginx</span></span><br><span class="line">NAME                   CHART VERSIONAPP VERSIONDESCRIPTION</span><br><span class="line">chartmuseum/chart-nginx0.1.0        1.0.0      A Helm chart for Kubernetes</span><br></pre></td></tr></table></figure><p>通过仓库安装<code>chart-nginx</code></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> helm install my-chart-nginx chartmuseum/chart-nginx</span></span><br><span class="line">NAME: my-chart-nginx</span><br><span class="line">LAST DEPLOYED: Mon Feb 14 01:54:34 2022</span><br><span class="line">NAMESPACE: default</span><br><span class="line">STATUS: deployed</span><br><span class="line">REVISION: 1</span><br><span class="line">...</span><br></pre></td></tr></table></figure><hr><p>以上我们对helm进行了基本介绍以及如何创建一个自己的<code>helm chart</code>,如何结合私有仓库<code>chartmuseum</code>在K8s中发布应用。</p><p><strong>希望小作文对你有些许帮助，如果内容有误请指正。</strong>通过博客阅读：<a href="https://iqsing.github.io/">iqsing.github.io</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h4 id=&quot;什么是helm？&quot;&gt;&lt;a href=&quot;#什么是helm？&quot; class=&quot;headerlink&quot; title=&quot;什么是helm？&quot;&gt;&lt;/a&gt;什么是helm？&lt;/h4&gt;&lt;hr&gt;
&lt;blockquote&gt;
&lt;p&gt;Helm 是 Kubernetes 的包管理器。Helm</summary>
      
    
    
    
    <category term="k8s" scheme="https://iqsing.github.io/categories/k8s/"/>
    
    
    <category term="helm" scheme="https://iqsing.github.io/tags/helm/"/>
    
  </entry>
  
  <entry>
    <title>理解https中的安全及其实现原理</title>
    <link href="https://iqsing.github.io/2022/02/07/%E7%90%86%E8%A7%A3https%E4%B8%AD%E7%9A%84%E5%AE%89%E5%85%A8%E5%8F%8A%E5%85%B6%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/"/>
    <id>https://iqsing.github.io/2022/02/07/%E7%90%86%E8%A7%A3https%E4%B8%AD%E7%9A%84%E5%AE%89%E5%85%A8%E5%8F%8A%E5%85%B6%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/</id>
    <published>2022-02-06T16:47:21.000Z</published>
    <updated>2022-02-13T18:56:21.177Z</updated>
    
    <content type="html"><![CDATA[<p>Google的一份<a href="https://transparencyreport.google.com/https/overview">网络上的 HTTPS 加密</a>透明报告（数据截至2022年1月）中指出HTTPS 连接的普及率在过去几年激增，互联网上排名前 100 位的非 Google 网站HTTPS 使用情况为：97%的站点默认启用HTTPS，100%的站点支持HTTPS。</p><p> Chrome 中的 HTTPS 浏览时间所占的百分比（按平台）</p><p><img src="https://markdown-1257692304.cos.ap-nanjing.myqcloud.com/markdown_img/image-20220205144030761.png" alt="image-20220205144030761"></p><p> Chrome 中通过 HTTPS 加载的网页所占的百分比（按国家/地区）</p><p><img src="https://markdown-1257692304.cos.ap-nanjing.myqcloud.com/markdown_img/image-20220205144136067.png" alt="image-20220205144136067"></p><hr><p>如此流行的HTTPS我们应当对其有所了解，通过阅读本文你可能能更进一步了解HTTPS相关的安全实现。</p><p>HTTPS(超文本传输安全协议)使用HTTP进行通信，但利用SSL/TLS来加密数据包，所以它也有另外一种称呼HTTP over TLS/SSL，说HTTPS安全其实说的就是TLS/SSL协议。HTTP以明文的方式在网络中交换数据，攻击者可以轻易通过监听或中间人攻击等手段，获取网站帐户和敏感信息等，而HTTPS可以做到如下几个特性：</p><ul><li><strong>保密性。</strong> 客户端的连接被加密，隐藏了 URL、cookie 和其他敏感元数据。</li><li>**真实性。 ** 确保客户端正在与“真实”的服务端通信，而非中间人。</li><li><strong>准确性。</strong>  客户端与服务端之间发送的数据没有被篡改。</li></ul><h4 id="保密性–对称加密、非对称加密"><a href="#保密性–对称加密、非对称加密" class="headerlink" title="保密性–对称加密、非对称加密"></a>保密性–对称加密、非对称加密</h4><hr><p>我们说http是明文传输，所以https首要解决的问题就是它的通信加密，达到保密性。</p><h5 id="对称加密"><a href="#对称加密" class="headerlink" title="对称加密"></a>对称加密</h5><p>对称加密是最简单、最常见的加密方式。</p><p><img src="https://markdown-1257692304.cos.ap-nanjing.myqcloud.com/markdown_img/image-20220205222244676.png" alt="image-20220205222244676"></p><p>通信双方持有相同的密钥key，加密和解密都是使用同一个密钥。当客户端要发送数据时先用key对数据进行加密生成secret data，接着传输到服务端。服务端接收数据时，通过key将数据解密为data。反之客户端接收数据也是如此。</p><p>这样即使数据被截获，由于不知道key数据也无法被解密。常见的对称加密算法有 DES、 AES 等。对称加密速度快、效率高，能够使用较小的计算量完成加密。</p><p><strong>对称加密有一个核心问题是如何在互联网上传输密钥？</strong>它不能像现实中一样我打个车就过去你家把密钥塞给你，万一密钥被截胡了不就白搭了。所以需要非对称加密来解决这个问题。</p><h5 id="非对称加密"><a href="#非对称加密" class="headerlink" title="非对称加密"></a>非对称加密</h5><p>非对称加密就是加密和解密使用两个不同的密钥，密钥对包含一个公钥（public key）和一个私钥（private key）。其中公钥只能用于加密，私钥只用于解密。</p><p><img src="https://markdown-1257692304.cos.ap-nanjing.myqcloud.com/markdown_img/image-20220205214218879.png" alt="image-20220205214218879"></p><p>首先客户端请求服务端，服务端将自己的公钥返回，客户端拿到公钥后就可以用它来加密要传输的数据data ，将加密数据secret data发送到服务端后通过服务端的私钥来解密，以此完成加密传输。</p><p>有了非对称加密，只要我们将其中的data换成随机码key，这个key作为对称加密中密钥。密钥传输问题就解决了，同时很好地利用了对称加密的高效率。</p><p>如下所示：</p><p><img src="https://markdown-1257692304.cos.ap-nanjing.myqcloud.com/markdown_img/image-20220205222743133.png" alt="image-20220205222743133"></p><p>这样HTTPS中通信的数据加密已经完成了。</p><p><strong>一个http请求：</strong></p><p><img src="https://markdown-1257692304.cos.ap-nanjing.myqcloud.com/markdown_img/with-http-headers.png" alt="with-http-headers"></p><p><strong>一个加密的https请求：</strong></p><p><img src="https://markdown-1257692304.cos.ap-nanjing.myqcloud.com/markdown_img/with-https-headers-secret.png" alt="with-https-headers-secret"></p><p>只要我们的私钥不被破解，即使通信被监听也得不到其中的敏感加密数据。</p><h4 id="真实性、准确性–数字证书、签名"><a href="#真实性、准确性–数字证书、签名" class="headerlink" title="真实性、准确性–数字证书、签名"></a>真实性、准确性–数字证书、签名</h4><hr><p>上面我们忽略了一个重要的问题，<strong>在通信中如何保证所连接的服务端真实性呢？</strong>如下图我们的通信已经被中间人截胡了，client此时通信对象为hacker。</p><p><img src="https://markdown-1257692304.cos.ap-nanjing.myqcloud.com/markdown_img/image-20220206092643558.png" alt="image-20220206092643558"></p><p>在HTTPS中是如何防止这种中间人攻击的呢？让我们请出数字证书！</p><h5 id="数字证书"><a href="#数字证书" class="headerlink" title="数字证书"></a>数字证书</h5><p>所谓证书就是第三方（自签证书没有公证效应）颁发的认证，比如我们的学位证是由教育局颁发的一种学历认证，由教育局来认证此人获得了某个学位。同样在HTTPS中存在一种认证机构即CA（Certification Authority），由它来证明你所连接的服务端就是你想要连接的server，即保证服务端真实性。</p><p>要获取学位证你需要花钱上学、学习，而获取数字证书你只需要花钱。</p><ol><li>首先站点的所有者生成一个密钥对，然后掏钱将站点的信息如域名、组织信息等以及公钥提交给CA机构审核，即**证书签名请求 (CSR)**。</li><li>CA机构审核通过后，用它独有的私钥对CSR信息（其实是CSR信息的hash值，用于加速加、解密）进行加密，即形成<strong>数字签名</strong>，用于验证证书是否被篡改，经过签名后一个完整的数字证书就成了其中包含站点信息、数字签名。</li></ol><p>如下图所示（图源:<a href="https://www.ssl.com/faqs/what-is-a-certificate-authority/">what-is-a-certificate-authority</a>）：</p><p><img src="https://markdown-1257692304.cos.ap-nanjing.myqcloud.com/markdown_img/ca-diagram-b.png" alt="证书颁发机构如何验证证书？"></p><p>ok，申请到了数字证书，给安装到server中。</p><ul><li><p><strong>当client请求时server返回数字证书，先查看证书认证的域名或所有者是谁？如果与你访问的域名不一致毫无疑问你正遭受中间人攻击，这是一个假站点请停止访问。</strong></p></li><li><p><strong>如果一致，接着client查看证书的签发CA机构是谁？找到浏览器或操作系统中对应的内置CA公钥，找不到？对不起，这个站点不安全（这其实也是垄断和付费的根源），如果找到则使用公钥解密签名得到hash值和此时证书中CSR信息的hash值做对比，如果一致，则这个证书没有被修改，你访问的站点很安全，取出证书中公钥来做加密通信吧。</strong></p></li></ul><p>如下图所示：</p><p><img src="https://markdown-1257692304.cos.ap-nanjing.myqcloud.com/markdown_img/image-20220206223630425.png" alt="image-20220206223630425"></p><h4 id="HTTPS不保护的信息？"><a href="#HTTPS不保护的信息？" class="headerlink" title="HTTPS不保护的信息？"></a>HTTPS不保护的信息？</h4><hr><ul><li><p>虽然 HTTPS 对整个 HTTP 请求和响应进行加密，但 DNS 解析和连接监听仍然可以获得一些其他信息，例如完整的域名或子域以及原始 IP 地址。</p></li><li><p>别有用心者还可能通过分析加密的 HTTPS 流量以获取特殊信息比如在网站上花费的时间，或用户数据包相对大小。</p></li></ul><h4 id="攻击-HTTPS-连接的有多难？"><a href="#攻击-HTTPS-连接的有多难？" class="headerlink" title="攻击 HTTPS 连接的有多难？"></a>攻击 HTTPS 连接的有多难？</h4><hr><p>对 HTTPS 连接的攻击通常分为 3 类：</p><ul><li>通过密码分析或其他协议的弱点破坏 HTTPS 连接的质量。</li><li>黑掉客户端，将恶意根证书安装到系统或浏览器信任库中。</li><li>获得浏览器信任的“流氓”证书，即通过操纵或破坏证书颁发机构。</li></ul><hr><p>以上是对HTTPS安全及其实现原理的学习，其中没有提到TLS/SSL版本、加密算法相关的内容，有兴趣的可以自行检索。</p><p><strong>希望小作文对你有些许帮助，如果内容有误请指正。</strong></p><p><strong>您可以随意转载、修改、发布本文，无需经过本人同意。通过博客阅读</strong>：<a href="https://iqsing.github.io/">iqsing.github.io</a></p><p>参考：</p><p><a href="https://www.ssl.com/faqs/what-is-a-certificate-authority/">what-is-a-certificate-authority</a></p><p><a href="https://https.cio.gov/faq/">The HTTPS-Only Standard</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;Google的一份&lt;a href=&quot;https://transparencyreport.google.com/https/overview&quot;&gt;网络上的 HTTPS 加密&lt;/a&gt;透明报告（数据截至2022年1月）中指出HTTPS 连接的普及率在过去几年激增，互联网上排名前 </summary>
      
    
    
    
    <category term="network" scheme="https://iqsing.github.io/categories/network/"/>
    
    
    <category term="https" scheme="https://iqsing.github.io/tags/https/"/>
    
  </entry>
  
  <entry>
    <title>k8s 基于RBAC的认证、授权介绍和实践</title>
    <link href="https://iqsing.github.io/2022/01/25/k8s%20%E5%9F%BA%E4%BA%8ERBAC%E7%9A%84%E8%AE%A4%E8%AF%81%E3%80%81%E6%8E%88%E6%9D%83%E4%BB%8B%E7%BB%8D%E5%92%8C%E5%AE%9E%E8%B7%B5/"/>
    <id>https://iqsing.github.io/2022/01/25/k8s%20%E5%9F%BA%E4%BA%8ERBAC%E7%9A%84%E8%AE%A4%E8%AF%81%E3%80%81%E6%8E%88%E6%9D%83%E4%BB%8B%E7%BB%8D%E5%92%8C%E5%AE%9E%E8%B7%B5/</id>
    <published>2022-01-24T16:47:21.000Z</published>
    <updated>2022-02-04T05:33:35.799Z</updated>
    
    <content type="html"><![CDATA[<p>在K8S中，当我们试图通过API与集群资源交互时，必定经过集群资源管理对象入口kube-apiserver。显然不是随随便便来一个请求它都欢迎的，每个请求都需要经过合规检查，包括Authentication(身份验证)、Authorization(授权)和Admission Control(准入控制)。通过一系列验证后才能完成交互。</p><p> Kubernetes API 请求从发起到持久化到ETCD数据库中的过程如下：</p><p><img src="https://markdown-1257692304.cos.ap-nanjing.myqcloud.com/markdown_img/image-20220121201812274.png" alt="image-20220121201812274"></p><p>“三个A”我们可以简单理解为：</p><ul><li><code>Authentication</code>：<strong>你是谁？</strong>你能登录系统么？</li><li><code>Authorization</code>：<strong>你想做什么？</strong>你有相应的权限么？</li><li><code>Admission Control</code>： 在apiserver中准入控制会以控制器插件的方式存在，类似于各类web框架中的中间件，可以在kube-apiserver的yml中添加控制器插件<code>--enable-admission-plugins</code>开启。</li></ul><p>这篇小作文我们主要来学习K8S中关于认证与授权相关的知识，看看他们是如何实现的。包含如下内容：</p><ul><li>K8S 通过证书认证</li><li>K8S 通过RBAC 授权</li></ul><h4 id="一、-K8S-通过证书认证"><a href="#一、-K8S-通过证书认证" class="headerlink" title="一、 K8S 通过证书认证"></a>一、 K8S 通过证书认证</h4><hr><p>Authentication(身份认证)，即核查用户能否进入K8s集群。一般来说k8s中有两类用户，普通用户和服务账户(Service Account)。</p><p>普通用户，使用者是人，即用户可以通过 kubectl 命令、或通过REST请求访问 API，<strong>但是请注意K8s不提供普通用户管理的资源对象</strong>，那所谓的普通用户哪里的？很简单只要你能通过k8s身份认证策略那么你就是一个普通用户。而Service Account 则是针对运行在 Pod 中的进程而言的。</p><p>K8S的几种验证方式：</p><ul><li>Certificate</li><li>Token</li><li>OpenID</li><li>Web Hook</li></ul><p>其中Certificate(证书)是在普通用户（客户端）中被广泛使用的验证方式。通过客户端证书进行身份验证时，客户端必须先获得一个有效的 x509 客户端证书，然后Kubernetes API服务器通过验证这个证书来验证你的身份。当然你的X509证书必须由集群 CA 证书签名。这其实就是HTTPS加密中的一部分，只不过是CA是K8S自签名的CA证书。</p><p>首先我们通过openssl创建一个用户私钥</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">openssl genrsa -out develop1.key 2048</span><br></pre></td></tr></table></figure><p>通过user.key 生成CSR（证书签名请求）,Kubernetes 使用证书中的 ‘subject’ 的通用名称（Common Name）字段来确定用户名,Organization Name 作为组。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">openssl req -new -key develop1.key -out develop1.csr -subj &quot;/CN=develop1/O=devops&quot;</span><br></pre></td></tr></table></figure><p>有了CSR，我们就可以把它交给K8S admin通过集群CA签署客户端证书。kubeadm创建的集群证书对存储在master节点的 /etc/Kubernetes/pki/ 目录中，（当然如果你是admin，也可以直接通过API的方式签署证书）集群包含一个根 CA，用它签署所有集群组件相互通信所需的证书。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">openssl x509 -req -in develop1.csr -CA /etc/kubernetes/pki/ca.crt \</span><br><span class="line">-CAkey /etc/kubernetes/pki/ca.key -CAcreateserial -out develop1.crt -days 30</span><br></pre></td></tr></table></figure><p>这样我们获得了一个被集群CA签署过的证书<code>develop1.crt</code></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">develop1.crt  develop1.csr  develop1.key</span><br></pre></td></tr></table></figure><p>查看证书内容<code>openssl x509 -noout -text -in develop1.crt</code>包含CN/O，以及证书过期时间。</p><p><img src="https://markdown-1257692304.cos.ap-nanjing.myqcloud.com/markdown_img/image-20220122011925935.png" alt="image-20220122011925935"></p><p>好了，有了证书之后，下一步我们需要配置<code>kubecofnig</code>使<code>kubectl</code>可以正常访问apiserver，关于<code>kubeconfig</code>可参考官方文档<a href="https://kubernetes.io/zh/docs/concepts/configuration/organize-cluster-access-kubeconfig/">organize-cluster-access-kubeconfig</a> 这里我们以配置为主。</p><p>默认情况下，<code>kubectl</code> 读取 <code>$HOME/.kube/config</code> 作为配置文件。也可以通过两种方式为 <code>kubectl</code> 指定配置文件：</p><ul><li>环境变量 <code>KUBECONFIG</code></li><li>命令行参数 <code>--kubeconfig</code></li></ul><p>现在通过kubectl来创建config中的集群入口</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">kubectl config set-cluster kubernetes \</span><br><span class="line">    --server=https://apiserver.cluster.local:6443 \</span><br><span class="line">    --certificate-authority=/etc/kubernetes/pki/ca.crt \</span><br><span class="line">    --embed-certs=true </span><br></pre></td></tr></table></figure><p>创建用户入口</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">kubectl config set-credentials develop1 \</span><br><span class="line">    --client-certificate=$HOME/private_key/develop1.crt \</span><br><span class="line">    --client-key=$HOME/private_key/develop1.key \</span><br><span class="line">    --embed-certs=true </span><br></pre></td></tr></table></figure><p>创建上下文</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kubectl config set-context develop1 \</span><br><span class="line">    --cluster=kubernetes \</span><br><span class="line">    --user=develop1 </span><br></pre></td></tr></table></figure><p>指定当前context</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kubectl config <span class="built_in">set</span> current-context develop1</span></span><br><span class="line">Property &quot;current-context&quot; set.</span><br><span class="line"><span class="meta">#</span><span class="bash">查看当前context，已绑定develop1</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> kubectl config current-context</span></span><br><span class="line">develop1</span><br></pre></td></tr></table></figure><p>通过<code>kubectl config view</code>查看当前的config</p><p><img src="https://markdown-1257692304.cos.ap-nanjing.myqcloud.com/markdown_img/image-20220122170015273.png" alt="image-20220122170015273"></p><p>这样我们<code>kubectl</code>已经配置完毕，但是此时我们只完成了<code>Authentication</code>，并没有获得权限</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kubectl get pod</span></span><br><span class="line">Error from server (Forbidden): pods is forbidden: User &quot;develop1&quot; cannot list resource &quot;pods&quot; in API group &quot;&quot; in thenamespace &quot;default&quot;</span><br></pre></td></tr></table></figure><p>可以看到develop1没有对命名空间<code>default</code>的<code>list</code>权限。所以接下来我们来学习<code>Authorization</code>授权相关内容。</p><h4 id="二、K8S-通过RBAC-授权"><a href="#二、K8S-通过RBAC-授权" class="headerlink" title="二、K8S 通过RBAC 授权"></a>二、K8S 通过RBAC 授权</h4><hr><p>RBAC(Role-Based Access Control)即基于角色的访问控制，在各类大型系统如虚拟化Vcenter、各类云服务以及众多toB软件访问控制中被大量使用。关于RBAC可参考一篇译文：<a href="https://arthurchiao.art/blog/rbac-as-it-meant-to-be-zh/">[译] 基于角色的访问控制（RBAC）：演进历史、设计理念及简洁实现（Tailscale, 2021）</a></p><p>k8s作为企业内部重要云基础设施并不希望每个使用平台的用户都可以不受限制的创建、修改和删除资源。同时伴随着集群节点、应用程序和团队数量的增加，你需要一种安全措施将用户或应用权限控制在某个范围内，这就K8S 在V1.8正式引入RBAC所要做的事（其他鉴权机制本文不涉及）。</p><p>K8S的RBAC 主要由Role、ClusterRole、RoleBinding 和 ClusterRoleBinding 等资源实现。模型如下：</p><p><img src="https://markdown-1257692304.cos.ap-nanjing.myqcloud.com/markdown_img/image-20220120025812853.png" alt="image-20220120025812853"></p><h5 id="Role、ClusterRole"><a href="#Role、ClusterRole" class="headerlink" title="Role、ClusterRole"></a>Role、ClusterRole</h5><p>角色是一组权限规则的集合，Role 用来定义某个命名空间内的访问权限，而ClusterRole 则是一个集群作用域的资源。为啥要用两个资源？因为Kubernetes 对象的作用域已经被划分为集群和命名空间两部分了。需要注意：角色只有授权没有禁止的操作。</p><p>构成一个<strong>Rule</strong>需要声明三部分：</p><ul><li><code>apiGroups</code>：资源所属的API组：<code>&quot;&quot;</code> 缺省为 core 组资源，如：extensions、apps、batch等。<a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.23/#-strong-api-groups-strong-">Kubernetes API 参考文档</a> </li><li><code>resources</code>：资源，如： pods、deployments、services、secrets 等。</li><li><code>verbs</code>：动作，如： get、list、watch、create、delete、update 等。</li></ul><p>现在我们来创建一个可以读取默认命名空间<code>default</code>的Role，它的api版本为：<code>rbac.authorization.k8s.io/v1</code></p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Role</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">default</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">develop-defualt</span></span><br><span class="line"><span class="attr">rules:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">apiGroups:</span> [<span class="string">&quot;&quot;</span>] <span class="comment">#core api组</span></span><br><span class="line">  <span class="attr">resources:</span> [<span class="string">&quot;pods&quot;</span>]</span><br><span class="line">  <span class="attr">verbs:</span> [<span class="string">&quot;get&quot;</span>, <span class="string">&quot;watch&quot;</span>, <span class="string">&quot;list&quot;</span>]</span><br></pre></td></tr></table></figure><p>此时还没有api交互权限，所以应该通过kube-admin来创建</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> kubectl apply -f role.yml</span></span><br><span class="line">role.rbac.authorization.k8s.io/develop-defualt created</span><br></pre></td></tr></table></figure><h5 id="RoleBinding、ClusterRoleBinding"><a href="#RoleBinding、ClusterRoleBinding" class="headerlink" title="RoleBinding、ClusterRoleBinding"></a>RoleBinding、ClusterRoleBinding</h5><p>上面我们已经创建了一个带权限的角色，下一步就了解如何将角色关联到用户。角色绑定是将我们角色中定义好的权限赋予一个或者一组用户，即上图Sujbect。RoleBinding 在指定的名字空间中执行授权，而 ClusterRoleBinding 在集群范围执行授权。</p><p><img src="https://markdown-1257692304.cos.ap-nanjing.myqcloud.com/markdown_img/image-20220120112142048.png" alt="image-20220120112142048"></p><p>图中展示了三种绑定方式，除了常规的绑定各自作用域的角色外，RoleBinding还可以绑定集群级别的ClusterRole。有啥用呢？当我们要对namespace做授权时，通常可以创建namespace中的Role进行绑定，如果管理几百个NS则需创建相应数量的NS Role，显然不是很棒，所以我们将RoleBinding绑定到集群的ClusterRole，只需几个ClusterRole就可以将几百个NS做访问控制了。</p><p>我们将上面创建的<code>develop-defualt</code>角色做绑定：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">RoleBinding</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">develop-rolebinding</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">default</span> <span class="comment">#授权的命名空间为default</span></span><br><span class="line"><span class="attr">subjects:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">kind:</span> <span class="string">User</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">develop1</span> <span class="comment"># 绑定develop1用户</span></span><br><span class="line">  <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span></span><br><span class="line"><span class="attr">roleRef:</span></span><br><span class="line">  <span class="attr">kind:</span> <span class="string">Role</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">develop-defualt</span> <span class="comment">#绑定Role</span></span><br><span class="line">  <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span></span><br></pre></td></tr></table></figure><p>通过admin创建RoleBinding</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> kubectl apply -f role-binding.yml</span></span><br><span class="line">rolebinding.rbac.authorization.k8s.io/develop-rolebinding created</span><br></pre></td></tr></table></figure><p>ok，此时在使用<code>kubectl get pod</code>时，就能获得结果了。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kubectl get pod</span></span><br><span class="line">NAME                                              READY   STATUS    RESTARTS   AGE</span><br><span class="line">web-85549dcb84-nb67c                              1/1     Running   0          12d</span><br><span class="line">web-85549dcb84-z95sj                              1/1     Running   0          12d</span><br></pre></td></tr></table></figure><p>ServiceAccount授权和普通用户相似，这里不再赘述。有兴趣的读者可以参考官方文档学习。</p><p>以上我们对K8S中认证和授权做了基本介绍，以及对创建一个用户并授权pod读取权限做了实践。</p><hr><p><strong>希望小作文对你有些许帮助，如果内容有误请指正。</strong></p><p><strong>您可以随意转载、修改、发布本文，无需经过本人同意。通过博客阅读</strong>：<a href="https://iqsing.github.io/">iqsing.github.io</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;在K8S中，当我们试图通过API与集群资源交互时，必定经过集群资源管理对象入口kube-apiserver。显然不是随随便便来一个请求它都欢迎的，每个请求都需要经过合规检查，包括Authentication(身份验证)、Authorization(授权)和Admission</summary>
      
    
    
    
    <category term="k8s" scheme="https://iqsing.github.io/categories/k8s/"/>
    
    
    <category term="RBAC" scheme="https://iqsing.github.io/tags/RBAC/"/>
    
  </entry>
  
  <entry>
    <title>k8s loadbalancer与ingress实践</title>
    <link href="https://iqsing.github.io/2022/01/20/k8s%20loadbalancer%E4%B8%8Eingress%E5%AE%9E%E8%B7%B5/"/>
    <id>https://iqsing.github.io/2022/01/20/k8s%20loadbalancer%E4%B8%8Eingress%E5%AE%9E%E8%B7%B5/</id>
    <published>2022-01-19T16:47:21.000Z</published>
    <updated>2022-02-04T05:29:09.413Z</updated>
    
    <content type="html"><![CDATA[<p>k8s可以通过三种方式将集群内服务暴露到外网，分别是NodePort、LoadBalancer、Ingress，其中NodePort作为基础通信形式我们在《k8s网络模型与集群通信》中进行了介绍，这里我们主要关注LoadBalancer和Ingress</p><h4 id="LoadBalancer"><a href="#LoadBalancer" class="headerlink" title="LoadBalancer"></a>LoadBalancer</h4><hr><p>loadbalancer是服务暴露到因特网的标准形式，和nodeport一样我们只需在创建service是指定type为loadbalancer即可，接着Service 的通过<code>status.loadBalancer</code>字段将需要创建的负载均衡器信息发布供负载均衡服务创建。不过loadbalancer是云服务商”专属“，像腾讯云CLB、阿里云SLB，这样在创建service时会自动帮我们创建一个负载均衡器。</p><p>大多数云上负载均衡也是基于nodeport，他们的结构如下：</p><p><img src="https://markdown-1257692304.cos.ap-nanjing.myqcloud.com/markdown_img/image-20220104155502920.png" alt="image-20220104155502920"></p><p>如果要在本地创建一个负载均衡器如何实现呢？</p><p><a href="https://metallb.universe.tf/">MetalLB</a>，一个CNCF沙箱项目，使用标准路由协议(ARP/BGP)，实现裸机K8s集群的负载均衡器。</p><p>安装方式可参考官方文档：<a href="https://metallb.universe.tf/installation/">installation</a></p><p>L2（子网）模式的结构，<a href="https://banzaicloud.com/tags/metallb/">图源</a></p><p><img src="https://markdown-1257692304.cos.ap-nanjing.myqcloud.com/markdown_img/image-20220104163613950.png" alt="image-20220104163613950"></p><p>安装后我们获得如下两个组件：</p><ul><li><code>metallb-system/controller</code> deployment。用于处理IP分配的控制器。</li><li><code>metallb-system/speaker</code>daemonset。集群中每个节点启动一个协议服务守护进程。</li></ul><p>接着添加一个configmap配置metallb IP池。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ConfigMap</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">metallb-system</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">config</span></span><br><span class="line"><span class="attr">data:</span></span><br><span class="line">  <span class="attr">config:</span> <span class="string">|</span></span><br><span class="line"><span class="string">    address-pools:</span></span><br><span class="line"><span class="string">    - name: default</span></span><br><span class="line"><span class="string">      protocol: layer2</span></span><br><span class="line"><span class="string">      addresses:</span></span><br><span class="line"><span class="string">      - 192.168.1.240-192.168.1.250</span></span><br></pre></td></tr></table></figure><p>这样当我们创建一个loadbalancer类型的service时,EXTERNAL-IP将会从地址池中获取一个用于外部访问的IP 192.168.1.243 当外部流量进入时，ARP将我们的请求地址广播获取所属的service，接着k8s内部 通过<code>iptables</code> 规则和 <code>kube-proxy</code>，将流量从服务端点引导到后端。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#nginx_deployment_service.yaml</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">metallb-system</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">nginx</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">nginx</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">nginx:latest</span></span><br><span class="line">        <span class="attr">ports:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">http</span></span><br><span class="line">          <span class="attr">containerPort:</span> <span class="number">80</span></span><br><span class="line"></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">metallb-system</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">http</span></span><br><span class="line">    <span class="attr">port:</span> <span class="number">80</span></span><br><span class="line">    <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line">    <span class="attr">targetPort:</span> <span class="number">80</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">nginx</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">LoadBalancer</span></span><br></pre></td></tr></table></figure><p>查看service <code>kubectl get svc</code></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">NAME     TYPE           CLUSTER-IP      EXTERNAL-IP     PORT(S)        AGE</span><br><span class="line">nginx    LoadBalancer   10.96.243.159   192.168.1.243   80:31052/TCP   40h</span><br></pre></td></tr></table></figure><p>测试访问：<code>curl 192.168.1.243</code></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> curl 192.168.1.243</span></span><br><span class="line">&lt;!DOCTYPE html&gt;</span><br><span class="line">&lt;html&gt;</span><br><span class="line">&lt;head&gt;</span><br><span class="line">&lt;title&gt;Welcome to nginx!&lt;/title&gt;</span><br><span class="line">&lt;style&gt;</span><br><span class="line">html &#123; color-scheme: light dark; &#125;</span><br><span class="line">body &#123; width: 35em; margin: 0 auto;</span><br><span class="line">font-family: Tahoma, Verdana, Arial, sans-serif; &#125;</span><br><span class="line">&lt;/style&gt;</span><br><span class="line">&lt;/head&gt;</span><br></pre></td></tr></table></figure><p>负载均衡可以建立在 OSI 网络模型的不同级别上，主要是在 L4（传输层，例如 TCP/UDP）和 L7（应用层，例如 HTTP）上。在 Kubernetes 中，<code>Services</code>是 L4 的抽象，LoadBalancer类型负载均衡依然有局限性，同时我们看到每创建一个service对应的负载均衡器都会消耗一个静态IP，这并不合理。当然k8s中的另一种资源对象ingress可工作在 L7 层实现应用程序协议（HTTP/HTTPS）的负载均衡。</p><h4 id="Ingress"><a href="#Ingress" class="headerlink" title="Ingress"></a>Ingress</h4><hr><p><a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.23/#ingress-v1beta1-networking-k8s-io">Ingress</a> 公开了从集群外部到集群内<a href="https://kubernetes.io/zh/docs/concepts/services-networking/service/">服务</a>的 HTTP 和 HTTPS 路由。 流量路由由 Ingress 资源上定义的规则控制。我们可以将 Ingress 配置为服务提供外部可访问的 URL、负载均衡流量、终止 SSL/TLS，以及提供基于名称的虚拟主机等能力。</p><p>我们所说的Ingress包含两个部分：</p><ul><li>ingress k8s资源对象：流量路由规则的控制</li><li>ingress-controller控制器：控制器的实现有非常多，可参考官方文档中列表<a href="https://kubernetes.io/zh/docs/concepts/services-networking/ingress-controllers/">Ingress 控制器</a>，这里我们使用k8s官方维护的控制器<a href="https://kubernetes.github.io/ingress-nginx/">NGINX Ingress Controller</a></li></ul><p>外部流量进入集群时先经过ingress-controller，然后根据ingress配置的路由规则将请求转发到后端service。</p><p><img src="https://markdown-1257692304.cos.ap-nanjing.myqcloud.com/markdown_img/image-20220104174923429.png" alt="image-20220104174923429"></p><h5 id="ingress-controller"><a href="#ingress-controller" class="headerlink" title="ingress-controller"></a>ingress-controller</h5><p>ingress-controller其实就是守护进程加一个反向代理的应用，守护进程不断监听集群中资源的变化，将ingress中的配置信息生成反向代理配置。在nginx-ingress controller中即生成<code>nginx.conf</code>的配置文件。</p><p>在本文中因为我们上面已经配置好了loadbalancer的服务，这样我们创建一个type为LoadBalancer的service关联这组pod，再把域名解析指向该地址，就实现了集群服务的对外暴露。当然你也可以使用<code>NodePort</code>、<code>Hostnetwork</code>的方式，感兴趣的小伙伴可以进行测试。</p><p>ingress-controller不是k8s内部组件，可以通过helm或资源清单方式安装,可查看<a href="https://kubernetes.github.io/ingress-nginx/deploy/#quick-start">ingress-nginx deploy</a></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v1.1.0/deploy/static/provider/cloud/deploy.yaml</span><br></pre></td></tr></table></figure><p>然后我们编辑service</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl edit service/ingress-nginx-controller -n ingress-nginx</span><br></pre></td></tr></table></figure><p>修改spec.type为LoadBalancer即可。</p><p>这样我们创建好了nginx-ingress controller，下一步就要配置ingress路由规则。</p><h5 id="ingress规则"><a href="#ingress规则" class="headerlink" title="ingress规则"></a>ingress规则</h5><p>host：k8s.com</p><p>基于url的路由：</p><ul><li>/api/v1</li><li>/api/v2</li></ul><p>这两个url分别路由到不同的service中</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">extensions/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Ingress</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">test</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">training</span></span><br><span class="line">  <span class="attr">annotations:</span></span><br><span class="line">    <span class="attr">ingress.kubernetes.io/rewrite-target:</span> <span class="string">/</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">rules:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">host:</span> <span class="string">k8s.com</span></span><br><span class="line">    <span class="attr">http:</span></span><br><span class="line">      <span class="attr">paths:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">path:</span> <span class="string">/api/v1</span></span><br><span class="line">        <span class="attr">backend:</span></span><br><span class="line">          <span class="attr">serviceName:</span> <span class="string">service-apiv1</span></span><br><span class="line">          <span class="attr">servicePort:</span> <span class="number">80</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">path:</span> <span class="string">/api/v2</span></span><br><span class="line">        <span class="attr">backend:</span></span><br><span class="line">          <span class="attr">serviceName:</span> <span class="string">service-apiv2</span></span><br><span class="line">          <span class="attr">servicePort:</span> <span class="number">80</span></span><br></pre></td></tr></table></figure><p><code>ingress.kubernetes.io/rewrite-target</code>是nginx-ingress controller的一个注解，当后端服务中暴露的 URL 与 Ingress 规则中指定的路径不同时可以通过此重定向。</p><p>查看svc可以看到此时控制器已经获得了一个EXTERNAL-IP</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">kubectl get svc -n ingress-nginx</span></span><br><span class="line">NAME                                 TYPE           CLUSTER-IP     EXTERNAL-IP     PORT(S)                      AGE</span><br><span class="line">ingress-nginx-controller             LoadBalancer   10.96.87.23    192.168.1.245   80:32603/TCP,443:31906/TCP   621d</span><br><span class="line">ingress-nginx-controller-admission   ClusterIP      10.96.109.70   &lt;none&gt;          443/TCP                      621d</span><br></pre></td></tr></table></figure><p>现在nginx-ingress controller和ingress路由规则都有了。</p><p>我们可以进入到nginx-ingress controller pod中查看nginx.conf可以看到此时我们的ingress配置已经被生成为路由规则。</p><p><img src="https://markdown-1257692304.cos.ap-nanjing.myqcloud.com/markdown_img/image-20220104211938284.png" alt="image-20220104211938284">接下来就是指定我们的backend，即上面的server-apiv1/2</p><p>我们添加两个用于暴露的service和deployment，和loadbalancer中测试清单一样，我们稍稍修改一下名称即可。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">nginx-apiv1</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">training</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">nginx-apiv1</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">nginx-apiv1</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx-apiv1</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">nginx:latest</span></span><br><span class="line">        <span class="attr">ports:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">http</span></span><br><span class="line">          <span class="attr">containerPort:</span> <span class="number">80</span></span><br><span class="line"></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">training</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">service-apiv1</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">http</span></span><br><span class="line">    <span class="attr">port:</span> <span class="number">80</span></span><br><span class="line">    <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line">    <span class="attr">targetPort:</span> <span class="number">80</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">nginx-apiv1</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">NodePort</span></span><br></pre></td></tr></table></figure><p>将nginx-apiv1换成nginx-apiv2创建出另一个service和deployment。</p><p>最后修改hosts解析k8s.com</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">192.168.1.245 k8s.com</span><br></pre></td></tr></table></figure><p>使用curl命令测试url路由（记得在pod中添加测试文件，否则虽然url进行了路由但会出现404）。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> curl k8s.com/api/v1/index.html</span></span><br><span class="line">api v1</span><br><span class="line"><span class="meta">#</span><span class="bash"> curl k8s.com/api/v2/index.html</span></span><br><span class="line">api v2</span><br></pre></td></tr></table></figure><p>这样我们对ingress有了初步了解，ingress的路由规则可自定项较多也比较繁杂，可通过官方文档进一步学习。</p><hr><p><strong>希望小作文对你有些许帮助，如果内容有误请指正。</strong></p><p><strong>您可以随意转载、修改、发布本文，无需经过本人同意。</strong> </p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;k8s可以通过三种方式将集群内服务暴露到外网，分别是NodePort、LoadBalancer、Ingress，其中NodePort作为基础通信形式我们在《k8s网络模型与集群通信》中进行了介绍，这里我们主要关注LoadBalancer和Ingress&lt;/p&gt;
&lt;h4 id</summary>
      
    
    
    
    <category term="k8s" scheme="https://iqsing.github.io/categories/k8s/"/>
    
    
    <category term="loadBalancer" scheme="https://iqsing.github.io/tags/loadBalancer/"/>
    
    <category term="ingress" scheme="https://iqsing.github.io/tags/ingress/"/>
    
  </entry>
  
  <entry>
    <title>k8s 理解Service工作原理</title>
    <link href="https://iqsing.github.io/2022/01/15/k8s%20%E7%90%86%E8%A7%A3Service%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86/"/>
    <id>https://iqsing.github.io/2022/01/15/k8s%20%E7%90%86%E8%A7%A3Service%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86/</id>
    <published>2022-01-14T16:47:21.000Z</published>
    <updated>2022-02-04T05:29:18.023Z</updated>
    
    <content type="html"><![CDATA[<h4 id="什么是service？"><a href="#什么是service？" class="headerlink" title="什么是service？"></a>什么是service？</h4><hr><blockquote><p>Service是将运行在一组 Pods 上的应用程序公开为网络服务的抽象方法。</p></blockquote><p>简单来说K8s提供了service对象来访问pod。我们在《k8s网络模型与集群通信》中也说过k8s集群中的每一个Pod（最小调度单位）都有自己的IP地址，都有IP了访问起来还不简单？</p><p>其实不然，一是k8s中pod不是持久性的，摧毁重建将获得新的IP，客户端通过变更IP来访问显然不合理。二是需要多个副本间的负载均衡。所以此时Service就冒出来了。</p><p>那么今天我们就来学习一下service，看看它是如何工作的。</p><h4 id="Service与endpoints、pod"><a href="#Service与endpoints、pod" class="headerlink" title="Service与endpoints、pod"></a>Service与endpoints、pod</h4><hr><p>当我们通过API创建/修改service对象时，endpoints控制器的informer机制 Listen到service对象，然后根据service的配置的选择器创建一个<code>endpoints</code>对象，此对象将pod的IP、容器端口做记录并存储到etcd，这样service只要看一下自己名下的endpoints就可以知道所对应pod信息了。</p><p>且看下图：</p><p><img src="https://markdown-1257692304.cos.ap-nanjing.myqcloud.com/markdown_img/image-20220108162349356.png" alt="image-20220108162349356"></p><p>我们在实例来看一下，先稀疏平常创建一个Deployment</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#deployment.yml</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">deployment-demo</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">nginx</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">3</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">nginx</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">mirrorgooglecontainers/serve_hostname</span></span><br><span class="line">        <span class="attr">ports:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">9376</span></span><br><span class="line">          <span class="attr">protocol:</span> <span class="string">TCP</span></span><br></pre></td></tr></table></figure><p><code>serve_hostname</code>是k8s官方提供的debug镜像，一个返回hostname的web server。这样我们创建出了标签为<code>app=nginx</code>的三个pod，当我们访问pod的9376时会返回hostname。</p><p>接着是service清单，我们在service中指定了选择器为<code>app=nginx</code></p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#service.yaml</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">service-demo</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">nginx</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">default</span></span><br><span class="line">    <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line">    <span class="comment">#service port</span></span><br><span class="line">    <span class="attr">port:</span> <span class="number">80</span></span><br><span class="line">    <span class="comment">#container port</span></span><br><span class="line">    <span class="attr">targetPort:</span> <span class="number">9376</span></span><br></pre></td></tr></table></figure><p>这样我们获得不变的CLUSTER-IP 10.96.148.206的service</p><p><img src="https://markdown-1257692304.cos.ap-nanjing.myqcloud.com/markdown_img/image-20220107233553740.png" alt="image-20220107233553740"></p><p>如果pod启动成功，则自动创建和service同名的endpoints记录下了三个pod的数据</p><p><img src="https://markdown-1257692304.cos.ap-nanjing.myqcloud.com/markdown_img/image-20220108004254486.png" alt="image-20220108004254486"></p><p>service中选择器未指定标签时endpoints需要手动创建映射到service的网络地址如下：</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Endpoints</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">service</span></span><br><span class="line"><span class="attr">subsets:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">addresses:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">ip:</span> <span class="number">10.96</span><span class="number">.148</span><span class="number">.206</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">port:</span> <span class="number">9376</span></span><br></pre></td></tr></table></figure><p>此时当我们不断访问service的CLUSTER-IP时：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> curl 10.96.148.206:80</span></span><br><span class="line">deployment-demo-7d94cbb55f-8mmxb</span><br><span class="line"><span class="meta">#</span><span class="bash"> curl 10.96.148.206:80</span></span><br><span class="line">deployment-demo-7d94cbb55f-674ns</span><br><span class="line"><span class="meta">#</span><span class="bash"> curl 10.96.148.206:80</span></span><br><span class="line">deployment-demo-7d94cbb55f-lfrm8</span><br><span class="line"><span class="meta">#</span><span class="bash"> curl 10.96.148.206:80</span></span><br><span class="line">deployment-demo-7d94cbb55f-8mmxb</span><br></pre></td></tr></table></figure><p>可以看到此时请求已被路由到后端pod，返回hostname，并且负载均衡方式是<code>Round Robin</code>即轮询模式。</p><p>通过上面介绍我们好像摸到了<code>Service</code>其中的门道，接下来是流量到底如何通过service进入pod的？</p><h4 id="Service与kube-proxy"><a href="#Service与kube-proxy" class="headerlink" title="Service与kube-proxy"></a>Service与kube-proxy</h4><hr><p>涉及到流量当然是kube-proxy登场了！</p><blockquote><p>kube-proxy 是集群中每个节点上运行的网络代理， 实现 Kubernetes 服务（Service） 概念的一部分。用于处理单个主机子网划分并向外部世界公开服务。它跨集群中的各种隔离网络将请求转发到正确的 pod/容器。</p></blockquote><p>kube-proxy 维护节点上的网络规则。这些网络规则允许从集群内部或外部的网络会话与 Pod 进行网络通信。</p><p>如下图所示：</p><p><img src="https://markdown-1257692304.cos.ap-nanjing.myqcloud.com/markdown_img/image-20220108143313157.png" alt="image-20220108143313157"></p><p>kube-proxy 通过 Informer知道了Service、endpoints对象的创建，然后把service身上的CLUSTER-IP 和端口已经端点信息拿出来，创建iptable NAT规则做转发或通过ipvs模块创建VS服务器，这样经过CLUSTER-IP的流量都被转发到后端pod。</p><h5 id="iptables模式"><a href="#iptables模式" class="headerlink" title="iptables模式"></a>iptables模式</h5><p>我们先查看nat表的OUTPUT链，存在kube-proxy创建的KUBE-SERVICE链</p><p><code>iptables -nvL OUTPUT -t nat</code></p><p><img src="https://markdown-1257692304.cos.ap-nanjing.myqcloud.com/markdown_img/image-20220108152150242.png" alt="image-20220108152150242"></p><p>在KUBE-SERVICES链中有一条目的地为10.96.148.206即CLUSTER-IP地址跳转到KUBE-SVC-EJUV4ZBKPDWOZNF4</p><p><code>iptables -nvL KUBE-SERVICES -t nat |grep  service-demo</code></p><p><img src="https://markdown-1257692304.cos.ap-nanjing.myqcloud.com/markdown_img/image-20220108153015622.png" alt="image-20220108153015622"></p><p>接着是查看这条链，以1/3的概率跳转到其中一条</p><p><code>iptables -nvL KUBE-SVC-EJUV4ZBKPDWOZNF4 -t nat</code></p><p><img src="https://markdown-1257692304.cos.ap-nanjing.myqcloud.com/markdown_img/image-20220108153839227.png" alt="image-20220108153839227"></p><p>最后KUBE-SEP-BTFJGISFGMEBGVUF链终于找到了DNAT规则</p><p><code>iptables -nvL KUBE-SEP-BTFJGISFGMEBGVUF -t nat</code></p><p><img src="https://markdown-1257692304.cos.ap-nanjing.myqcloud.com/markdown_img/image-20220108154014449.png" alt="image-20220108154014449"></p><p>即将请求通过DNAT发送到地址<code>100.101.184.61:9376</code>也就是我们其中一个Pod。</p><h5 id="IPVS模式"><a href="#IPVS模式" class="headerlink" title="IPVS模式"></a>IPVS模式</h5><p>与iptalbes模式相比，IPVS模式工作在内核态，在同步代理规则时具有更好的性能，同时提高网络吞吐量为大型集群提供了更好的可扩展性。</p><p>IPVS 模式在工作时，当我们创建了前面的 Service 之后，kube-proxy 首先会在宿主机上创建一个虚拟网卡kube-ipvs0，并为它分配 Service VIP 作为 IP 地址，如图</p><p><img src="https://markdown-1257692304.cos.ap-nanjing.myqcloud.com/markdown_img/image-20220108161050509.png" alt="image-20220108161050509"></p><p>接着kube-proxy通过Linux的IPVS模块为这个 IP 地址添加三个 IPVS 虚拟主机，并设置这三个虚拟主机之间使用轮询模式 来作为负载均衡策略。</p><p>通过ipvsadm查看</p><p><code>ipvsadm -ln |grep -C 5 10.96.148.206</code></p><p><img src="https://markdown-1257692304.cos.ap-nanjing.myqcloud.com/markdown_img/image-20220108161800771.png" alt="image-20220108161800771"></p><p>可以看到虚拟server的IP即是Pod的地址，这样流量即向了目的地Pod。</p><p>以上我们先认识了Service这个API对象，接着讲到了service与endpoints和pod的关联，然后是service与kube-proxy的关系，以及kube-proxy的两种模式如何通过service的IP创建iptables、IPVS规则将流量转发到Pod。</p><hr><p><strong>希望小作文对你有些许帮助，如果内容有误请指正。</strong></p><p><strong>您可以随意转载、修改、发布本文，无需经过本人同意。通过博客阅读</strong>：<a href="https://iqsing.github.io/">iqsing.github.io</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h4 id=&quot;什么是service？&quot;&gt;&lt;a href=&quot;#什么是service？&quot; class=&quot;headerlink&quot; title=&quot;什么是service？&quot;&gt;&lt;/a&gt;什么是service？&lt;/h4&gt;&lt;hr&gt;
&lt;blockquote&gt;
&lt;p&gt;Service是将运行在一组 P</summary>
      
    
    
    
    <category term="k8s" scheme="https://iqsing.github.io/categories/k8s/"/>
    
    
    <category term="service" scheme="https://iqsing.github.io/tags/service/"/>
    
  </entry>
  
  <entry>
    <title>k8s env、configmap、secret外部数据加载配置</title>
    <link href="https://iqsing.github.io/2022/01/10/k8s%20env%E3%80%81configmap%E3%80%81secret%E5%A4%96%E9%83%A8%E6%95%B0%E6%8D%AE%E5%8A%A0%E8%BD%BD%E9%85%8D%E7%BD%AE/"/>
    <id>https://iqsing.github.io/2022/01/10/k8s%20env%E3%80%81configmap%E3%80%81secret%E5%A4%96%E9%83%A8%E6%95%B0%E6%8D%AE%E5%8A%A0%E8%BD%BD%E9%85%8D%E7%BD%AE/</id>
    <published>2022-01-09T16:47:21.000Z</published>
    <updated>2022-02-04T05:28:23.080Z</updated>
    
    <content type="html"><![CDATA[<p>K8s提供了多种外部数据注入容器的方式，今天我们主要学习环境变量、ConfigMap以及Secret的使用和配置。</p><h4 id="环境变量"><a href="#环境变量" class="headerlink" title="环境变量"></a>环境变量</h4><hr><p>在docker项目中，对一个容器添加环境变量可以在容器创建时通过<code>-e ENV=name</code>方式加载。而k8s在创建 Pod 时，也提供了其下容器环境变量配置的能力。</p><p>我们可以通过配置清单中的 <code>env</code> 及 <code>envFrom（来自外部配置）</code> 字段来设置环境变量。</p><p>比如如下的yaml</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#busybox-deployment.yml</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">busybox-deployment</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">busybox</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">1</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">busybox</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">busybox</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">busybox:latest</span></span><br><span class="line">        <span class="attr">resources:</span></span><br><span class="line">          <span class="attr">limits:</span></span><br><span class="line">            <span class="attr">memory:</span> <span class="string">20Mi</span></span><br><span class="line">        <span class="attr">env:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">DEMO_VERSION</span></span><br><span class="line">          <span class="attr">value:</span> <span class="string">demov1</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">DEMO_POD_NAME</span></span><br><span class="line">          <span class="attr">valueFrom:</span></span><br><span class="line">            <span class="attr">fieldRef:</span></span><br><span class="line">              <span class="attr">fieldPath:</span> <span class="string">metadata.name</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">DEMO_CONT_MEM</span></span><br><span class="line">          <span class="attr">valueFrom:</span></span><br><span class="line">            <span class="attr">resourceFieldRef:</span></span><br><span class="line">              <span class="attr">containerName:</span> <span class="string">busybox</span></span><br><span class="line">              <span class="attr">resource:</span> <span class="string">limits.memory</span></span><br><span class="line">        <span class="attr">command:</span> [<span class="string">&#x27;top&#x27;</span>]</span><br></pre></td></tr></table></figure><p>在清单中我们配置了三个环境变量：</p><ul><li><code>DEMO_VERSION</code>:直接添加变量值<code>demov1</code></li><li><code>DEMO_POD_NAME</code>:结合valueFrom中fieldRef获取pod名称字段<code>metadata.name</code></li><li><code>DEMO_CONT_MEM</code>:结合valueFrom中resourceFieldRef获取容器资源字段<code>limits.memory</code></li></ul><p>此时我们创建pod进入容器后通过printenv命令可以查看到环境变量已经被加载：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">kubectl <span class="built_in">exec</span> busybox-deployment-5bb768546c-jbsmz -- printenv</span></span><br><span class="line"></span><br><span class="line">DEMO_POD_NAME=busybox-deployment-5bb768546c-jbsmz</span><br><span class="line">DEMO_CONT_MEM=20971520</span><br><span class="line">    DEMO_VERSION=demov1</span><br></pre></td></tr></table></figure><p><code>valueFrom</code>中其他字段如下待会我们会用到，需要时可参考官方API文档：<a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.23/#envvar-v1-core">envvar-v1-core</a></p><p><img src="https://markdown-1257692304.cos.ap-nanjing.myqcloud.com/markdown_img/image-20220105234011959.png" alt="image-20220105234011959">注意： 环境变量将覆盖容器镜像中指定的所有环境变量。</p><h4 id="ConfigMap"><a href="#ConfigMap" class="headerlink" title="ConfigMap"></a>ConfigMap</h4><hr><blockquote><p>ConfigMap 是一种 API 对象，用来将非机密性的数据保存到键值对中。使用时， Pods可以将其用作环境变量、命令行参数或者存储卷中的配置文件。</p></blockquote><h5 id="1、用于环境变量"><a href="#1、用于环境变量" class="headerlink" title="1、用于环境变量"></a>1、用于环境变量</h5><p>Configmap 用于配置环境变量的好处是可以将环境配置信息和容器镜像解耦，便于应用配置的修改。</p><p>我们可以快速的创建出一个configmap如下：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#busybox-configmap.yaml</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ConfigMap</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">busybox-configmap</span></span><br><span class="line"><span class="attr">data:</span></span><br><span class="line">  <span class="attr">DEMO_VERSION:</span> <span class="string">&quot;demov2&quot;</span></span><br></pre></td></tr></table></figure><p>configmap使用 <code>data</code>（UTF-8字节序列） 和 <code>binaryData</code>（二进制数据base64 编码的字串） 字段创建键值对做数据存储。</p><p>接着使用调整我们deployment中的<code>env</code>DEMO_VERSION的字段如下：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">DEMO_VERSION</span></span><br><span class="line">  <span class="attr">valueFrom:</span></span><br><span class="line">    <span class="attr">configMapKeyRef:</span></span><br><span class="line">      <span class="attr">name:</span> <span class="string">busybox-configmap</span></span><br><span class="line">      <span class="attr">key:</span> <span class="string">DEMO_VERSION</span></span><br></pre></td></tr></table></figure><p><code>configMapKeyRef</code>如API所说的选择一个configmap</p><p>同样创建后查看</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> kubectl <span class="built_in">exec</span> pod/busybox-deployment-64c678977f-zjnhb -- printenv</span></span><br><span class="line"></span><br><span class="line">DEMO_VERSION=demov2</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>这样我们只需要维护这个configmap即可，不过通过环境变量引用configmap时也是不支持热更新，环境变量只在容器创建时加载，所以你需要触发一次deployment的滚动更新。</p><h5 id="2、挂载配置信息"><a href="#2、挂载配置信息" class="headerlink" title="2、挂载配置信息"></a>2、挂载配置信息</h5><p>显然从名字上可以看出configmap并不是为环境变量而生。我们可以将configmap中key作文文件挂载到容器中，我们创建如下清单：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ConfigMap</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">busybox-configmap</span></span><br><span class="line"><span class="attr">data:</span></span><br><span class="line">  <span class="attr">DEMO_VERSION:</span> <span class="string">&quot;demov3&quot;</span></span><br><span class="line"></span><br><span class="line">  <span class="attr">game.properties:</span> <span class="string">|</span></span><br><span class="line"><span class="string">    enemies=aliens</span></span><br><span class="line"><span class="string">    lives=3</span></span><br><span class="line"><span class="string">    enemies.cheat=true</span></span><br><span class="line"><span class="string">    enemies.cheat.level=noGoodRotten</span></span><br><span class="line"><span class="string">    secret.code.passphrase=UUDDLRLRBABAS</span></span><br><span class="line"><span class="string">    secret.code.allowed=true</span></span><br><span class="line"><span class="string">    secret.code.lives=30</span></span><br><span class="line"><span class="string"></span>  <span class="attr">ui.properties:</span> <span class="string">|</span></span><br><span class="line"><span class="string">    color.good=purple</span></span><br><span class="line"><span class="string">    color.bad=yellow</span></span><br><span class="line"><span class="string">    allow.textmode=true</span></span><br><span class="line"><span class="string">    how.nice.to.look=fairlyNice</span></span><br></pre></td></tr></table></figure><p>相当于此时我们获得三个key文件，接下来我们就可以通过volume挂载了。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">...</span></span><br><span class="line"><span class="attr">volumeMounts:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">config-volume</span></span><br><span class="line">  <span class="attr">mountPath:</span> <span class="string">/etc/config</span></span><br><span class="line"><span class="attr">volumes:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">config-volume</span></span><br><span class="line">  <span class="attr">configMap:</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">busybox-configmap</span></span><br><span class="line"><span class="string">...</span></span><br></pre></td></tr></table></figure><p>在volume中configmap字段指定我们的busybox-configmap，创建后查看/etc/config</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kubectl <span class="built_in">exec</span> busybox-deployment-87b6c7bd7-ljcfr --  ls /etc/config/</span></span><br><span class="line">DEMO_VERSION</span><br><span class="line">game.properties</span><br><span class="line">ui.properties</span><br></pre></td></tr></table></figure><p>当卷中使用的 ConfigMap 被更新时，所投射的键最终也会被更新。 kubelet 组件会在每次周期性同步时检查所挂载的 ConfigMap 是否为最新。即k8s的watch机制。</p><h4 id="Secret"><a href="#Secret" class="headerlink" title="Secret"></a>Secret</h4><hr><p>与ConfigMap类似，k8s提供了另一种API对象Secret用于存储机密信息，我们可以使用Secret对象存储敏感信息例如密码、令牌或密钥，这样在应用程序代码中解耦机密数据。</p><p>创建一个Sercet</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Secret</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">mysecret</span></span><br><span class="line"><span class="attr">type:</span> <span class="string">Opaque</span></span><br><span class="line"><span class="attr">data:</span></span><br><span class="line">  <span class="attr">password:</span> <span class="string">cGFzc3dk</span></span><br><span class="line"><span class="attr">stringData:</span></span><br><span class="line">  <span class="attr">username:</span> <span class="string">k8s</span></span><br></pre></td></tr></table></figure><p><code>data</code> 字段用来存储 base64 编码的任意数据，我们可以通过base64命令生成编码。</p><p><code>stringData</code>则允许 Secret 使用未编码的字符串，只用于写，无法直接读取明文字段。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kubectl get secret mysecret -o yaml</span></span><br><span class="line">apiVersion: v1</span><br><span class="line">data:</span><br><span class="line">  password: cGFzc3dk</span><br><span class="line">  username: azhz</span><br><span class="line">...</span><br><span class="line"><span class="meta">$</span><span class="bash"> kubectl describe secret mysecret</span></span><br><span class="line">...</span><br><span class="line">Data</span><br><span class="line">====</span><br><span class="line">password:  6 bytes</span><br><span class="line">username:  3 bytes</span><br></pre></td></tr></table></figure><p> 这样在<code>kubectl get</code> 和 <code>kubectl describe</code> 中默认不显示 <code>Secret</code> 的内容。 这是为了防止 <code>Secret</code> 意外地暴露给旁观者或者保存在终端日志中。</p><blockquote><p>Kubernetes 提供若干种内置的Secret类型，用于一些常见的使用场景。 针对这些类型，Kubernetes 所执行的合法性检查操作以及对其所实施的限制各不相同。</p></blockquote><table><thead><tr><th>内置类型</th><th>用法</th></tr></thead><tbody><tr><td><code>Opaque</code></td><td>用户定义的任意数据</td></tr><tr><td><code>kubernetes.io/service-account-token</code></td><td>服务账号令牌</td></tr><tr><td><code>kubernetes.io/dockercfg</code></td><td><code>~/.dockercfg</code> 文件的序列化形式</td></tr><tr><td><code>kubernetes.io/dockerconfigjson</code></td><td><code>~/.docker/config.json</code> 文件的序列化形式</td></tr><tr><td><code>kubernetes.io/basic-auth</code></td><td>用于基本身份认证的凭据</td></tr><tr><td><code>kubernetes.io/ssh-auth</code></td><td>用于 SSH 身份认证的凭据</td></tr><tr><td><code>kubernetes.io/tls</code></td><td>用于 TLS 客户端或者服务器端的数据</td></tr><tr><td><code>bootstrap.kubernetes.io/token</code></td><td>启动引导令牌数据</td></tr></tbody></table><p>类型说明可参考官方文档：<a href="https://kubernetes.io/zh/docs/concepts/configuration/secret/">secret</a>，当然也可以通过<code>Opaque</code>自定义的实现内置类型。</p><p>这里我们以类型<code>kubernetes.io/ssh-auth</code>为例尝试使用Secret,<code>kubernetes.io/ssh-auth</code> 用来存放 SSH 身份认证中 所需要的凭据。使用这种 Secret 类型时，我们必须在其 <code>data</code> （或 <code>stringData</code>） 字段中提供一个 <code>ssh-privatekey</code> 键值对，作为要使用的 SSH 凭据。</p><p>创建如下的yaml：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Secret</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">secret-ssh-auth</span></span><br><span class="line"><span class="attr">type:</span> <span class="string">kubernetes.io/ssh-auth</span></span><br><span class="line"><span class="attr">data:</span></span><br><span class="line">  <span class="attr">ssh-privatekey:</span> <span class="string">|</span></span><br><span class="line">          <span class="string">PRIVATEKEY_STINGS..</span>  <span class="comment">#base64编码数据</span></span><br></pre></td></tr></table></figure><p>创建后可以查看到类型和key名称。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kubectl describe secret/secret-ssh-auth</span></span><br><span class="line">Name:         secret-ssh-auth</span><br><span class="line">Namespace:    default</span><br><span class="line">Labels:       &lt;none&gt;</span><br><span class="line">Annotations:  &lt;none&gt;</span><br><span class="line"></span><br><span class="line">Type:  kubernetes.io/ssh-auth</span><br><span class="line"></span><br><span class="line">Data</span><br><span class="line">====</span><br><span class="line">ssh-privatekey:  2626 bytes</span><br></pre></td></tr></table></figure><p>接着创建用于加载secret的pod</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">pod-secret</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">pod-secret</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">nginx</span></span><br><span class="line">    <span class="attr">volumeMounts:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">secret-volume</span></span><br><span class="line">      <span class="attr">mountPath:</span> <span class="string">&quot;/etc/ssh/&quot;</span></span><br><span class="line">      <span class="attr">readOnly:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">volumes:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">secret-volume</span></span><br><span class="line">    <span class="attr">secret:</span></span><br><span class="line">      <span class="attr">secretName:</span> <span class="string">secret-ssh-auth</span></span><br></pre></td></tr></table></figure><p>此时容器中已加载到secretName中的<code>ssh-privatekey</code>项</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kubectl <span class="built_in">exec</span> pod/pod-secret --  ls /etc/ssh</span></span><br><span class="line">ssh-privatekey</span><br></pre></td></tr></table></figure><p>这样我们可以通过此key来做ssh相关的认证。</p><p>和configmap一样，secret也可用于环境变量配置。通过secretRef字段引入secret</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">...</span></span><br><span class="line"><span class="attr">envFrom:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">secretRef:</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">mysecret</span></span><br><span class="line"><span class="string">...</span></span><br></pre></td></tr></table></figure><p><em>以上secret使用仅做学习，生产中请排查以下安全问题，更多secret内容参考官方文档：<a href="https://kubernetes.io/zh/docs/concepts/configuration/secret/">Secret</a></em></p><p><strong>安全问题：</strong></p><ul><li><p><strong>当部署与 Secret API 交互的应用程序时，应使用 鉴权策略， 例如 RBAC，来限制访问。</strong></p></li><li><p><strong>API 服务器上的 Secret 数据以纯文本的方式存储在 etcd 中</strong>，因此：</p><ul><li>管理员应该为集群数据开启<a href="https://kubernetes.io/zh/docs/tasks/administer-cluster/encrypt-data/">静态加密</a>（要求 v1.13 或者更高版本）。</li><li>管理员应该限制只有 admin 用户能访问 etcd；</li><li>API 服务器中的 Secret 数据位于 etcd 使用的磁盘上,不再使用secret应该被删除。</li><li>如果 etcd 运行在集群内，管理员应该确保 etcd 之间的通信使用 SSL/TLS 进行加密。</li></ul></li><li><p><strong>如果将 Secret 数据编码为 base64 的清单（JSON 或 YAML）文件，共享该文件或将其检入代码库，该密码将会被泄露。 Base64 编码不是一种加密方式，应该视同纯文本。</strong></p></li><li><p><strong>应用程序在从卷中读取 Secret 后仍然需要保护 Secret 的值，例如不会意外将其写入日志或发送给不信任方。</strong></p></li><li><p><strong>可以创建使用 Secret 的 Pod 的用户也可以看到该 Secret 的值。即使 API 服务器策略不允许用户读取 Secret 对象，用户也可以运行 Pod 导致 Secret 暴露。</strong></p></li></ul><hr><p><strong>希望小作文对你有些许帮助，如果内容有误请指正。</strong></p><p><strong>您可以随意转载、修改、发布本文，无需经过本人同意。</strong> 通过博客阅读：<a href="https://iqsing.github.io/">iqsing.github.io</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;K8s提供了多种外部数据注入容器的方式，今天我们主要学习环境变量、ConfigMap以及Secret的使用和配置。&lt;/p&gt;
&lt;h4 id=&quot;环境变量&quot;&gt;&lt;a href=&quot;#环境变量&quot; class=&quot;headerlink&quot; title=&quot;环境变量&quot;&gt;&lt;/a&gt;环境变量&lt;/h4&gt;</summary>
      
    
    
    
    <category term="k8s" scheme="https://iqsing.github.io/categories/k8s/"/>
    
    
    <category term="configmap" scheme="https://iqsing.github.io/tags/configmap/"/>
    
    <category term="secret" scheme="https://iqsing.github.io/tags/secret/"/>
    
  </entry>
  
  <entry>
    <title>k8s网络模型与集群通信</title>
    <link href="https://iqsing.github.io/2021/11/16/k8s%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E4%B8%8E%E9%9B%86%E7%BE%A4%E9%80%9A%E4%BF%A1/"/>
    <id>https://iqsing.github.io/2021/11/16/k8s%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E4%B8%8E%E9%9B%86%E7%BE%A4%E9%80%9A%E4%BF%A1/</id>
    <published>2021-11-16T04:47:21.000Z</published>
    <updated>2022-02-04T05:16:11.998Z</updated>
    
    <content type="html"><![CDATA[<p>在k8s中，我们的应用会以pod的形式被调度到各个node节点上，在设计集群如何处理容器之间的网络时是一个不小的挑战，今天我们会从pod（应用）通信来展开关于k8s网络的讨论。</p><p>小作文包含如下内容：</p><ul><li>k8s网络模型与实现方案</li><li>pod内容器通信</li><li>pod与pod通信</li><li>pod与service通信</li><li>外网与service通信</li></ul><hr><h4 id="k8s网络模型与实现方案"><a href="#k8s网络模型与实现方案" class="headerlink" title="k8s网络模型与实现方案"></a>k8s网络模型与实现方案</h4><p><strong>k8s集群中的每一个Pod（最小调度单位）都有自己的IP地址，即ip-per-pod模型</strong>。</p><p>在<strong>ip-per-pod</strong>模型中每一个pod在集群中保持唯一性，我们不需要<strong>显式</strong>地在每个 <code>Pod</code> 之间创建链接， 不需要处理容器端口到主机端口之间的映射。从端口分配、命名、服务发现、 负载均衡、应用配置和迁移的角度来看，<code>Pod</code> 可以被视作独立虚拟机或者物理主机。</p><p>如下图，从表面上来看两个容器在docker网络与k8s网络中与client通信形式。</p><p><img src="https://markdown-1257692304.cos.ap-nanjing.myqcloud.com/markdown_img/ip-per-pod.png" alt="ip-per-pod"></p><p>k8s是一套庞大的分布式系统，为了保持核心功能的精简（模块化）以及适应不同业务用户的网络环境，k8s通过CNI(Container Network Interface)即容器网络接口集成各种网络方案。这些网络方案必须符合k8s网络模型要求：</p><ul><li>节点上的 Pod 可以不通过 NAT 和其他任何节点上的 Pod 通信</li><li>节点上的代理（比如：系统守护进程、kubelet）可以和节点上的所有Pod通信</li></ul><p>备注：仅针对那些支持 <code>Pods</code> 在主机网络中运行的平台（比如：Linux）：</p><ul><li>那些运行在节点的主机网络里的 Pod 可以不通过 NAT 和所有节点上的 Pod 通信</li></ul><p>如此操作，是不是有点像美团？将配送业务外包（CNI）给三方公司（实现方案），骑手是通过哪种飞机大炮（网络）送餐的我不管，只要符合准时、不撒漏（模型要求）等相关规矩这就是一次合格的配送。</p><p> CNI 做两件事，容器创建时的网络分配，和当容器被删除时释放网络资源。 常用的 CNI 实现方案有 Flannel、Calico、Weave以及各种云厂商根据自身网络推出的CNI插件如华为的 CNI-Genie、阿里云Terway。关于各实现方案的原理不是本次讨论重点，有机会单独写一篇。</p><hr><h4 id="pod内容器通信"><a href="#pod内容器通信" class="headerlink" title="pod内容器通信"></a>pod内容器通信</h4><p>Pod内容器非常简单，在同一个 Pod 内，所有容器共享存储、网络即使用同一个 IP 地址和端口空间，并且可以通过 <code>localhost</code> 发现对方。Pod 使用了一个中间容器 Infra，Infra 在 Pod 中首先被创建，而其他容器则通过 Join Network Namespace 的方式与 Infra 容器关联在一起。</p><p><img src="https://markdown-1257692304.cos.ap-nanjing.myqcloud.com/markdown_img/pod-network.png" alt="pod-network"></p><p>我们有一个pod包含busybox、nginx这两个容器</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kubectl get pod -n training</span><br><span class="line">NAME                             READY   STATUS    RESTARTS   AGE</span><br><span class="line">pod-localhost-765b965cfc-8sh76   2/2     Running   0          2m56s</span><br></pre></td></tr></table></figure><p>在busybox中使用telnet连接nginx容器的 80端口看看。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">kubectl exec -it  pod-localhost-765b965cfc-8sh76 -c container-si1nrb -n training -- /bin/sh</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> telnet localhost 80</span></span><br><span class="line">Connected to localhost</span><br></pre></td></tr></table></figure><p>一个pod有多个容器时可以通过-c指定进入的容器名（通过describe查看容器名称），显然通过localhost就可以轻松访问到同一个pod中的nginx容器80端口。这也是在许多关系密切的应用中通常会部署在同一个pod中。</p><hr><h4 id="pod与pod通信"><a href="#pod与pod通信" class="headerlink" title="pod与pod通信"></a>pod与pod通信</h4><ol><li><strong>pod在同一主机</strong></li></ol><p>我们通过node选择器将两个pod调度到同一个node中</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">...</span></span><br><span class="line"><span class="attr">nodeSelector:</span></span><br><span class="line">       <span class="attr">kubernetes.io/hostname:</span> <span class="string">node2</span></span><br><span class="line"><span class="string">...</span></span><br></pre></td></tr></table></figure><p>两个容器分别获得一个IP地址，同样通过IP地址双方网络正常互通。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> kubectl get pod -o wide -n training</span> </span><br><span class="line">NAME                                  READY   STATUS    RESTARTS   AGE     IP              NODE                    NOMINATED NODE   READINESS GATES</span><br><span class="line"></span><br><span class="line">pod-to-pod-64444686ff-w7c4g           1/1     Running   0          6m53s   100.82.98.206   node2        &lt;none&gt;           &lt;none&gt;</span><br><span class="line">pod-to-pod-busybox-7b9db67bc6-tl27c   1/1     Running   0          5m3s    100.82.98.250   node2        &lt;none&gt;           &lt;none&gt;</span><br><span class="line"><span class="meta">#</span><span class="bash"> kubectl <span class="built_in">exec</span> -it  pod-to-pod-busybox-7b9db67bc6-tl27c  -n training -- /bin/sh</span></span><br><span class="line"><span class="meta">/#</span><span class="bash"> telnet 100.82.98.206 80</span></span><br><span class="line">Connected to 100.82.98.206</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>同一主机网络的pod互通和我们之前学习的docker bridge相似，通过linux网桥添加虚拟设备对<strong>veth pair</strong>连接容器和主机主机命名空间。具体可查看文章《docker容器网络bridge》。</p><p>我们把之前的图拿过来，在k8s中只不过把灰色部分替换成CNI方案实现。</p><p><img src="https://markdown-1257692304.cos.ap-nanjing.myqcloud.com/markdown_img/CNI-B.png" alt="CNI-B"></p><ol start="2"><li><strong>pod在不同主机</strong></li></ol><p>此时我们的pod分布如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">kubectl get pod -o wide -n training </span><br><span class="line">NAME                                        READY   STATUS    RESTARTS   AGE    IP              NODE                    NOMINATED NODE   READINESS GATES</span><br><span class="line"></span><br><span class="line">pod-to-pod-64444686ff-w7c4g                 1/1     Running   0          104m   100.82.98.206   node2        &lt;none&gt;           </span><br><span class="line"></span><br><span class="line">pod-to-pod-busybox-node2-6476f7b7f9-mqcw9   1/1     Running   0          42s    100.91.48.208   node3        &lt;none&gt;    </span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> kubectl <span class="built_in">exec</span> -it  pod-to-pod-busybox-node2-6476f7b7f9-mqcw9  -n training -- /bin/sh</span></span><br><span class="line">/ # telnet 100.82.98.206 80</span><br><span class="line">Connected to 100.82.98.206</span><br></pre></td></tr></table></figure><p>pod在不同主机的通信依赖于<strong>CNI</strong>插件，这里我们以Calico为例的做简单了解，从Calico架构图中可以看到每个node节点的自身依然采用容器网络模式，Calico在每个节点都利用Linux 内核实现了一个高效的虚拟路由器vRouter来负责数据转发。每个虚拟路由器将路由信息广播到网络中，并添加路由转发规则。同时基于iptables还提供了丰富的网络策略，实现k8s的Network Policy策略，提供容器间网络可达性限制的功能。</p><p><strong>简单理解就是通过在主机上启动虚拟路由器(calico node)，将每个主机作为路由器使用实现互联互通的网络拓扑。</strong></p><p><strong>Calico节点组网时可以直接利用数据中心的网络结构(L2或者L3)，不需要额外的NAT、隧道或者Overlay Network，没有额外的封包解包，能够节约CPU运算，提高网络效率。</strong></p><p><img src="https://markdown-1257692304.cos.ap-nanjing.myqcloud.com/markdown_img/calico.png" alt="calico"></p><hr><h4 id="pod与service通信"><a href="#pod与service通信" class="headerlink" title="pod与service通信"></a>pod与service通信</h4><p>我们知道在k8s中容器随时可能被摧毁，pod的IP显然不是持久的，会随着扩展或缩小应用规模、或者应用程序崩溃以及节点重启等而消失和出现。service 设计就是来处理这个问题。service可以管理一组 Pod 的状态，允许我们跟踪一组随时间动态变化的 Pod IP 地址。而客户端只需要知道service这个不变的虚拟IP就可以了。</p><p>我们先来看看典型的service与pod使用，我们创建了一个service，标签选择器为app:nginx，将会路由到app=nginx标签的Pod上。</p><p><img src="https://markdown-1257692304.cos.ap-nanjing.myqcloud.com/markdown_img/service.png" alt="service"></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> kubectl get service -n training</span></span><br><span class="line">NAME               TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)    AGE</span><br><span class="line">training-service   ClusterIP   10.96.229.238   &lt;none&gt;        8881/TCP   10m</span><br></pre></td></tr></table></figure><p>Service对外暴露的端口8881,这样在集群的中的pod即可通过8881访问到与service 绑定的label为app=nginx的pod</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">kubectl run -it --image nginx:alpine curl --rm /bin/sh</span><br><span class="line">/ # curl 10.96.229.238:8881</span><br><span class="line">&lt;!DOCTYPE html&gt;</span><br><span class="line">&lt;html&gt;</span><br><span class="line">&lt;head&gt;</span><br><span class="line">&lt;title&gt;Welcome to nginx!&lt;/title&gt;</span><br><span class="line">&lt;style&gt;</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>其实大多数时候在自动化部署服务时并不知道service ip，所以另一种常见方式通过DNS进行域名解析后，可以使用<strong>“ServiceName:Port”</strong>访问Service，可以自己尝试一下。</p><p><strong>service 是如何做到服务发现的？</strong></p><p>Endpoints是k8s中的一种资源对象，k8s通过Endpoints监控到Pod的IP，service又关联Endpoints从而实现Pod的发现。大致如下图所示，service的发现机制我们会在后面文章中做深入了解。</p><p><img src="https://markdown-1257692304.cos.ap-nanjing.myqcloud.com/markdown_img/endpoints.png" alt="endpoints"></p><hr><h4 id="外网与service通信"><a href="#外网与service通信" class="headerlink" title="外网与service通信"></a>外网与service通信</h4><p>其实所谓外网通信也是service的表现形式。</p><p>service几种类型和不同用途。</p><ul><li>ClusterIP：用于在集群内部互相访问的场景，通过ClusterIP访问Service，即我们上面所说的pod与service。</li><li>NodePort：用于从集群外部访问的场景，通过节点上的端口访问Service。</li><li>LoadBalancer：用于从集群外部访问的场景，其实是NodePort的扩展，通过一个特定的LoadBalancer访问Service，这个LoadBalancer将请求转发到节点的NodePort，而外部只需要访问LoadBalancer。</li><li>None：用于Pod间的互相发现，这种类型的Service又叫Headless Service。</li></ul><p>我们先来看NodePort：</p><p><img src="https://markdown-1257692304.cos.ap-nanjing.myqcloud.com/markdown_img/service-nodeport.png" alt="service-nodeport"></p><p>我们在service中指定<strong>type: NodePort</strong>创建出的service将会包含一个在所有node 开放的端口30678，这样我们访问任意节点IP:30678即可访问到我们的pod</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> kubectl get service -n training</span></span><br><span class="line">NAME               TYPE       CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE</span><br><span class="line">training-service   NodePort   10.96.229.238   &lt;none&gt;        8881:30678/TCP   55m</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> curl 192.168.1.86:30678</span></span><br><span class="line">&lt;!DOCTYPE html&gt;</span><br><span class="line">&lt;html&gt;</span><br><span class="line">&lt;head&gt;</span><br><span class="line">&lt;title&gt;Welcome to nginx!&lt;/title&gt;</span><br><span class="line">&lt;style&gt;</span><br><span class="line">....</span><br></pre></td></tr></table></figure><p>LoadBalancer类型和它名字一样，为负载均衡而生。它的结构如下图所示，</p><p><img src="https://markdown-1257692304.cos.ap-nanjing.myqcloud.com/markdown_img/loadbalancer.png" alt="loadbalancer"></p><p>LoadBalancer本身不是属于Kubernetes的组件，如果使用云厂商的容器服务。通常会提供一套他们的负载均衡服务比如阿里云ACK的SLB、华为云的ELB等等。Service是基于四层TCP和UDP协议转发的，而k8s 另外一种资源对象Ingress可以基于七层的HTTP和HTTPS协议转发，可通过域名和路径做到更细粒度的划分，这是后话。</p><hr><p><strong>希望小作文对你有些许帮助，如果内容有误请指正。</strong></p><p><strong>您可以随意转载、修改、发布本文，无需经过本人同意。</strong> 通过博客阅读：<a href="https://iqsing.github.io/">iqsing.github.io</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;在k8s中，我们的应用会以pod的形式被调度到各个node节点上，在设计集群如何处理容器之间的网络时是一个不小的挑战，今天我们会从pod（应用）通信来展开关于k8s网络的讨论。&lt;/p&gt;
&lt;p&gt;小作文包含如下内容：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;k8s网络模型与实现方案&lt;/li&gt;</summary>
      
    
    
    
    <category term="k8s" scheme="https://iqsing.github.io/categories/k8s/"/>
    
    
    <category term="network" scheme="https://iqsing.github.io/tags/network/"/>
    
  </entry>
  
  <entry>
    <title>k8s关于Job与Cronjob</title>
    <link href="https://iqsing.github.io/2021/10/24/k8s%20%E5%85%B3%E4%BA%8EJob%E4%B8%8ECronjob/"/>
    <id>https://iqsing.github.io/2021/10/24/k8s%20%E5%85%B3%E4%BA%8EJob%E4%B8%8ECronjob/</id>
    <published>2021-10-23T16:47:21.000Z</published>
    <updated>2022-02-04T05:16:11.944Z</updated>
    
    <content type="html"><![CDATA[<p>在Kubernetes 中通过创建工作负载资源 Job 可完成大型计算以及一些批处理任务。比如 Job 转码文件、获取部分文件和目录，机器学习中的训练任务等。这篇小作文我们一起来了解 k8s 中关于 job、cronjob 的内容。</p><hr><h3 id="Job创建"><a href="#Job创建" class="headerlink" title="Job创建"></a>Job创建</h3><p>我们可以通过API版本 <code>batch/v1</code>创建出一个简单的k8s Job</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#new-job.yml</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">batch/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Job</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">command-job</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">command-job</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">busybox</span></span><br><span class="line">        <span class="attr">command:</span> [<span class="string">&quot;/bin/sh&quot;</span>,<span class="string">&quot;-c&quot;</span>,<span class="string">&quot;sleep 5;echo &#x27;job one&#x27;&quot;</span>]</span><br><span class="line">      <span class="attr">restartPolicy:</span> <span class="string">Never</span></span><br></pre></td></tr></table></figure><p>Job对象 将会启动一个pod用于完成我们的工作–睡眠5s，接着输出 job one</p><p>应用job定义，查看job工作工作状态：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kubectl apply -f new-job.yml</span> </span><br><span class="line">job.batch/command-job created</span><br></pre></td></tr></table></figure><p><img src="https://markdown-1257692304.cos.ap-nanjing.myqcloud.com/markdown_img/image-20211023220152228.png" alt="image-20211023220152228"></p><p>任务完成后，pod状态被置为Completed：</p><p><img src="https://markdown-1257692304.cos.ap-nanjing.myqcloud.com/markdown_img/image-20211023220112509.png" alt="image-20211023220112509"></p><p>通过logs查看我们的任务执行结果：</p><p><img src="https://markdown-1257692304.cos.ap-nanjing.myqcloud.com/markdown_img/image-20211023220329267.png" alt="image-20211023220329267"></p><hr><h3 id="Job重启与失败认定"><a href="#Job重启与失败认定" class="headerlink" title="Job重启与失败认定"></a>Job重启与失败认定</h3><p>在上面我们的例子中，job pod顺利的完成了我们的任务。当pod在执行作业时，容器可能会由于一些原因启动失败，比如进程以非0代码退出或超出内存限制等。在pod模板中可以通过<code>restartPolicy</code>控制job pod的重启策略。</p><p><strong>重启策略（restartPolicy）：</strong></p><ul><li>Never：pod启动失败时不会重启，而是通过<code>job-controller</code>重新创建pod供节点调度。</li><li>OnFailure：pod将会在节点重启执行任务。</li></ul><p><strong>失败回退策略（backoffLimit）：</strong></p><p>当Job pod 经过多次重启无果，显然我们应该认定这个Job是一个失败任务，默认失败认定重启次数为6，我们可以通过在spec中添加<code>backoffLimit</code>来改变这一认定。</p><p>我们调整new-job.yml如下：</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#new-job.yml</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">batch/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Job</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">command-job-two</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">command-job-two</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">busybox</span></span><br><span class="line">        <span class="attr">command:</span> [<span class="string">&quot;/bin/sh&quot;</span>,<span class="string">&quot;-c&quot;</span>,<span class="string">&quot;sleep 5;echo &#x27;job two&#x27;;exit 1&quot;</span>]</span><br><span class="line">      <span class="attr">restartPolicy:</span> <span class="string">Never</span></span><br><span class="line">  <span class="attr">backoffLimit:</span> <span class="number">2</span></span><br></pre></td></tr></table></figure><p>我们通过<code>describe</code>查看创建的Job</p><p><img src="https://markdown-1257692304.cos.ap-nanjing.myqcloud.com/markdown_img/image-20211023224555309.png" alt="image-20211023224555309"></p><p><code>job-controller</code>经过2次重建pod达到阈值，<code>job-controller</code>认定本次Job为失败工作流。</p><p><img src="https://markdown-1257692304.cos.ap-nanjing.myqcloud.com/markdown_img/image-20211023223943399.png" alt="image-20211023223943399"></p><p>在重启策略为<code>Never</code>时，认定失败的Job会将pod遗留在节点上。</p><hr><h3 id="Job-期限与清理"><a href="#Job-期限与清理" class="headerlink" title="Job 期限与清理"></a>Job 期限与清理</h3><p>除了Job执行结束与重启失败认定的Job 终止外还可以通过配置活跃期限（activeDeadlineSeconds）来自动停止Job任务。</p><p> 我们可以为 Job 的 <code>.spec.activeDeadlineSeconds</code> 设置一个秒数值。 该值适用于 Job 的整个生命期，无论 Job 创建了多少个 Pod。 一旦 Job 运行时间达到 <code>activeDeadlineSeconds</code> 秒，其所有运行中的 Pod 都会被终止，并且 Job 的状态更新为 <code>type: Failed</code> 及 <code>reason: DeadlineExceeded</code>。</p><p>注意 Job 的 <code>.spec.activeDeadlineSeconds</code> 优先级高于其 <code>.spec.backoffLimit</code> 设置。 因此，如果一个 Job 正在重试一个或多个失效的 Pod，该 Job 一旦到达 <code>activeDeadlineSeconds</code> 所设的时限即不再部署额外的 Pod，即使其重试次数还未 达到 <code>backoffLimit</code> 所设的限制。</p><p>调整new-job.yml如下：</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#new-job.yml</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">batch/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Job</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">command-job-three</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">command-job-three</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">busybox</span></span><br><span class="line">        <span class="attr">command:</span> [<span class="string">&quot;/bin/sh&quot;</span>,<span class="string">&quot;-c&quot;</span>,<span class="string">&quot;sleep 50;echo &#x27;job three&#x27;&quot;</span>]</span><br><span class="line">      <span class="attr">restartPolicy:</span> <span class="string">Never</span></span><br><span class="line">  <span class="attr">backoffLimit:</span> <span class="number">2</span></span><br><span class="line">  <span class="attr">activeDeadlineSeconds:</span> <span class="number">10</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>虽然是50s的任务，但是由于<code>activeDeadlineSeconds</code>的限制,Job运行10s后被终止</p><p><img src="https://markdown-1257692304.cos.ap-nanjing.myqcloud.com/markdown_img/image-20211023231642032.png" alt="image-20211023231642032"></p><p>清理job和终止相似，我们可以通过添加<code>spec.ttlSecondsAfterFinished</code>使Job在任务完成后一段时间内被清理，读者感兴趣可动手尝试一下。</p><hr><h3 id="Job-任务类型"><a href="#Job-任务类型" class="headerlink" title="Job 任务类型"></a>Job 任务类型</h3><ul><li><p><strong>非并行 Job</strong></p><p>通常只启动一个 Pod，除非该 Pod 失败，Pod中应用成功运行完成即视为Job任务为完成状态，我们上面讨论的任务即属于此类。</p></li><li><p>**并行 Job **</p><ul><li><p><strong>指定任务数的并行 Job</strong></p><p>通过<strong>spec.completions</strong>指定任务数，一旦所有 Pod 成功完成它的任务. 作业将完成。</p><p>我们添加一个new-jobs.yml，并指定completions为3</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">batch/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Job</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">command-jobs</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">command-jobs</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">busybox</span></span><br><span class="line">        <span class="attr">command:</span> [<span class="string">&quot;/bin/sh&quot;</span>,<span class="string">&quot;-c&quot;</span>,<span class="string">&quot;sleep 50;echo &#x27;jobs &#x27;&quot;</span>]</span><br><span class="line">      <span class="attr">restartPolicy:</span> <span class="string">Never</span></span><br><span class="line">  <span class="attr">backoffLimit:</span> <span class="number">2</span></span><br><span class="line">  <span class="attr">completions:</span> <span class="number">3</span></span><br></pre></td></tr></table></figure><p>当3个Pod都运行完成时，Job状态为成功执行。</p></li></ul><p><img src="https://markdown-1257692304.cos.ap-nanjing.myqcloud.com/markdown_img/image-20211023235914663.png" alt="image-20211023235914663"></p><p>   我们可以从Job pod 运行过程中看到次模式中Pod 创建存在先后顺序，即需要等待一个job完成后，开启下一个Job的运行。</p><ul><li><p><strong>工作队列式的并行 Job</strong></p><p>一旦一个 Pod 成功终止则所有 Pod 都都终止，此时Job 成功完成。</p><p>修改new-jobs.yml，并添加parallelism使其并行数为5</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">batch/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Job</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">command-jobs</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">command-jobs</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">busybox</span></span><br><span class="line">        <span class="attr">command:</span> [<span class="string">&quot;/bin/sh&quot;</span>,<span class="string">&quot;-c&quot;</span>,<span class="string">&quot;sleep 50;echo &#x27;jobs &#x27;&quot;</span>]</span><br><span class="line">      <span class="attr">restartPolicy:</span> <span class="string">Never</span></span><br><span class="line">  <span class="attr">backoffLimit:</span> <span class="number">2</span></span><br><span class="line">  <span class="attr">parallelism:</span> <span class="number">5</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>此类Job Pod在同一时间创建和结束。</p><p><img src="https://markdown-1257692304.cos.ap-nanjing.myqcloud.com/markdown_img/image-20211024005056600.png" alt="image-20211024005056600"></p></li></ul></li></ul><hr><h3 id="Cronjob周期性任务"><a href="#Cronjob周期性任务" class="headerlink" title="Cronjob周期性任务"></a>Cronjob周期性任务</h3><p>CronJob 用于执行周期性的动作，例如备份、邮件、报告生成等。</p><p>cron时间配置与linux crontab相似。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">#      ┌────────────────── 时区 (可选)</span><br><span class="line">#      |      ┌───────────── 分钟 (0 - 59)</span><br><span class="line">#      |      │ ┌───────────── 小时 (0 - 23)</span><br><span class="line">#      |      │ │ ┌───────────── 月的某天 (1 - 31)</span><br><span class="line">#      |      │ │ │ ┌───────────── month (1 - 12)</span><br><span class="line">#      |      │ │ │ │ ┌───────────── 周的某天 (0 - 6)（周日到周一；在某些系统上，7 也是星期日）</span><br><span class="line">#      |      │ │ │ │ │                                </span><br><span class="line">#      |      │ │ │ │ │</span><br><span class="line">#      |      │ │ │ │ │</span><br><span class="line"># CRON_TZ=UTC * * * * *</span><br></pre></td></tr></table></figure><p>添加cronjob.yml如下：</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#cronjob.yml</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">batch/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">CronJob</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">cronjob</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">schedule:</span> <span class="string">&quot;*/1 * * * *&quot;</span></span><br><span class="line">  <span class="attr">jobTemplate:</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">template:</span></span><br><span class="line">        <span class="attr">spec:</span></span><br><span class="line">          <span class="attr">containers:</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">cronjob</span></span><br><span class="line">            <span class="attr">image:</span> <span class="string">busybox</span></span><br><span class="line">            <span class="attr">command:</span> [<span class="string">&quot;/bin/sh&quot;</span>,<span class="string">&quot;-c&quot;</span>,<span class="string">&quot;date&quot;</span>]</span><br><span class="line">          <span class="attr">restartPolicy:</span> <span class="string">Never</span></span><br></pre></td></tr></table></figure><p>我们通过cronjob没隔一分钟打印一次日期。</p><p>查看cronjob信息：</p><p><img src="https://markdown-1257692304.cos.ap-nanjing.myqcloud.com/markdown_img/image-20211024013232637.png" alt="image-20211024013232637"></p><p>通过logs查看任务结果：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[docker@localhost yml]$ kubectl logs cronjob-1635010680-n5gxj</span><br><span class="line">Sat Oct 23 17:38:15 UTC 2021</span><br></pre></td></tr></table></figure><p>cronjob可以自动清理任务，默认保留3次成功的任务，我们可以通过添加<code>.spec.successfulJobsHistoryLimit</code>改变保留的历史任务信息即Pod。</p><hr><p>以上我们将k8s中Job、Cronjob涉及的大部分内容进行了介绍。</p><p>参考：</p><p><a href="https://kubernetes.io/zh/docs/concepts/workloads/controllers/job/">Job</a></p><p><a href="https://kubernetes.io/docs/tasks/job/automated-tasks-with-cron-jobs/">Running Automated Tasks with a CronJob</a></p><p><strong>希望小作文对你有些许帮助，如果内容有误请指正。</strong></p><p><strong>您可以随意转载、修改、发布本文，无需经过本人同意。亦可通过博客阅读本文</strong>：<a href="https://iqsing.github.io/">iqsing.github.io</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;在Kubernetes 中通过创建工作负载资源 Job 可完成大型计算以及一些批处理任务。比如 Job 转码文件、获取部分文件和目录，机器学习中的训练任务等。这篇小作文我们一起来了解 k8s 中关于 job、cronjob 的内容。&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&quot;Job</summary>
      
    
    
    
    <category term="k8s" scheme="https://iqsing.github.io/categories/k8s/"/>
    
    
    <category term="job" scheme="https://iqsing.github.io/tags/job/"/>
    
  </entry>
  
  <entry>
    <title>k8s DaemonSet 介绍与实例</title>
    <link href="https://iqsing.github.io/2021/10/21/k8s%20DaemonSet%20%E4%BB%8B%E7%BB%8D%E4%B8%8E%E5%AE%9E%E4%BE%8B/"/>
    <id>https://iqsing.github.io/2021/10/21/k8s%20DaemonSet%20%E4%BB%8B%E7%BB%8D%E4%B8%8E%E5%AE%9E%E4%BE%8B/</id>
    <published>2021-10-20T16:47:21.000Z</published>
    <updated>2022-02-04T05:16:11.918Z</updated>
    
    <content type="html"><![CDATA[<p> 我们之前说k8s中使用deployment、statefulset工作负载资源来分别维护无状态和有状态应用。这篇小作文我们会学习如何使用<code>DaemonSet</code>来维护一个守护进程（应用）。</p><hr><h4 id="一、DaemonSet是什么？"><a href="#一、DaemonSet是什么？" class="headerlink" title="一、DaemonSet是什么？"></a>一、DaemonSet是什么？</h4><p><em>DaemonSet</em> 是一个<strong>确保全部或者某些节点上必须运行一个 Pod的工作负载资源（守护进程），当有节点加入集群时， 也会为他们新增一个 Pod。</strong></p><p>下面是常用的使用案例：</p><ul><li>集群守护进程，如<code>Kured</code>、<code>node-problem-detector</code></li><li>日志收集守护进程，如<code>fluentd</code>、<code>logstash</code></li><li>监控守护进程，如promethues <code>node-exporter</code></li></ul><p><strong>通过创建<em>DaemonSet</em> 可以确保 守护进程pod 被调度到每个可用节点上运行。</strong></p><hr><h4 id="二、DaemonSet-如何工作？"><a href="#二、DaemonSet-如何工作？" class="headerlink" title="二、DaemonSet 如何工作？"></a>二、DaemonSet 如何工作？</h4><p>DaemonSet 是由控制器（controller manager）管理的 Kubernetes 工作资源对象。我们通过声明一个想要的daemonset状态，表明每个节点上都需要有一个特定的 Pod。协调控制回路会比较期望状态和当前观察到的状态。如果观察到的节点没有匹配的 Pod，DaemonSet controller将自动创建一个。可以参考之前《k8s工作流程详解》</p><p>在这个过程包括现有节点和所有新创建的节点。不过DaemonSet 控制器创建的 Pod 会被Kubernetes 调度器忽略，即DaemonSet Pods 由 DaemonSet 控制器创建和调度。这样带来的两个微妙的问题：</p><ul><li>Pod 行为的不一致性：正常 Pod 在被创建后等待调度时处于 <code>Pending</code> 状态， DaemonSet Pods 创建后不会处于 <code>Pending</code> 状态下。</li><li>Pod 抢占行为由默认调度器处理。启用抢占后，DaemonSet 控制器将在不考虑 Pod 优先级和抢占 的情况下制定调度决策。</li></ul><p>所以在k8s v1.12以后DaemonSet Controller 将会向 DaemonSet 的 Pod 添加 <code>.spec.nodeAffinity</code> 字段，而不是 <code>.spec.nodeName</code> 字段，并进一步由 kubernetes 调度器将 Pod 绑定到目标节点。如果 DaemonSet 的 Pod 已经存在了 <code>nodeAffinity</code> 字段，该字段的值将被替换。</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">nodeAffinity:</span></span><br><span class="line">  <span class="attr">requiredDuringSchedulingIgnoredDuringExecution:</span></span><br><span class="line">    <span class="attr">nodeSelectorTerms:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">matchFields:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">metadata.name</span></span><br><span class="line">        <span class="attr">operator:</span> <span class="string">In</span></span><br><span class="line">        <span class="attr">values:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">target-host-name</span></span><br></pre></td></tr></table></figure><p><strong>daemonset pod的默认容忍规则如下：</strong></p><p><img src="https://markdown-1257692304.cos.ap-nanjing.myqcloud.com/markdown_img/image-20211021134258976.png" alt="image-20211021134258976"></p><p>DaemonSet 默认在每个节点上创建一个 Pod。当然也可以使用节点选择器来限制可接受节点的数量。DaemonSet 控制器将仅在与 YAML 文件中预定义的nodeSelector字段匹配的节点上创建Pod。我们在下面会使用到。</p><hr><h4 id="三、DaemonSet实例"><a href="#三、DaemonSet实例" class="headerlink" title="三、DaemonSet实例"></a>三、DaemonSet实例</h4><h4 id="创建DaemonSet"><a href="#创建DaemonSet" class="headerlink" title="创建DaemonSet"></a>创建DaemonSet</h4><p>我们只需要将前面deployment中的<code>kind</code>调整为DaemonSet 就可以创建出一个DaemonSet守护进程</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span> </span><br><span class="line"><span class="attr">kind:</span> <span class="string">DaemonSet</span> </span><br><span class="line"><span class="attr">metadata:</span> </span><br><span class="line">  <span class="attr">name:</span> <span class="string">my-daemonset</span></span><br><span class="line"><span class="attr">spec:</span> </span><br><span class="line">  <span class="attr">selector:</span> </span><br><span class="line">    <span class="attr">matchLabels:</span> </span><br><span class="line">      <span class="attr">app:</span> <span class="string">my-daemon</span></span><br><span class="line">  <span class="attr">template:</span> </span><br><span class="line">    <span class="attr">metadata:</span> </span><br><span class="line">      <span class="attr">labels:</span> </span><br><span class="line">        <span class="attr">app:</span> <span class="string">my-daemon</span></span><br><span class="line">    <span class="attr">spec:</span> </span><br><span class="line">      <span class="attr">containers:</span> </span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">daemonset-container</span> </span><br><span class="line">          <span class="attr">image:</span> <span class="string">httpd</span> </span><br><span class="line">          <span class="attr">ports:</span> </span><br><span class="line">          <span class="bullet">-</span> <span class="attr">containerPort :</span> <span class="number">80</span></span><br></pre></td></tr></table></figure><p>通过apply应用后查看资源状态</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kubectl get daemonset</span></span><br><span class="line">NAME            DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR            AGE</span><br><span class="line">my-daemonset    1         1         1       1            1           &lt;none&gt;                   10m</span><br></pre></td></tr></table></figure><p>由于我们minikube只有一个node 所以只建立了一个副本，在节点通过get查看到已创建出这个daemonset pod</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kubectl get pod</span> </span><br><span class="line">NAME                  READY   STATUS    RESTARTS   AGE</span><br><span class="line">my-daemonset-97z2g    1/1     Running   0          10m</span><br></pre></td></tr></table></figure><p>在daemonset资源状态中可以看到<code>NODE SELECTOR</code>的值为<code>none</code>，显然我们可以通过在pod模板中添加<code>nodeSelector</code>使DaemonSet 控制器仅在与Node 选择算符匹配的节点上创建出pod，接下来我们添加一个<code>nodeSelector</code></p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span> </span><br><span class="line"><span class="attr">kind:</span> <span class="string">DaemonSet</span> </span><br><span class="line"><span class="attr">metadata:</span> </span><br><span class="line">  <span class="attr">name:</span> <span class="string">my-daemonset</span></span><br><span class="line"><span class="attr">spec:</span> </span><br><span class="line">  <span class="attr">selector:</span> </span><br><span class="line">    <span class="attr">matchLabels:</span> </span><br><span class="line">      <span class="attr">app:</span> <span class="string">my-daemon</span></span><br><span class="line">  <span class="attr">template:</span> </span><br><span class="line">    <span class="attr">metadata:</span> </span><br><span class="line">      <span class="attr">labels:</span> </span><br><span class="line">        <span class="attr">app:</span> <span class="string">my-daemon</span></span><br><span class="line">    <span class="attr">spec:</span> </span><br><span class="line">      <span class="attr">containers:</span> </span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">daemonset-container</span> </span><br><span class="line">          <span class="attr">image:</span> <span class="string">httpd</span> </span><br><span class="line">          <span class="attr">ports:</span> </span><br><span class="line">          <span class="bullet">-</span> <span class="attr">containerPort :</span> <span class="number">80</span></span><br><span class="line">      <span class="attr">nodeSelector:</span></span><br><span class="line">       <span class="attr">kubernetes.io/hostname:</span> <span class="string">minikube</span> </span><br></pre></td></tr></table></figure><p>这样我们的pod只会在hostname为minikube的Node上创建DaemonSet守护进程的pod</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kubectl get daemonset</span></span><br><span class="line">NAME            DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR                     AGE</span><br><span class="line">my-daemonset    1         1         1       1            1           kubernetes.io/hostname=minikube   30m</span><br></pre></td></tr></table></figure><p>除了通过<code>nodeSelector</code>来控制节点调度外，还可以通过上面提到的容忍策略即<code>tolerations</code>使daemonset pod 调度到“非正常“Node。</p><p>我们可以来看一个<code>fluentd</code>的官方<strong>elasticsearch</strong> daemonset </p><p>源文件地址：<a href="https://github.com/fluent/fluentd-kubernetes-daemonset/blob/master/fluentd-daemonset-elasticsearch.yaml">fluentd-daemonset-elasticsearch.yaml</a></p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">DaemonSet</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">fluentd</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">kube-system</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">k8s-app:</span> <span class="string">fluentd-logging</span></span><br><span class="line">    <span class="attr">version:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">k8s-app:</span> <span class="string">fluentd-logging</span></span><br><span class="line">      <span class="attr">version:</span> <span class="string">v1</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">k8s-app:</span> <span class="string">fluentd-logging</span></span><br><span class="line">        <span class="attr">version:</span> <span class="string">v1</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">tolerations:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">node-role.kubernetes.io/master</span></span><br><span class="line">        <span class="attr">effect:</span> <span class="string">NoSchedule</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">fluentd</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">fluent/fluentd-kubernetes-daemonset:v1-debian-elasticsearch</span></span><br><span class="line">        <span class="attr">env:</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">name:</span>  <span class="string">FLUENT_ELASTICSEARCH_HOST</span></span><br><span class="line">            <span class="attr">value:</span> <span class="string">&quot;elasticsearch-logging&quot;</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">name:</span>  <span class="string">FLUENT_ELASTICSEARCH_PORT</span></span><br><span class="line">            <span class="attr">value:</span> <span class="string">&quot;9200&quot;</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">FLUENT_ELASTICSEARCH_SCHEME</span></span><br><span class="line">            <span class="attr">value:</span> <span class="string">&quot;http&quot;</span></span><br><span class="line">          <span class="comment"># Option to configure elasticsearch plugin with self signed certs</span></span><br><span class="line">          <span class="comment"># ================================================================</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">FLUENT_ELASTICSEARCH_SSL_VERIFY</span></span><br><span class="line">            <span class="attr">value:</span> <span class="string">&quot;true&quot;</span></span><br><span class="line">          <span class="comment"># Option to configure elasticsearch plugin with tls</span></span><br><span class="line">          <span class="comment"># ================================================================</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">FLUENT_ELASTICSEARCH_SSL_VERSION</span></span><br><span class="line">            <span class="attr">value:</span> <span class="string">&quot;TLSv1_2&quot;</span></span><br><span class="line">          <span class="comment"># X-Pack Authentication</span></span><br><span class="line">          <span class="comment"># =====================</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">FLUENT_ELASTICSEARCH_USER</span></span><br><span class="line">            <span class="attr">value:</span> <span class="string">&quot;elastic&quot;</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">FLUENT_ELASTICSEARCH_PASSWORD</span></span><br><span class="line">            <span class="attr">value:</span> <span class="string">&quot;changeme&quot;</span></span><br><span class="line">          <span class="comment"># Logz.io Authentication</span></span><br><span class="line">          <span class="comment"># ======================</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">LOGZIO_TOKEN</span></span><br><span class="line">            <span class="attr">value:</span> <span class="string">&quot;ThisIsASuperLongToken&quot;</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">LOGZIO_LOGTYPE</span></span><br><span class="line">            <span class="attr">value:</span> <span class="string">&quot;kubernetes&quot;</span></span><br><span class="line">        <span class="attr">resources:</span></span><br><span class="line">          <span class="attr">limits:</span></span><br><span class="line">            <span class="attr">memory:</span> <span class="string">200Mi</span></span><br><span class="line">          <span class="attr">requests:</span></span><br><span class="line">            <span class="attr">cpu:</span> <span class="string">100m</span></span><br><span class="line">            <span class="attr">memory:</span> <span class="string">200Mi</span></span><br><span class="line">        <span class="attr">volumeMounts:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">varlog</span></span><br><span class="line">          <span class="attr">mountPath:</span> <span class="string">/var/log</span></span><br><span class="line">        <span class="comment"># When actual pod logs in /var/lib/docker/containers, the following lines should be used.</span></span><br><span class="line">        <span class="comment"># - name: dockercontainerlogdirectory</span></span><br><span class="line">        <span class="comment">#   mountPath: /var/lib/docker/containers</span></span><br><span class="line">        <span class="comment">#   readOnly: true</span></span><br><span class="line">        <span class="comment"># When actual pod logs in /var/log/pods, the following lines should be used.</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">dockercontainerlogdirectory</span></span><br><span class="line">          <span class="attr">mountPath:</span> <span class="string">/var/log/pods</span></span><br><span class="line">          <span class="attr">readOnly:</span> <span class="literal">true</span></span><br><span class="line">      <span class="attr">terminationGracePeriodSeconds:</span> <span class="number">30</span></span><br><span class="line">      <span class="attr">volumes:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">varlog</span></span><br><span class="line">        <span class="attr">hostPath:</span></span><br><span class="line">          <span class="attr">path:</span> <span class="string">/var/log</span></span><br><span class="line">      <span class="comment"># When actual pod logs in /var/lib/docker/containers, the following lines should be used.</span></span><br><span class="line">      <span class="comment"># - name: dockercontainerlogdirectory</span></span><br><span class="line">      <span class="comment">#   hostPath:</span></span><br><span class="line">      <span class="comment">#     path: /var/lib/docker/containers</span></span><br><span class="line">      <span class="comment"># When actual pod logs in /var/log/pods, the following lines should be used.</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">dockercontainerlogdirectory</span></span><br><span class="line">        <span class="attr">hostPath:</span></span><br><span class="line">          <span class="attr">path:</span> <span class="string">/var/log/pods</span></span><br></pre></td></tr></table></figure><p>特别之处在于，为了收集master节点上的pod日志，将会容忍<code>fluentd</code>调度到master节点。其中<code>tolerations</code>如下</p><p><img src="https://markdown-1257692304.cos.ap-nanjing.myqcloud.com/markdown_img/image-20211021114701977.png" alt="image-20211021114701977"></p><h4 id="Daemon-Pods-通信"><a href="#Daemon-Pods-通信" class="headerlink" title="Daemon Pods 通信"></a>Daemon Pods 通信</h4><p>与 DaemonSet 中的 Pod 进行通信的几种模式如下：</p><ul><li><strong>推送（Push）</strong>：配置 DaemonSet 中的 Pod，将更新发送到另一个服务，例如统计数据库。 </li><li><strong>NodeIP 和已知端口</strong>：DaemonSet 中的 Pod 可以使用 <code>hostPort</code>，从而可以通过节点 IP 访问到 Pod。客户端能通过某种方法获取节点 IP 列表，并且基于此也可以获取到相应的端口。比如prometheus的node-exporter。</li><li><strong>DNS</strong>：创建具有相同 Pod 选择算符的 无头服务 通过使用 <code>endpoints</code> 资源或从 DNS 中检索到多个 A 记录来发现 DaemonSet。</li></ul><h4 id="DaemonSet-更新"><a href="#DaemonSet-更新" class="headerlink" title="DaemonSet 更新"></a>DaemonSet 更新</h4><p>如果节点的标签被修改，DaemonSet 将立刻向新匹配上的节点添加 Pod， 同时删除不匹配的节点上的 Pod。</p><p>可以删除一个 DaemonSet。如果使用 <code>kubectl</code> 指定 <code>--cascade=orphan</code> 选项， 则 Pod 将被保留在节点上。接下来如果创建使用相同选择算符的新 DaemonSet， 新的 DaemonSet 会收养已有的 Pod。 如果有 Pod 需要被替换，DaemonSet 会根据其 <code>updateStrategy</code> 来替换。</p><p>比如prometheus中的<code>node-exporter</code></p><p><img src="https://markdown-1257692304.cos.ap-nanjing.myqcloud.com/markdown_img/image-20211021121548126.png" alt="image-20211021121548126"></p><p>以上是关于k8s中的DaemonSet相关内容。</p><hr><p>参考：</p><p><a href="https://kubernetes.io/zh/docs/concepts/workloads/controllers/daemonset/">daemonset</a></p><p><a href="https://kubernetes.io/zh/docs/concepts/scheduling-eviction/assign-pod-node/#node-affinity">node-affinity</a></p><p><a href="https://github.com/prometheus-operator/kube-prometheus/blob/main/manifests/node-exporter-daemonset.yaml">node-exporter-daemonset</a></p><p><strong>希望小作文对你有些许帮助，如果内容有误请指正。</strong></p><p><strong>您可以随意转载、修改、发布本文，无需经过本人同意。通过博客阅读</strong>：<a href="https://iqsing.github.io/">iqsing.github.io</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt; 我们之前说k8s中使用deployment、statefulset工作负载资源来分别维护无状态和有状态应用。这篇小作文我们会学习如何使用&lt;code&gt;DaemonSet&lt;/code&gt;来维护一个守护进程（应用）。&lt;/p&gt;
&lt;hr&gt;
&lt;h4 id=&quot;一、DaemonSet是什么</summary>
      
    
    
    
    <category term="k8s" scheme="https://iqsing.github.io/categories/k8s/"/>
    
    
    <category term="DaemonSet" scheme="https://iqsing.github.io/tags/DaemonSet/"/>
    
  </entry>
  
  <entry>
    <title>k8s负载资源StatefulSet工作细节</title>
    <link href="https://iqsing.github.io/2021/09/27/k8s%E8%B4%9F%E8%BD%BD%E8%B5%84%E6%BA%90StatefulSet%E5%B7%A5%E4%BD%9C%E7%BB%86%E8%8A%82/"/>
    <id>https://iqsing.github.io/2021/09/27/k8s%E8%B4%9F%E8%BD%BD%E8%B5%84%E6%BA%90StatefulSet%E5%B7%A5%E4%BD%9C%E7%BB%86%E8%8A%82/</id>
    <published>2021-09-26T16:47:21.000Z</published>
    <updated>2022-02-04T05:16:12.014Z</updated>
    
    <content type="html"><![CDATA[<p>在k8s中工作负载资源StatefulSet用于管理有状态应用。</p><p><strong>什么是无状态？</strong></p><p>组成一个应用的pod是对等的，它们之前没有关联和依赖关系，不依赖外部存储。</p><p>即我们上篇小作文中deployment创建的nginx pod ，他们是完全一样的，任何一个pod 被移除后依然可以正常工作。由于不依赖外部存储，它们可以被轻易的调度到任何 node 上。</p><p><strong>什么是有状态？</strong></p><p>显然无状态的反面就是有状态了，pod之间可能包含主从、主备的相互依赖关系，甚至对启动顺序也有要求。更关键的是这些pod 需要外部存储，一旦pod被清除或调度后，怎么把pod 和原来的外部数据联系起来？这就是StatefulSet厉害的地方。</p><p><strong>StatefulSet将这些状态应用进行记录，在需要的时候恢复。</strong></p><hr><h3 id="StatefulSet如何展开这些工作"><a href="#StatefulSet如何展开这些工作" class="headerlink" title="StatefulSet如何展开这些工作?"></a>StatefulSet如何展开这些工作?</h3><h4 id="一、维护应用拓扑状态"><a href="#一、维护应用拓扑状态" class="headerlink" title="一、维护应用拓扑状态"></a>一、维护应用拓扑状态</h4><h4 id="通过dns记录为-pod-分配集群内唯一、稳定的网络标识。即只要保证pod-的名称不变，pod被调度到任何节点或者ip如何变更都能被找到。"><a href="#通过dns记录为-pod-分配集群内唯一、稳定的网络标识。即只要保证pod-的名称不变，pod被调度到任何节点或者ip如何变更都能被找到。" class="headerlink" title="通过dns记录为 pod 分配集群内唯一、稳定的网络标识。即只要保证pod 的名称不变，pod被调度到任何节点或者ip如何变更都能被找到。"></a>通过dns记录为 pod 分配集群内唯一、稳定的网络标识。即只要保证pod 的名称不变，pod被调度到任何节点或者ip如何变更都能被找到。</h4><p> 在 k8s 中Service用来来将一组 Pod 暴露给外界访问的一种机制。<strong>当创建的service 中clusterIP为None 时（headless 无头服务）， 不会进行负载均衡，也不会为该服务分配集群 IP。仅自动配置 DNS。</strong></p><p><img src="https://markdown-1257692304.cos.ap-nanjing.myqcloud.com/markdown_img/image-20210927121907615.png" alt="image-20210927121907615"></p><p>这样我们集群中的 一个pod 将被绑定到一条DNS记录：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;pod-name&gt;.&lt;svc-name&gt;.&lt;namespace&gt;.svc.cluster.local</span><br></pre></td></tr></table></figure><p>通过解析这个地址就能找到pod的IP 。</p><p>下面我们创建一个headless service，将<code>clusterIP</code>配置为<code> None</code>：</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#headless-service.yml</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">nginx-headless</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx-service-port</span></span><br><span class="line">    <span class="attr">port:</span> <span class="number">80</span></span><br><span class="line">    <span class="attr">targetPort:</span> <span class="number">9376</span></span><br><span class="line">  <span class="attr">clusterIP:</span> <span class="string">None</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">nginx</span></span><br></pre></td></tr></table></figure><p>这个service将会绑定 <code>app=nginx</code>标签的pod，我们通过<code>kubectl apply -f headless-service.yml</code>应用service 并通过get 查看：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kubectl get service</span></span><br><span class="line">NAME             TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE</span><br><span class="line">kubernetes       ClusterIP   10.96.0.1    &lt;none&gt;        443/TCP   18d</span><br><span class="line">nginx-headless   ClusterIP   None         &lt;none&gt;        80/TCP    4h48m</span><br></pre></td></tr></table></figure><p>nginx-headless 这个headless service创建成功了。接着我们创建一个StatefulSet：</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#nginx-statefulset.yml</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">StatefulSet</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">nginx-statefulset</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">serviceName:</span> <span class="string">&quot;nginx-headless&quot;</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">3</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">nginx</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">nginx</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx-web</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">nginx:1.17</span></span><br><span class="line">        <span class="attr">ports:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">82</span></span><br></pre></td></tr></table></figure><p>nginx-statefulset 将会绑定我们前面的service <code>nginx-headless</code>并创建三个nginx pod。</p><p><strong>我们查看创建的pod ,StatefulSet 中的每个 Pod 根据 StatefulSet 的名称和 Pod 的序号派生出它的主机名。同时statefulset创建出来的pod 名称以<code>$(StatefulSet name)-$(order)</code>开始编号。</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kubectl get pod</span> </span><br><span class="line">NAME                  READY   STATUS    RESTARTS   AGE</span><br><span class="line">nginx-statefulset-0   1/1     Running   0          18s</span><br><span class="line">nginx-statefulset-1   1/1     Running   0          15s</span><br><span class="line">nginx-statefulset-2   1/1     Running   0          12s</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">$</span><span class="bash"> kubectl <span class="built_in">exec</span> nginx-statefulset-0 -- sh -c hostname</span></span><br><span class="line">nginx-statefulset-0</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>其实他们的创建顺序也是从0-2，当我们删除这些pod时，statefulset 马上重建出相同名称的Pod 。</p><p>我们通过statefulset 的event可以观测到这个过程：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl describe  nginx-statefulset</span><br><span class="line">Events:</span><br><span class="line">  Type    Reason            Age    From                    Message</span><br><span class="line">  ----    ------            ----   ----                    -------</span><br><span class="line">  Normal  SuccessfulCreate  7m43s  statefulset-controller  create Pod nginx-statefulset-0 in StatefulSet nginx-statefulset successful</span><br><span class="line">  Normal  SuccessfulCreate  7m40s  statefulset-controller  create Pod nginx-statefulset-1 in StatefulSet nginx-statefulset successful</span><br><span class="line">  Normal  SuccessfulCreate  7m37s  statefulset-controller  create Pod nginx-statefulset-2 in StatefulSet nginx-statefulset successful</span><br></pre></td></tr></table></figure><p>现在我们来看一下 pod 是否存在于 DNS 记录中：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl run -it --image busybox busybox --rm /bin/sh</span><br></pre></td></tr></table></figure><p>运行一个一次性 pod busybox ，接着使用 ping 命令查询之前提到的规则构建名称<code>nginx-statefulset-0.nginx-headless.default.svc.cluster.local</code></p><p><img src="https://markdown-1257692304.cos.ap-nanjing.myqcloud.com/markdown_img/image-20210926164056933.png" alt="image-20210926164056933"></p><p>解析的IP与如下<code>nginx-statefulset-0</code>相符。</p><p><img src="https://markdown-1257692304.cos.ap-nanjing.myqcloud.com/markdown_img/image-20210926164906187.png" alt="image-20210926164906187"></p><p><strong>这样我们使用pod名称通过DNS就可以找到这个pod 再加上StatefulSet可以按顺序创建出不变名称的 pod ，即一个应用通过StatefulSet准确维护其<em>拓扑状态</em></strong></p><hr><h3 id="二、维护应用存储状态"><a href="#二、维护应用存储状态" class="headerlink" title="二、维护应用存储状态"></a>二、维护应用存储状态</h3><p><strong>k8s为应对应用的数据存储需求提供了卷的概念（volume）以及提供持久化存储的PVC（ PersistentVolumeClaim）PV（ PersistentVolume）当一个pod 和 PVC绑定后，即使pod 被移除，PVC和PV仍然保留在集群中，pod 再次被创建后会自动绑定到之前的PVC。</strong>他们看起来是这样的：</p><p><img src="https://markdown-1257692304.cos.ap-nanjing.myqcloud.com/markdown_img/rs_pv_pvc.jpg" alt="rs_pv_pvc"></p><p>这里我们以讨论statefulset持久化存储为主，对于k8s存储本身不了解的同学可以参考k8s官方文档存储章节<a href="https://kubernetes.io/zh/docs/concepts/storage/">storage</a></p><p>首先我们创建存储目录 /data/volumes/ 以及一个本地的<code>local</code>类型（使用节点上的文件或目录来模拟网络附加存储）的PV：</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#pv-local.yml</span></span><br><span class="line"></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">PersistentVolume</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">pv-local</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">capacity:</span></span><br><span class="line">    <span class="attr">storage:</span> <span class="string">5Gi</span> </span><br><span class="line">  <span class="attr">volumeMode:</span> <span class="string">Filesystem</span></span><br><span class="line">  <span class="attr">accessModes:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">ReadWriteMany</span></span><br><span class="line">  <span class="attr">persistentVolumeReclaimPolicy:</span> <span class="string">Delete</span></span><br><span class="line">  <span class="attr">storageClassName:</span> <span class="string">local-storage</span></span><br><span class="line">  <span class="attr">local:</span></span><br><span class="line">    <span class="attr">path:</span> <span class="string">/data/volumes/</span> </span><br><span class="line">  <span class="attr">nodeAffinity:</span></span><br><span class="line">    <span class="attr">required:</span></span><br><span class="line">      <span class="attr">nodeSelectorTerms:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">matchExpressions:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">kubernetes.io/hostname</span></span><br><span class="line">          <span class="attr">operator:</span> <span class="string">In</span></span><br><span class="line">          <span class="attr">values:</span></span><br><span class="line">          <span class="bullet">-</span> <span class="string">minikube</span></span><br></pre></td></tr></table></figure><p>PV是集群中的一块存储，它声明了后端使用的真实存储，通常会由K8S管理员创建。我们在<code>pv-local</code>中声明了后端存储类型为<code>local</code>挂载到目录 /data/volumes/ , 存储卷类名为<code>local-storage</code>，1Gb容量，访问模式<code>ReadWriteMany</code> – 卷可以被多个个节点以读写方式挂载。亲和的节点为<code>minikube</code></p><p>我们通过get来查看这个PV：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kubectl get pv</span></span><br><span class="line">NAME       CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM             STORAGECLASS    REASON   AGE</span><br><span class="line">pv-local   5Gi        RWX            Delete           Available                  local-storage            25m</span><br></pre></td></tr></table></figure><p>此时PV的状态为<code>available</code>，还未与任何PVC绑定。<strong>我们通过创建PV使集群得到了一块存储资源，但此时还不属于你的应用，我们需要通过PVC去构建一个使用它的”通道“。</strong></p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#app1-pvc.yml</span></span><br><span class="line"></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">PersistentVolumeClaim</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">app1-pvc</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">storageClassName:</span> <span class="string">local-storage</span></span><br><span class="line">  <span class="attr">accessModes:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">ReadWriteMany</span></span><br><span class="line">  <span class="attr">resources:</span></span><br><span class="line">    <span class="attr">requests:</span></span><br><span class="line">      <span class="attr">storage:</span> <span class="string">1Gi</span></span><br></pre></td></tr></table></figure><p>现在我们开辟好一个5Gb容量的存储通道（PVC），此时PV和PVC已通过 <code>storageClassName</code>自动形成绑定。这样PV和PVC的status 皆为<code>Bound</code></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kubectl get pv</span></span><br><span class="line">NAME       CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM             STORAGECLASS    REASON   AGE</span><br><span class="line">pv-local   5Gi        RWX            Delete           Bound    default/app-pvc   local-storage            25m</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">$</span><span class="bash"> kubectl get pvc</span></span><br><span class="line">NAME      STATUS   VOLUME     CAPACITY   ACCESS MODES   STORAGECLASS    AGE</span><br><span class="line">app-pvc   Bound    pv-local   5Gi        RWX            local-storage   27m</span><br></pre></td></tr></table></figure><p>上面我们创建好通道，接下来要在我们statefuset中绑定这个通道，才能顺利使用存储。</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># nginx-statefulset.yml</span></span><br><span class="line"></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span>            </span><br><span class="line"><span class="attr">kind:</span> <span class="string">StatefulSet</span>              </span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">nginx-statefulset</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">serviceName:</span> <span class="string">&quot;nginx-headless&quot;</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">3</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">nginx</span>               </span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span>                  </span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">nginx</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">nodeName:</span> <span class="string">minikube</span></span><br><span class="line">      <span class="attr">volumes:</span> </span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">app-storage</span></span><br><span class="line">          <span class="attr">persistentVolumeClaim:</span>          </span><br><span class="line">            <span class="attr">claimName:</span> <span class="string">app-pvc</span></span><br><span class="line">            </span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx-web</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">nginx:1.17</span></span><br><span class="line">        <span class="attr">ports:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span></span><br><span class="line">          <span class="attr">name:</span> <span class="string">nginx-port</span></span><br><span class="line">        <span class="attr">volumeMounts:</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">mountPath:</span> <span class="string">/usr/share/nginx/html</span></span><br><span class="line">            <span class="attr">name:</span> <span class="string">app-storage</span></span><br></pre></td></tr></table></figure><p>与之前的statefulset相比我们在pod 模板中添加了<code>volume</code> 已经 <code>volumeMounts</code>，这样使用这个statefulset 所创建的pod都将挂载 我们前面定义的PVC <code>app-pvc</code>，应用<code>nginx-statefulset.yml</code>后我们进入到pod 检验一下目录是否被正确挂载。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kubectl <span class="built_in">exec</span> -it nginx-statefulset-0 -- /bin/bash</span></span><br><span class="line"></span><br><span class="line">root@nginx-statefulset-0:/# cat /usr/share/nginx/html/index.html</span><br><span class="line">hello pv</span><br></pre></td></tr></table></figure><p>查看本地目录文件：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">root@minikube:/# cat /data/volumes/index.html </span><br><span class="line">hello pv</span><br></pre></td></tr></table></figure><p>接着我们在pod 中修改index.html内容为并将pod删除，检验重载后的 pod 存储数据是否能被找回。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">root@nginx-statefulset-0:/# echo &quot;pod data&quot; &gt; /usr/share/nginx/html/index.html</span><br></pre></td></tr></table></figure><p>删除带有标签<code>app=nginx</code>的pod ,由于statefulset的控制器使pod按顺序被重建：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kubectl delete pod -l app=nginx</span></span><br><span class="line">pod &quot;nginx-statefulset-0&quot; deleted</span><br><span class="line">pod &quot;nginx-statefulset-1&quot; deleted</span><br><span class="line">pod &quot;nginx-statefulset-2&quot; deleted</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">$</span><span class="bash"> kubectl get pod</span> </span><br><span class="line">NAME                  READY   STATUS              RESTARTS   AGE</span><br><span class="line">nginx-statefulset-0   1/1     Running             0          9s</span><br><span class="line">nginx-statefulset-1   1/1     Running             0          6s</span><br><span class="line">nginx-statefulset-2   0/1     ContainerCreating   0          3s</span><br></pre></td></tr></table></figure><p>毫无疑问，pod 数据完好无损：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kubectl <span class="built_in">exec</span> -it nginx-statefulset-0 -- /bin/bash</span></span><br><span class="line">root@nginx-statefulset-0:/# cat /usr/share/nginx/html/index.html</span><br><span class="line">pod data</span><br></pre></td></tr></table></figure><p><strong>也就是说虽然我们的pod被删除了，但是PV已经PV依然保留在集群中，当pod 被重建后，它依然会去找定义的<code>claimName: app-pvc</code>这个PVC，接着挂载到容器中。</strong></p><p>这里我们一个PVC 绑定了多个节点，其实可以为每一个 statefulset中的pod 创建PVC，可以自行了解。</p><p>k8s存储可操作性非常强，这里只在statefulset下做了简单的演示。后续我们会对k8s存储做更深入的了解。</p><hr><h3 id="三、总结"><a href="#三、总结" class="headerlink" title="三、总结"></a>三、总结</h3><p>这篇小作文我们一起学习了k8s中工作负载资源StatefulSet是如何管理有状态应用的，主要从维护应用拓扑状态和存储状态两个方面做了简单介绍。这样我们对statefulset这个工作资源有了大体了解：StatefulSet 与 Deployment 相比，它为每个管理的 Pod 都进行了编号，使Pod有一个稳定的启动顺序，并且是集群中唯一的网络标识。有了标识后使用PV、PVC对存储状态进行维护。</p><hr><p><strong>希望小作文对你有些许帮助，如果内容有误请指正。</strong></p><p><strong>您可以随意转载、修改、发布本文，无需经过本人同意。</strong> 通过博客阅读：<a href="https://iqsing.github.io/">iqsing.github.io</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;在k8s中工作负载资源StatefulSet用于管理有状态应用。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;什么是无状态？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;组成一个应用的pod是对等的，它们之前没有关联和依赖关系，不依赖外部存储。&lt;/p&gt;
&lt;p&gt;即我们上篇小作文中deployment创</summary>
      
    
    
    
    <category term="k8s" scheme="https://iqsing.github.io/categories/k8s/"/>
    
    
    <category term="statefulset" scheme="https://iqsing.github.io/tags/statefulset/"/>
    
  </entry>
  
  <entry>
    <title>k8s工作负载资源之deployment</title>
    <link href="https://iqsing.github.io/2021/09/23/k8s%E5%B7%A5%E4%BD%9C%E8%B4%9F%E8%BD%BD%E8%B5%84%E6%BA%90%E4%B9%8Bdeployment/"/>
    <id>https://iqsing.github.io/2021/09/23/k8s%E5%B7%A5%E4%BD%9C%E8%B4%9F%E8%BD%BD%E8%B5%84%E6%BA%90%E4%B9%8Bdeployment/</id>
    <published>2021-09-22T16:47:21.000Z</published>
    <updated>2022-02-04T05:16:11.969Z</updated>
    
    <content type="html"><![CDATA[<p>首先我们要理解：一个应用跑在k8s集群上了，那么这个应用就是一个<strong>工作负载（<em>workloads</em>）。</strong></p><p>在k8s中会用pod的来承载这个应用，那么负责管理这个pod的东西就叫<strong>工作负载资源（<em>workload resources</em>）</strong>。</p><p>我们可以简单理解为是这样的：</p><p><img src="https://markdown-1257692304.cos.ap-nanjing.myqcloud.com/markdown_img/image-20210918102050547.png" alt="image-20210918102050547"></p><p>工作负载资源又支持jj自定义或使用第三方资源，这里我们先认识内置的，k8s内置工作负载资源包含如下：</p><ul><li>deployment</li><li>replicaset</li><li>statefulset</li><li>daemonset</li><li>jobs</li><li>cronjob</li><li>TTL Controller for Finished Resources</li><li>ReplicationController （逐步被ReplicaSet替代）</li></ul><hr><p><strong>那让我们从最常用的deployment开始吧。</strong></p><p><strong>一个 <em>Deployment</em> 为 Pods和 ReplicaSets提供声明式的更新能力，我们从下面几个方面开始上手：</strong></p><ol><li><strong>创建 Deployment 将 ReplicaSet 上线。</strong> ReplicaSet 在后台创建 Pods。 检查 ReplicaSet 的上线状态，查看其是否成功。</li><li>**通过更新 Deployment 的 Pod模板（TemplateSpec），声明 Pod 的新状态 。 **新的 ReplicaSet 会被创建，Deployment 以受控速率将 Pod 从旧 ReplicaSet 迁移到新 ReplicaSet。 每个新的 ReplicaSet 都会更新到 Deployment 的修订版本。</li><li><strong>如果 Deployment 与你的预期不符，可以回滚到较早的 Deployment 版本</strong>。 每次回滚都会更新到 Deployment 修订的新版本。</li><li><strong>通过Deployment 扩大应用规模承担更多负载</strong>。</li><li><strong>暂停 Deployment ，对 PodTemplateSpec 做修改然后恢复执行，让pod更新到新版本。</strong></li></ol><hr><h3 id="deployment创建"><a href="#deployment创建" class="headerlink" title="deployment创建"></a>deployment创建</h3><p>说了这么多还不如手动写一个deployment的yml声明实在（如果你喜欢json也可以是json格式，本质上还是将yml转换为json格式请求的api）。</p><p>下面deployment创建了一个replicaset，这个replicaset将会启动三个nginx的pod：</p><p>nginx-deployment.yml </p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">nginx-deployment</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">3</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">nginx</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">nginx</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx-web</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">nginx:latest</span></span><br><span class="line">        <span class="attr">ports:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span></span><br></pre></td></tr></table></figure><p>通过kubectl apply 将声明文件转换为api提交给apiserver</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kubectl apply -f nginx-deployment.yml</span> </span><br><span class="line">deployment.apps/nginx-deployment created</span><br></pre></td></tr></table></figure><p>查看deployment资源创建的对象nginx-deployment（这里的对象与编程语言中对象同义）</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kubectl get deployment</span></span><br><span class="line">NAME               READY   UP-TO-DATE   AVAILABLE   AGE</span><br><span class="line">nginx-deployment   3/3     3            3           67m</span><br></pre></td></tr></table></figure><p>查看nginx-deplyment创建的replicat对象nginx-deployment-767cf44bff</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash">kubectl get rs</span></span><br><span class="line">NAME                          DESIRED   CURRENT   READY   AGE</span><br><span class="line">nginx-deployment-767cf44bff   3         3         3       68m</span><br></pre></td></tr></table></figure><p>最后是nginx-deployment-767cf44bff创建的三个pod对象</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kubectl get pod</span> </span><br><span class="line"></span><br><span class="line">NAMESPACE     NAME                                READY   STATUS    RESTARTS   AGE</span><br><span class="line">default       nginx-deployment-767cf44bff-9fj8q   1/1     Running   0          13m</span><br><span class="line">default       nginx-deployment-767cf44bff-f746l   1/1     Running   0          13m</span><br><span class="line">default       nginx-deployment-767cf44bff-ktbzl   1/1     Running   0          13m</span><br></pre></td></tr></table></figure><p>也可以通过rollout status 查看 Deployment 上线状态。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash">kubectl rollout status deployment/nginx-deployment</span></span><br><span class="line">deployment &quot;nginx-deployment&quot; successfully rolled out</span><br></pre></td></tr></table></figure><p>这就是deployment资源创建对象的关系图：</p><p><img src="https://markdown-1257692304.cos.ap-nanjing.myqcloud.com/markdown_img/image-20210918111755912.png" alt="image-20210918111755912"></p><p>现在我们主要来看一下创建的这个nginx-deployment声明。</p><p><img src="https://markdown-1257692304.cos.ap-nanjing.myqcloud.com/markdown_img/image-20210918154910640.png" alt="image-20210918154910640"></p><p>我们把yml文件分为两个大部分（红色）：</p><ul><li><p>属性。</p><ul><li><code>apiVersion</code> - 创建该对象所使用的 Kubernetes API 的版本</li><li><code>kind</code> - 想要创建的对象的类别</li><li><code>metadata</code> - 帮助唯一性标识对象的一些数据，包括一个 <code>name</code> 字符串、UID 和可选的 <code>namespace</code></li></ul></li><li><p>规格 spec（specification）</p><ul><li><code>replicas</code> - 期望的pod副本数量</li><li><code>selector</code> - pod标签选择器</li><li><code>template</code> - pod模板</li></ul><p><strong>我们在selector中匹配包含<code>app=nginx</code>标签的pod，pod模板中又为新创建的pod打上<code>app=nginx</code>的标签，这样就形成了控制闭环。</strong></p></li></ul><p>我们通过可以show-labels查看pod的标签</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kubectl get pod  --show-labels</span></span><br><span class="line">NAME                                READY   STATUS    RESTARTS   AGE   LABELS</span><br><span class="line">nginx-deployment-767cf44bff-9fj8q   1/1     Running   0          81m   app=nginx,pod-template-hash=767cf44bff</span><br><span class="line">nginx-deployment-767cf44bff-f746l   1/1     Running   0          81m   app=nginx,pod-template-hash=767cf44bff</span><br><span class="line">nginx-deployment-767cf44bff-ktbzl   1/1     Running   0          81m   app=nginx,pod-template-hash=767cf44bff</span><br></pre></td></tr></table></figure><p><strong>为什么pod中又有一个<code>pod-template-hash</code>标签？</strong></p><p>eployment 控制器将 <code>pod-template-hash</code> 标签添加到 Deployment 所创建的每一个 ReplicaSet 中。我们来看一下rs的selector描述：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kubectl describe rs</span></span><br><span class="line">Name:           nginx-deployment-767cf44bff</span><br><span class="line">Namespace:      default</span><br><span class="line">Selector:       app=nginx,pod-template-hash=767cf44bff</span><br></pre></td></tr></table></figure><p>pod-template-hash 标签是通过对 ReplicaSet 的 <code>PodTemplate</code> 进行哈希处理，此标签可确保 Deployment 的子 ReplicaSets 不冲突，所生成的哈希值被添加到 ReplicaSet的selector、Pod 模板labels、以及 ReplicaSet 旗下的任何 Pod 中。<strong>这样deployment下的replicaset只能控制自己的pod。恩，妙哉。</strong></p><p>不同工作负载资源所创建的对象，spec是不同的。比如在Deployment中spec可以包含如下字段，这个可以在<a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.22/#deployment-v1-apps">Kubernetes API</a>中找到。</p><p><img src="https://markdown-1257692304.cos.ap-nanjing.myqcloud.com/markdown_img/image-20210918144005483.png" alt="image-20210918144005483"></p><p>大多数字段都包含了一个默认值，除非有特殊需求，大多数时候很难被用到。如果需要的时候你再谷歌一下也不迟。到这里deployment工作负载的第一个用例已经成了。</p><hr><h3 id="deployment更新"><a href="#deployment更新" class="headerlink" title="deployment更新"></a>deployment更新</h3><p>仅当 Deployment Pod 模板（即 <code>.spec.template</code>字段）发生改变时，例如模板的标签或容器镜像被更新， 才会触发 Deployment 上线。</p><p> 其他更新（如对 Deployment 执行扩缩容的操作）不会触发上线动作。</p><p><img src="https://markdown-1257692304.cos.ap-nanjing.myqcloud.com/markdown_img/image-20210920204824833.png" alt="image-20210920204824833"></p><ol><li><strong>我们可以通过<code>kubectl set </code>命令更新现有工作负责资源</strong></li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kubectl <span class="built_in">set</span> image deployment/nginx-deployment nginx-web=nginx:1.17 --record</span></span><br><span class="line">deployment.apps/nginx-deployment image updated</span><br></pre></td></tr></table></figure><p><code>--record</code> 用于记录kubectl对资源的操作。便于后期需要时回滚。下面会说到。</p><p>kubectl set -h 查询set支持更新的内容。</p><p>Available Commands:</p><ul><li>env            Update environment variables on a pod template</li><li>image          Update image of a pod template<br>  resources      Update resource requests/limits on objects with pod templates</li><li>  selector       Set the selector on a resource</li><li>  serviceaccount Update ServiceAccount of a resource</li><li>  subject        Update User, Group or ServiceAccount in a RoleBinding/ClusterRoleBinding</li></ul><ol start="2"><li><strong>使用<code>kubectl edit</code>编辑deployment后自动更新</strong></li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kubectl edit deployment/nginx-deployment --record</span></span><br><span class="line">deployment.apps/nginx-deployment edited</span><br></pre></td></tr></table></figure><ol start="3"><li><strong>直接更新deployment yml文件</strong></li></ol><p><strong>个人觉得最好的方式是更新yml声明文件，通过kubectl apply 应用即可，这样你只要管理好你的的nginx-deployment.yml做到心中有数</strong></p><p>当我们更新后查看rs状态，此时deployment 创建了一个新的nginx-deployment replicaset并投入使用。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kubectl get rs</span></span><br><span class="line">NAME                          DESIRED   CURRENT   READY   AGE</span><br><span class="line">nginx-deployment-64f9765d86   4         4         4       4h11m</span><br><span class="line">nginx-deployment-6cf9cc9c9d   0         0         0       5h6m</span><br></pre></td></tr></table></figure><p>这里顺便看一下deployment中pod滚动更新策略</p><p>我们可以通过kubectl describe deployment 查看RollingUpdateStrategy字段，即在滚动更新时最大不可用pod数为1/4，最大可用pod数为期望副本数1.25倍（多25%）。</p><p><strong>RollingUpdateStrategy:  25% max unavailable, 25% max surge</strong></p><p>假如我们将 deployment_A 中4个副本（pod）更新到deployment_B（也是4副本）,其中的某个数据pod状态如下</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kubectl get pod</span> </span><br><span class="line">NAME                                READY   STATUS              RESTARTS   AGE</span><br><span class="line">nginx-deployment-64f9765d86-c9rlj   0/1     ContainerCreating   0          2s</span><br><span class="line">nginx-deployment-64f9765d86-wngmx   0/1     ContainerCreating   0          2s</span><br><span class="line">nginx-deployment-7fcdcb4b75-lmsmm   1/1     Running             0          4h6m</span><br><span class="line">nginx-deployment-7fcdcb4b75-m99tx   1/1     Terminating         0          4h5m</span><br><span class="line">nginx-deployment-7fcdcb4b75-tghb2   1/1     Running             0          4h5m</span><br><span class="line">nginx-deployment-7fcdcb4b75-xfs2m   1/1     Running             0          4h6m</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>即只有1个在停止，正在创建2个新pod（即将有5个可用），详细滚动过程可通过<code>kubectl descibe deployment</code>中events查看。</p><p>尽量不要更新模板中labels，会造成pod孤立。在某些API版本已经被禁止了。</p><hr><h3 id="deployment回滚"><a href="#deployment回滚" class="headerlink" title="deployment回滚"></a>deployment回滚</h3><p>deployment回滚和更新一样，Pod 模板部分会被回滚。</p><p>我们通过 rollout history 来查看某个deployment的历史版本。即之前通过<code>--record</code>所记录的。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kubectl  rollout <span class="built_in">history</span>   deployment/nginx-deployment</span> </span><br><span class="line">deployment.apps/nginx-deployment </span><br><span class="line">REVISION  CHANGE-CAUSE</span><br><span class="line">1         &lt;none&gt;</span><br><span class="line">2         &lt;none&gt;</span><br><span class="line">3         kubectl apply --filename=nginx-deployment.yml --record=true</span><br><span class="line">4         kubectl apply --filename=nginx-deployment.yml --record=true</span><br><span class="line">5         kubectl set image deployment/nginx-deployment nginx-web=nginx:1.17 --record=true</span><br><span class="line">9         kubectl edit deployment/nginx-deployment --record=true</span><br><span class="line">10        kubectl edit deployment/nginx-deployment --record=true</span><br></pre></td></tr></table></figure><p>回滚到第5个版本。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kubectl rollout undo deployment/nginx-deployment --to-revision=5</span></span><br><span class="line">deployment.apps/nginx-deployment rolled back</span><br></pre></td></tr></table></figure><p>或者直接回滚到上一个版本。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kubectl rollout undo deployment/nginx-deployment</span></span><br></pre></td></tr></table></figure><p><strong>还是如前面所说，回滚只一种更工程化的说法，其实回滚也是一种更新，yml声明依然是核心。所以我们更应该关注的对deployment的yml文件的版本控制。</strong></p><hr><h3 id="deployment缩放"><a href="#deployment缩放" class="headerlink" title="deployment缩放"></a>deployment缩放</h3><p>缩放控制的是<code>.spec.replicas</code>,也可通过scale命令操作。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kubectl scale deployment/nginx-deployment --replicas=6</span></span><br><span class="line">deployment.apps/nginx-deployment scaled</span><br></pre></td></tr></table></figure><p>水平自动缩放本为暂不涉及，后面文章会详细讨论。可以参考：<a href="https://kubernetes.io/zh/docs/tasks/run-application/horizontal-pod-autoscale-walkthrough/">Horizontal Pod Autoscaler</a></p><hr><h3 id="deployment暂停与恢复"><a href="#deployment暂停与恢复" class="headerlink" title="deployment暂停与恢复"></a>deployment暂停与恢复</h3><p>我们可以在触发更新之前暂停 Deployment，然后做多个修改之后再恢复，进行一次性上线。</p><p>还是我们之前的deployment</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kubectl get deploy</span></span><br><span class="line">NAME               READY   UP-TO-DATE   AVAILABLE   AGE</span><br><span class="line">nginx-deployment   4/4     4            4           30m</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">$</span><span class="bash"> kubectl get rs</span></span><br><span class="line">NAME                          DESIRED   CURRENT   READY   AGE</span><br><span class="line">nginx-deployment-64f9765d86   4         4         4       30m</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>暂停deployment</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kubectl rollout pause deployment/nginx-deployment</span></span><br><span class="line">error: deployments.apps &quot;nginx-deployment&quot; is already paused</span><br></pre></td></tr></table></figure><p>对nginx-deployment做一些更新</p><ol><li>直接修改yml文件，更新镜像为nginx:1.17，并通过kubectl apply应用更改。</li><li>通过set做资源限制。</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kubectl <span class="built_in">set</span> resources deployment/nginx-deployment -c=nginx-web --limits=cpu=50m,memory=100Mi</span></span><br><span class="line">deployment.apps/nginx-deployment resource requirements updated</span><br></pre></td></tr></table></figure><p>此时我们查看rs副本状态，查看deployment版本信息</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kubectl get rs</span> </span><br><span class="line">NAME                          DESIRED   CURRENT   READY   AGE</span><br><span class="line">nginx-deployment-64f9765d86   4         4         4       40m</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">$</span><span class="bash"> kubectl rollout <span class="built_in">history</span> deployment/nginx-deployment</span></span><br><span class="line">deployment.apps/nginx-deployment </span><br><span class="line">REVISION  CHANGE-CAUSE</span><br><span class="line">1         &lt;none&gt;</span><br></pre></td></tr></table></figure><p>可以看到还是之前的rs，deployment并没有将我们的修改应用到对象中。</p><p>现在我们将deployment通过Resume恢复</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kubectl rollout resume deployment/nginx-deployment</span></span><br><span class="line">deployment.apps/nginx-deployment resumed</span><br></pre></td></tr></table></figure><p>查看rs状态</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kubectl get rs</span> </span><br><span class="line">NAME                          DESIRED   CURRENT   READY   AGE</span><br><span class="line">nginx-deployment-64f9765d86   3         3         3       41m</span><br><span class="line">nginx-deployment-7f4447656b   2         2         0       4s</span><br></pre></td></tr></table></figure><p>这会deployment已恢复，并应用了对资源对象的更新。</p><hr><h3 id="参考："><a href="#参考：" class="headerlink" title="参考："></a>参考：</h3><p>k8s官方文档<a href="https://kubernetes.io/zh/docs/concepts/workloads/controllers/deployment/">Deployment</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;首先我们要理解：一个应用跑在k8s集群上了，那么这个应用就是一个&lt;strong&gt;工作负载（&lt;em&gt;workloads&lt;/em&gt;）。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;在k8s中会用pod的来承载这个应用，那么负责管理这个pod的东西就叫&lt;strong&gt;工作负载资源（&lt;em&gt;w</summary>
      
    
    
    
    <category term="k8s" scheme="https://iqsing.github.io/categories/k8s/"/>
    
    
    <category term="deployment" scheme="https://iqsing.github.io/tags/deployment/"/>
    
  </entry>
  
  <entry>
    <title>K8s工作流程详解</title>
    <link href="https://iqsing.github.io/2021/09/14/K8s%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B%E8%AF%A6%E8%A7%A3/"/>
    <id>https://iqsing.github.io/2021/09/14/K8s%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B%E8%AF%A6%E8%A7%A3/</id>
    <published>2021-09-13T16:47:21.000Z</published>
    <updated>2022-02-04T05:16:11.713Z</updated>
    
    <content type="html"><![CDATA[<p>在学习k8s工作流程之前，我们得再次认识一下上篇<a href="">k8s架构与组件详解</a>中提到的<code>kube-controller-manager</code>一个k8s中许多控制器的进程的集合。</p><p>比如Deployment 控制器（DeploymentController）和 Job 控制器（JobController）是 Kubernetes 内置控制器的典型例子。在 Kubernetes 中，一个控制器至少追踪一种类型的 Kubernetes 资源。这些 资源对象有一个代表期望状态的 <code>spec</code> 字段。 该资源的控制器负责所属对象当前状态接近期望状态。</p><hr><h4 id="一、控制器与apiserver的交互"><a href="#一、控制器与apiserver的交互" class="headerlink" title="一、控制器与apiserver的交互"></a>一、控制器与apiserver的交互</h4><p><strong>上面提到的这些资源的控制器是如何确保资源对象当前状态接近于期望状态？</strong></p><p>当然是持续同步apiserver中（查询etcd）资源对象的元数据，并不断更新对象属性。是这样么？</p><p>当集群中有几十上百万个资源对象时，光控制器的http同步请求就够apiserver喝一壶的，显然不太棒。所以Kubernetes采用了一个叫<code>Informer</code>的机制。Informer 是 Client-go 中的一个核心工具包。</p><p><strong>在这里<code>informer</code>主要实现的作用如下：</strong></p><ol><li><h5 id="更快地返回-List-Get-请求，减少对-Kubenetes-API-的直接调用"><a href="#更快地返回-List-Get-请求，减少对-Kubenetes-API-的直接调用" class="headerlink" title="更快地返回 List/Get 请求，减少对 Kubenetes API 的直接调用"></a>更快地返回 List/Get 请求，减少对 Kubenetes API 的直接调用</h5></li></ol><p>使用 Informer 实例的 Lister() 方法， List/Get Kubernetes 中的 Object 时，Informer 不会去请求 Kubernetes API，而是直接查找缓存在本地内存中的数据，依赖Etcd的List&amp;Watch机制，客户端及时获知这些对象的状态变化，然后更新本地缓存，这样就在客户端为这些API对象维护了一份和Etcd数据库中几乎一致的数据，然后控制器等客户端就可以直接访问缓存获取对象的信息，而不用去直接访问apiserver。通过这种方式，Informer 既可以更快地返回结果，又能减少对 Kubernetes API 的直接调用。</p><ol start="2"><li><h5 id="可监听事件并触发回调函数"><a href="#可监听事件并触发回调函数" class="headerlink" title="可监听事件并触发回调函数"></a>可监听事件并触发回调函数</h5></li></ol><p>Informer 通过 Kubernetes Watch API 监听某种 resource 下的所有事件。Watch API 本质上就是一种 APIServer 主动向客户端推送 Kubernetes 资源修改、创建的一种机制。这样我们就可以获取到资源的变更，及时更新对象状态。</p><p>关于k8s中 informer详细可参考：<a href="https://www.kubernetes.org.cn/2693.html">kubenetes informer 详解</a></p><p><strong>通过上面我们知道了控制器是通过watch api监听apiserver中资源对象的更新，下面我们进入正题：k8s工作流程。</strong></p><hr><h4 id="二、k8s工作流程"><a href="#二、k8s工作流程" class="headerlink" title="二、k8s工作流程"></a>二、k8s工作流程</h4><p>我们来看通过deployment部署pod的常规流程：</p><p><img src="https://markdown-1257692304.cos.ap-nanjing.myqcloud.com/markdown_img/image-20210914114226232.png" alt="image-20210914114226232"></p><ol><li><p><strong>kubectl</strong>向<strong>apiserver</strong>发送部署请求（例如使用 kubectl create -f deployment.yml）</p></li><li><p><strong>apiserver</strong>将 Deployment 持久化到<strong>etcd；etcd</strong>与apiserver进行一次http通信。</p></li><li><p><strong>controller manager</strong>通过watch api监听 <strong>apiserver</strong> ，<strong>deployment controller</strong>看到了一个新创建的<strong>deplayment对象</strong>更后，将其从<strong>队列中</strong>拉出，根据deployment的描述创建一个<strong>ReplicaSet</strong>并将 ReplicaSet 对象返回apiserver并持久化回<strong>etcd</strong>。</p><p>以此类推，当replicaset控制器看到新创建的replicaset对象，将其从队列中拉出，根据描述创建pod对象。</p></li><li><p>接着scheduler调度器看到未调度的pod对象，根据调度规则选择一个可调度的节点，加载到pod描述中<strong>nodeName</strong>字段，并将pod对象返回apiserver并写入etcd。</p></li><li><p>kubelet在看到有pod对象中nodeName字段属于本节点，将其从<strong>队列中</strong>拉出，通过容器运行时创建pod中描述的容器。</p></li></ol><hr><p>上面我们说到的deployment-replicaset-pod的关系如下：</p><p><img src="https://markdown-1257692304.cos.ap-nanjing.myqcloud.com/markdown_img/Deploy-Replica-Pod.png" alt="Deploy-Replica-Pod"></p><hr><p><strong>希望小作文对你有些许帮助，如果内容有误请指正。</strong></p><p><strong>您可以随意转载、修改、发布本文，无需经过本人同意。</strong> 没什么用的blog：<a href="https://iqsing.github.io/">iqsing.github.io</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;在学习k8s工作流程之前，我们得再次认识一下上篇&lt;a href=&quot;&quot;&gt;k8s架构与组件详解&lt;/a&gt;中提到的&lt;code&gt;kube-controller-manager&lt;/code&gt;一个k8s中许多控制器的进程的集合。&lt;/p&gt;
&lt;p&gt;比如Deployment 控制器（Deplo</summary>
      
    
    
    
    <category term="k8s" scheme="https://iqsing.github.io/categories/k8s/"/>
    
    
    <category term="workflow" scheme="https://iqsing.github.io/tags/workflow/"/>
    
  </entry>
  
  <entry>
    <title>k8s架构与组件详解</title>
    <link href="https://iqsing.github.io/2021/09/13/k8s%E6%9E%B6%E6%9E%84%E4%B8%8E%E7%BB%84%E4%BB%B6%E8%AF%A6%E8%A7%A3/"/>
    <id>https://iqsing.github.io/2021/09/13/k8s%E6%9E%B6%E6%9E%84%E4%B8%8E%E7%BB%84%E4%BB%B6%E8%AF%A6%E8%A7%A3/</id>
    <published>2021-09-12T16:47:21.000Z</published>
    <updated>2022-02-04T05:16:11.982Z</updated>
    
    <content type="html"><![CDATA[<p>没有那么多花里胡哨，直接进行一个K8s架构与组件的学习。</p><h4 id="一、K8s架构"><a href="#一、K8s架构" class="headerlink" title="一、K8s架构"></a>一、K8s架构</h4><p><img src="https://markdown-1257692304.cos.ap-nanjing.myqcloud.com/markdown_img/k8srebuild.png" alt="k8srebuild"></p><p>k8s系统在设计是遵循c-s架构的，也就是我们图中apiserver与其余组件的交互。在生产中通常会有多个Master以实现K8s系统服务高可用。K8s集群至少有一个工作节点，节点上运行 K8s 所管理的容器化应用。</p><p>在Master通常上包括 kube-apiserver、etcd 存储、kube-controller-manager、cloud-controller-manager、kube-scheduler 和用于 K8s 服务的 DNS 服务器（插件）。这些对集群做出全局决策(比如调度)，以及检测和响应集群事件的组件集合也称为控制平面。</p><p><strong>其实K8s官方并没有<code>Master</code>这一说，只是大多数安装工具（kubeadm）或者脚本为了架构更明了会把控制平面中的组件安装到一台机器上即Master机器，并且不会在此机器上运行用户容器。</strong>这不是强制性的，所以你也可以对将控制平面实行分布式部署，不过这样的话高可用会是一个不小的挑战。</p><p>在Node上组件包括 kubelet 、kube-porxy  以及服务于pod的容器运行时(runtime)。外部storage与registry用于为容器提供存储与镜像仓库服务。</p><hr><p><strong>从kubectl开始，我们来看一下K8s的基本工作流程：</strong></p><ol><li>kubectl 客户端首先将CLI命令转化为RESTful的API调用，然后发送到kube-apiserver。</li><li>kube-apiserver 在验证这些 API 调用后，将任务元信息并存储到etcd，接着调用 kube-scheduler 开始决策一个用于作业的Node节点。</li><li>一旦 kube-scheduler 返回一个适合调度的目标节点后，kube-apiserver 就把任务的节点信息存入etcd，并创建任务。</li><li>此时目标节点中的 kubelet正监听apiserver，当监听到有新任务需要调度到本节点后，kubelet通过本地runtime创建任务容器，执行作业。</li><li>接着kubelet将任务状态等信息返回给apiserver存储到etcd。</li><li>这样我们的任务已经在运行了，此时control-manager发挥作用保证任务一直是我们期望的状态。</li></ol><hr><h4 id="二、K8s组件介绍"><a href="#二、K8s组件介绍" class="headerlink" title="二、K8s组件介绍"></a>二、K8s组件介绍</h4><h4 id="1、控制平面组件"><a href="#1、控制平面组件" class="headerlink" title="1、控制平面组件"></a>1、控制平面组件</h4><h5 id="kube-apiserver"><a href="#kube-apiserver" class="headerlink" title="kube-apiserver"></a>kube-apiserver</h5><p>API服务器为K8s集群资源操作提供唯一入口，并提供认证、授权、访问控制、API 注册和发现机制。</p><p>Kubernetes API 服务器的主要实现是 kube-apiserver。 kube-apiserver 设计上考虑了水平伸缩，也就是说，它可通过部署多个实例进行伸缩。 你可以运行 kube-apiserver 的多个实例，并在这些实例之间进行流量平衡。</p><h5 id="etcd"><a href="#etcd" class="headerlink" title="etcd"></a>etcd</h5><p>etcd 是兼具一致性和高可用性的键值数据库，可以作为保存 Kubernetes 所有集群数据的后台数据库(例如 Pod 的数量、状态、命名空间等）、API 对象和服务发现细节。<br>在生产级k8s中etcd通常会以集群的方式存在，安全原因，它只能从 API 服务器访问。 </p><p>etcd也是k8s生态的关键应用。关于 etcd 可参考 <a href="https://etcd.io/docs/">etcd 文档</a>。</p><h5 id="kube-scheduler"><a href="#kube-scheduler" class="headerlink" title="kube-scheduler"></a>kube-scheduler</h5><p>kube-scheduler 负责监视新创建、未指定运行Node的 Pods，决策出一个让pod运行的节点。</p><p>例如，如果应用程序需要 1GB 内存和 2 个 CPU 内核，那么该应用程序的 pod 将被安排在至少具有这些资源的节点上。每次需要调度 pod 时，调度程序都会运行。调度程序必须知道可用的总资源以及分配给每个节点上现有工作负载的资源。</p><p>调度决策考虑的因素包括单个 Pod 和 Pod 集合的资源需求、硬件/软件/策略约束、亲和性和反亲和性规范、数据位置、工作负载间的干扰和最后时限。</p><h5 id="kube-controller-manager"><a href="#kube-controller-manager" class="headerlink" title="kube-controller-manager"></a>kube-controller-manager</h5><p>k8s在后台运行许多不同的控制器进程，当服务配置发生更改时（例如，替换运行 pod 的镜像，或更改配置 yaml 文件中的参数），控制器会发现更改并开始朝着新的期望状态工作。</p><p>从逻辑上讲，每个控制器都是一个单独的进程， 但是为了降低复杂性，它们都被编译到同一个可执行文件，并在一个进程中运行。</p><p>控制器包括:</p><ul><li>节点控制器（Node Controller）: 负责在节点出现故障时进行通知和响应</li><li>任务控制器（Job controller）: 监测代表一次性任务的 Job 对象，然后创建 Pods 来运行这些任务直至完成</li><li>端点控制器（Endpoints Controller）: 填充端点(Endpoints)对象(即加入 Service 与 Pod)</li><li>服务帐户和令牌控制器（Service Account &amp; Token Controllers）: 为新的命名空间创建默认帐户和 API 访问令牌</li></ul><h5 id="cloud-controller-manager"><a href="#cloud-controller-manager" class="headerlink" title="cloud-controller-manager"></a>cloud-controller-manager</h5><p> 云控制器管理器使得你可以将你的集群连接到云提供商的 API 之上， 同时可以将云平台交互组件与本地集群中组件分离。</p><p><code>cloud-controller-manager</code> 仅运行特定于云平台的控制回路。 如果我们在自己的环境中运行 Kubernetes，大多数时候非混合云环境是用不到这个组件的。</p><p>与 <code>kube-controller-manager</code> 类似，<code>cloud-controller-manager</code> 将若干逻辑上独立的 控制回路组合到同一个可执行文件中，供你以同一进程的方式运行。 你可以对其执行水平扩容（运行不止一个副本）以提升性能或者增强容错能力。</p><p>下面的控制器都包含对云平台驱动的依赖：</p><ul><li>节点控制器（Node Controller）: 用于在节点终止响应后检查云提供商以确定节点是否已被删除</li><li>路由控制器（Route Controller）: 用于在底层云基础架构中设置路由</li><li>服务控制器（Service Controller）: 用于创建、更新和删除云提供商负载均衡器</li></ul><hr><h4 id="2-Node中组件"><a href="#2-Node中组件" class="headerlink" title="2.Node中组件"></a>2.Node中组件</h4><p>节点组件在每个节点上运行，维护运行的 Pod 并提供 Kubernetes 运行环境。</p><h5 id="kubelet"><a href="#kubelet" class="headerlink" title="kubelet"></a>kubelet</h5><p>一个在集群中每个node上运行的代理。 它保证容器都 运行在 Pod 中。kubelet 定期接收新的或修改过的 pod 规范 PodSpecs（主要通过 kube-apiserver）并确保 pod 及容器健康并以所需状态运行。该组件还向 kube-apiserver 报告运行它的主机的健康状况。</p><p> kubelet 不会管理不是由 Kubernetes 创建的容器。</p><h5 id="kube-proxy"><a href="#kube-proxy" class="headerlink" title="kube-proxy"></a>kube-proxy</h5><p><a href="https://kubernetes.io/zh/docs/reference/command-line-tools-reference/kube-proxy/">kube-proxy</a> 是集群中每个节点上运行的网络代理， 实现 Kubernetes 服务（Service） 概念的一部分。用于处理单个主机子网划分并向外部世界公开服务。它跨集群中的各种隔离网络将请求转发到正确的 pod/容器。</p><p>kube-proxy 维护节点上的网络规则。这些网络规则允许从集群内部或外部的网络会话与 Pod 进行网络通信。</p><p>如果操作系统提供了数据包过滤层并可用的话，kube-proxy 会通过它来实现网络规则。否则， kube-proxy 仅转发流量本身。</p><h5 id="容器运行时（Container-Runtime）"><a href="#容器运行时（Container-Runtime）" class="headerlink" title="容器运行时（Container Runtime）"></a>容器运行时（Container Runtime）</h5><p>容器运行时负责创建容器运行环境。</p><p>Kubernetes 支持多个容器运行时: Docker（即将被废弃）、containerd、CRI-O以及任何实现 <a href="https://github.com/kubernetes/community/blob/master/contributors/devel/sig-node/container-runtime-interface.md">Kubernetes CRI (容器运行环境接口)</a>的runtime。</p><hr><h4 id="三、tips"><a href="#三、tips" class="headerlink" title="三、tips"></a>三、tips</h4><ol><li><p>K8s拥有一个完整的云原生生态，是一个缤纷多彩同时又把复杂度拉满的世界。</p></li><li><p>k8s基础是容器，虽然docker运行时已被k8s弃用，但是学习docker依然是上手容器化最佳方式。</p></li><li><p>Kubernetes 官方文档<a href="https://kubernetes.io/docs/home/">https://kubernetes.io/docs/home/</a></p></li></ol><hr><h4 id="NEXT"><a href="#NEXT" class="headerlink" title="NEXT"></a>NEXT</h4><ul><li>k8s工作流程详解</li></ul><p><strong>希望小作文对你有些许帮助，如果内容有误请指正。</strong></p><p><strong>您可以随意转载、修改、发布本文，无需经过本人同意。</strong> </p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;没有那么多花里胡哨，直接进行一个K8s架构与组件的学习。&lt;/p&gt;
&lt;h4 id=&quot;一、K8s架构&quot;&gt;&lt;a href=&quot;#一、K8s架构&quot; class=&quot;headerlink&quot; title=&quot;一、K8s架构&quot;&gt;&lt;/a&gt;一、K8s架构&lt;/h4&gt;&lt;p&gt;&lt;img src=&quot;http</summary>
      
    
    
    
    <category term="k8s" scheme="https://iqsing.github.io/categories/k8s/"/>
    
    
    <category term="k8s" scheme="https://iqsing.github.io/tags/k8s/"/>
    
  </entry>
  
  <entry>
    <title>docker 容器如何精简镜像减小体积</title>
    <link href="https://iqsing.github.io/2021/08/31/docker%E5%AE%B9%E5%99%A8%20%E5%A6%82%E4%BD%95%E7%B2%BE%E7%AE%80%E9%95%9C%E5%83%8F%E5%87%8F%E5%B0%8F%E4%BD%93%E7%A7%AF/"/>
    <id>https://iqsing.github.io/2021/08/31/docker%E5%AE%B9%E5%99%A8%20%E5%A6%82%E4%BD%95%E7%B2%BE%E7%AE%80%E9%95%9C%E5%83%8F%E5%87%8F%E5%B0%8F%E4%BD%93%E7%A7%AF/</id>
    <published>2021-08-31T04:22:21.000Z</published>
    <updated>2022-02-04T05:16:11.752Z</updated>
    
    <content type="html"><![CDATA[<h4 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h4><p>我们在上篇《Docker容器 关于镜像构建的安全问题》一起学习了如何构建一个基于安全的镜像，这篇小作文我们会学习镜像构建的另一个关键性问题，为何别人打造的镜像只有10MB而我的有几百MB？如何精简镜像减小镜像体积？</p><hr><p>精简镜像我们可以从两个方面切入：</p><ul><li><strong>减少镜像层数</strong></li><li><strong>缩减容量</strong></li></ul><hr><h5 id="一、减少镜像层数"><a href="#一、减少镜像层数" class="headerlink" title="一、减少镜像层数"></a>一、减少镜像层数</h5><h5 id="1-指令合并"><a href="#1-指令合并" class="headerlink" title="1.指令合并"></a>1.指令合并</h5><p>Dockerfile 中的每条指令都将创建一个层，不过查看官方文档中最佳实践有这样一句话：</p><p>In older versions of Docker, it was important that you minimized the number of layers in your images to ensure they were performant. The following features were added to reduce this limitation:</p><ul><li><p><strong>Only the instructions <code>RUN</code>, <code>COPY</code>, <code>ADD</code> create layers. Other instructions create temporary intermediate images, and do not increase the size of the build.</strong></p><p>…</p></li></ul><p>参考地址：<a href="https://docs.docker.com/develop/develop-images/dockerfile_best-practices/#minimize-the-number-of-layers">Minimize the number of layers</a></p><p>意味着只有 <code>RUN</code>, <code>COPY</code>, <code>ADD</code> 三个指令会创建层，其他指令会创建一个中间镜像，并且不会影响镜像大小。这样我们说的指令合并也就是以这三个指令为主。</p><p>我们以如下Dockerfile为例</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">FROM</span> debian:stable</span><br><span class="line"></span><br><span class="line"><span class="keyword">WORKDIR</span><span class="bash"> /var/www</span></span><br><span class="line"><span class="keyword">LABEL</span><span class="bash"> version=“v1”</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> apt-get update</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> apt-get -y --no-install-recommends install curl</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> apt-get purge -y curl</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> apt-get autoremove -y</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> apt-get clean</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> rm -rf /var/lib/apt/lists/*</span></span><br></pre></td></tr></table></figure><p>构建镜像</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker build -t curl:v1 .</span><br></pre></td></tr></table></figure><p>通过history查看构建历史</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># docker history curl:v1</span></span><br><span class="line"></span><br><span class="line">IMAGE          CREATED          CREATED BY                                      SIZE      COMMENT</span><br><span class="line">29b721c09b67   18 seconds ago   /bin/sh -c rm -rf /var/lib/apt/lists/*          0B        </span><br><span class="line">aa28ae151e59   20 seconds ago   /bin/sh -c apt-get clean                        0B        </span><br><span class="line">4f733781f557   22 seconds ago   /bin/sh -c apt-get autoremove -y                989kB     </span><br><span class="line">f66887372121   29 seconds ago   /bin/sh -c apt-get purge -y curl                987kB     </span><br><span class="line">d458ee0de463   34 seconds ago   /bin/sh -c apt-get -y --no-install-recommend…   4.46MB    </span><br><span class="line">43fdcf68018c   44 seconds ago   /bin/sh -c apt-get update                       17.6MB    </span><br><span class="line">65631e8bb010   53 seconds ago   /bin/sh -c <span class="comment">#(nop)  LABEL version=“v1”           0B        </span></span><br><span class="line">7ef7c53b019c   53 seconds ago   /bin/sh -c <span class="comment">#(nop) WORKDIR /var/www              0B        </span></span><br><span class="line">8bfa93572e55   13 days ago      /bin/sh -c <span class="comment">#(nop)  CMD [&quot;bash&quot;]                 0B        </span></span><br><span class="line">&lt;missing&gt;      13 days ago      /bin/sh -c <span class="comment">#(nop) ADD file:d78d93eff67b18592…   124MB </span></span><br></pre></td></tr></table></figure><p>镜像大小</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost dockerfiles]<span class="comment"># docker images</span></span><br><span class="line">REPOSITORY            TAG       IMAGE ID       CREATED          SIZE</span><br><span class="line">curl                  v1        29b721c09b67   10 minutes ago   148MB</span><br></pre></td></tr></table></figure><p>我们将<code>RUN</code>指令通过类shell操作<code>&amp;&amp;</code>合并后</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">RUN</span><span class="bash"> apt-get update &amp;&amp; \</span></span><br><span class="line"><span class="bash">    apt-get -y --no-install-recommends install curl &amp;&amp; \</span></span><br><span class="line"><span class="bash">    apt-get purge -y curl &amp;&amp; \</span></span><br><span class="line"><span class="bash">    apt-get autoremove -y &amp;&amp; \</span></span><br><span class="line"><span class="bash">    apt-get clean &amp;&amp; \</span></span><br><span class="line"><span class="bash">    rm -rf /var/lib/apt/lists/*</span></span><br></pre></td></tr></table></figure><p>查看构建历史与镜像大小</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># docker history curl:v2</span></span><br><span class="line">IMAGE          CREATED              CREATED BY                                      SIZE      COMMENT</span><br><span class="line">928e12c2f57e   About a minute ago   /bin/sh -c apt-get update &amp;&amp;     apt-get -y …   989kB     </span><br><span class="line">5a32372025fb   About a minute ago   /bin/sh -c <span class="comment">#(nop)  LABEL version=“v2”           0B        </span></span><br><span class="line">7ef7c53b019c   30 minutes ago       /bin/sh -c <span class="comment">#(nop) WORKDIR /var/www              0B        </span></span><br><span class="line">8bfa93572e55   13 days ago          /bin/sh -c <span class="comment">#(nop)  CMD [&quot;bash&quot;]                 0B        </span></span><br><span class="line">&lt;missing&gt;      13 days ago          /bin/sh -c <span class="comment">#(nop) ADD file:d78d93eff67b18592…   124MB</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># docker images</span></span><br><span class="line">REPOSITORY            TAG       IMAGE ID       CREATED          SIZE</span><br><span class="line">curl                  v2        928e12c2f57e   3 minutes ago    125MB</span><br></pre></td></tr></table></figure><p>可见只是一个简单的curl应用在通过指令合并的方式安装已经获得了约20MB的容量释放。同时使你的dockerfile文件更为易读和简约。</p><h5 id="2-多阶段构建"><a href="#2-多阶段构建" class="headerlink" title="2.多阶段构建"></a>2.多阶段构建</h5><p>在Docker17.05 中引入了多阶段构建，通过多阶段构建可以大大降低构建复杂度，同时使缩小镜像尺寸更为简单。我们来看多阶段构建的Dockerfile</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#阶段1</span></span><br><span class="line"><span class="keyword">FROM</span> golang:<span class="number">1.16</span></span><br><span class="line"><span class="keyword">WORKDIR</span><span class="bash"> /go/src</span></span><br><span class="line"><span class="keyword">COPY</span><span class="bash"> app.go ./</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> go build app.go -o myapp</span></span><br><span class="line"><span class="comment">#阶段2</span></span><br><span class="line"><span class="keyword">FROM</span> scratch</span><br><span class="line"><span class="keyword">WORKDIR</span><span class="bash"> /server</span></span><br><span class="line"><span class="keyword">COPY</span><span class="bash"> --from=0 /go/src/myapp ./</span></span><br><span class="line"><span class="keyword">CMD</span><span class="bash"> [<span class="string">&quot;./myapp&quot;</span>]</span></span><br></pre></td></tr></table></figure><p>构建镜像</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># docker build --no-cache  -t server_app:v2 .</span></span><br></pre></td></tr></table></figure><p>查看构建好的镜像</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># docker images</span></span><br><span class="line">REPOSITORY            TAG       IMAGE ID       CREATED              SIZE</span><br><span class="line">server_app            v2        20225cb1ea6b   12 seconds ago       1.94MB</span><br></pre></td></tr></table></figure><p>以上用例来自上篇文章<a href="">《Dockerfile 多阶段构建实践》</a>关于镜像多阶段构建具体内容可以前往查看，这里不做过多赘述。</p><h4 id="3-启用squash特性"><a href="#3-启用squash特性" class="headerlink" title="3.启用squash特性"></a>3.启用squash特性</h4><p>通过启用squash特性（实验性功能）<code>docker build --squash -t curl:v3 .</code> 可以构建的镜像压缩为一层。但是为了充分发挥容器镜像层共享的优越设计，这种方法不被推荐。</p><hr><h4 id="二、缩减容量"><a href="#二、缩减容量" class="headerlink" title="二、缩减容量"></a>二、缩减容量</h4><h5 id="1-选择小的基础镜像"><a href="#1-选择小的基础镜像" class="headerlink" title="1. 选择小的基础镜像"></a>1. 选择小的基础镜像</h5><p>每个linux发行版镜像大小相差很多，甚至相同发行版镜像也存在差异。我们以debian为例：</p><p>稳定版和瘦身版相差约40MB</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># docker images </span></span><br><span class="line">debian                stable-slim   2aa48a485e3a   13 days ago         80.4MB</span><br><span class="line">debian                stable        8bfa93572e55   13 days ago         124MB</span><br></pre></td></tr></table></figure><p>我们将Dockerfile中基础镜像改为瘦身版<code>debian:stable-slim</code></p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">FROM</span> debian:stable-slim</span><br></pre></td></tr></table></figure><p>构建后的镜像尺寸更小</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># docker images </span></span><br><span class="line">REPOSITORY            TAG           IMAGE ID       CREATED             SIZE</span><br><span class="line">curl                  v4            1aab5c9bf8b3   17 seconds ago      81.4MB</span><br></pre></td></tr></table></figure><p>当前映像基于 Debian，并包含许多二进制文件。Docker 容器应该包含一个进程，并包含运行它所需的最低限度。我们其实不需要整个操作系统。</p><p>我们可以使用基于 Alpine 的镜像 替换Debian 基础镜像。</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">FROM</span> alpine</span><br><span class="line"></span><br><span class="line"><span class="keyword">WORKDIR</span><span class="bash"> /var/www</span></span><br><span class="line"><span class="keyword">LABEL</span><span class="bash"> version=“v5”</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> <span class="built_in">echo</span> -e <span class="string">&#x27;https://mirrors.aliyun.com/alpine/v3.6/main/\nhttps://mirrors.aliyun.com/alpine/v3.6/community/&#x27;</span> &gt; /etc/apk/repositories &amp;&amp; \</span></span><br><span class="line"><span class="bash">    apk update &amp;&amp; \</span></span><br><span class="line"><span class="bash">    apk upgrade &amp;&amp; \</span></span><br><span class="line"><span class="bash">    apk add --no-cache curl</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>查看镜像大小</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># docker images</span></span><br><span class="line">REPOSITORY            TAG           IMAGE ID       CREATED             SIZE</span><br><span class="line">curl                  v5            7f735bb213be   11 seconds ago      10.1MB</span><br></pre></td></tr></table></figure><p>此时我们的镜像来到了10MB。使用alpine镜像包管理工具是apk，一些软件包名可能不一样。最大的区别在于Alpine 采用的链接库是 <a href="https://musl.libc.org/">musl libc</a> 而不是 <a href="https://www.etalabs.net/compare_libcs.html">glibc</a> 系列。</p><h5 id="2-上下文管理"><a href="#2-上下文管理" class="headerlink" title="2.上下文管理"></a>2.上下文管理</h5><p>我们经常会用到的COPY指令</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">COPY</span><span class="bash"> . /server/dir</span></span><br></pre></td></tr></table></figure><p>COPY会把<strong>整个</strong> <strong>构建上下文</strong>复制到镜像中，并生产新的缓存层。为了不必要的文件如日志、缓存文件、Git 历史记录被加载到构建上下文，我们最好添加**.dockerignore**用于忽略非必须文件。这也是精简镜像关键一步，同时能更好的保证我们构建的镜像安全性。</p><h5 id="3-及时清理下载"><a href="#3-及时清理下载" class="headerlink" title="3.及时清理下载"></a>3.及时清理下载</h5><p>我们有如下Dockerfile</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">..</span><br><span class="line"><span class="keyword">WORKDIR</span><span class="bash"> /tmp</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> curl -LO https://docker.com/download.zip &amp;&amp; tar -xf download.zip -C /var/www </span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> rm  -f download.zip</span></span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>我们虽然使用了<code>rm</code>删除download.zip包，由于镜像分层的问题，download.zip是在新的一层被删除，上一层仍然存在。</p><p>我们要在一层中及时清理下载</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">RUN</span><span class="bash"> curl -LO https://docker.com/download.zip &amp;&amp; tar -xf download.zip -C /var/www &amp;&amp;  rm  -f download.zip</span></span><br></pre></td></tr></table></figure><p>另外在安装软件时应及时使用包管理工具清除你下载的软件依赖及缓存，比如在我们dockerfile中使用apt包管理工具做清理。</p><hr><p>关于精简镜像的相关操作介绍到这里。</p><p><strong>希望小作文对你有些许帮助，如果内容有误请指正。</strong></p><p><strong>您可以随意转载、修改、发布本文章，无需经过本人同意。</strong></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h4 id=&quot;写在前面&quot;&gt;&lt;a href=&quot;#写在前面&quot; class=&quot;headerlink&quot; title=&quot;写在前面&quot;&gt;&lt;/a&gt;写在前面&lt;/h4&gt;&lt;p&gt;我们在上篇《Docker容器 关于镜像构建的安全问题》一起学习了如何构建一个基于安全的镜像，这篇小作文我们会学习镜像构建的另</summary>
      
    
    
    
    <category term="docker" scheme="https://iqsing.github.io/categories/docker/"/>
    
    
    <category term="dockerfile" scheme="https://iqsing.github.io/tags/dockerfile/"/>
    
  </entry>
  
  <entry>
    <title>Docker容器 Dockerfile构建安全镜像</title>
    <link href="https://iqsing.github.io/2021/08/30/Docker%E5%AE%B9%E5%99%A8%20Dockerfile%E6%9E%84%E5%BB%BA%E5%AE%89%E5%85%A8%E9%95%9C%E5%83%8F/"/>
    <id>https://iqsing.github.io/2021/08/30/Docker%E5%AE%B9%E5%99%A8%20Dockerfile%E6%9E%84%E5%BB%BA%E5%AE%89%E5%85%A8%E9%95%9C%E5%83%8F/</id>
    <published>2021-08-30T04:47:21.000Z</published>
    <updated>2022-02-04T05:16:11.693Z</updated>
    
    <content type="html"><![CDATA[<h4 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h4><p>确保容器中服务与应用安全是容器化演进的关键点。容器安全涉及到应用开发与维护的整个生命周期，本文主要从镜像构建的视角来看docker容器的一些安全问题及应对措施。</p><hr><h4 id="一、权限管理"><a href="#一、权限管理" class="headerlink" title="一、权限管理"></a>一、权限管理</h4><p><strong>1.避免以容器以root身份运行</strong></p><p>在Openshift与k8s环境中默认容器需要以<strong>非root</strong>身份运行，使用root身份运行的情况很少，所以不要忘记在dockerfile中包含<em>USER</em>指令，以将启动容器时默认有效 的UID 更改为非 root 用户。</p><p>以非 root 身份运行需要在 Dockerfile 中做的两个步骤：</p><ul><li>确保<em>USER</em>指令中指定的<em>用户</em>存在于容器内。</li><li>在进程将要读取或写入的位置提供适当的文件系统权限。</li></ul><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">FROM</span> alpine</span><br><span class="line"><span class="comment">#创建目录，添加myuser用户，目录所有作为myuser</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> mkdir /server &amp;&amp; adduser -D myuser  &amp;&amp; chown -R myuser /server</span></span><br><span class="line"><span class="keyword">USER</span> myuser</span><br><span class="line"><span class="keyword">WORKDIR</span><span class="bash"> /server</span></span><br><span class="line"><span class="keyword">COPY</span><span class="bash"> myapp ./</span></span><br><span class="line"><span class="keyword">CMD</span><span class="bash"> [<span class="string">&quot;./myapp&quot;</span>]</span></span><br></pre></td></tr></table></figure><p><strong>2.可执行文件权限应为root用户拥有但不可写</strong></p><p>容器中的每个可执行文件都应该由 root 用户拥有，即使它由非 root 用户执行，并且不应该是全局可写的。</p><p>通过阻止执行用户修改现有的二进制文件或脚本，可以有效降低攻击，保证容器不变性。不可变容器不会在运行时自动更新其代码，通过这种方式，我们可以防止正在运行的应用程序被意外或恶意修改。</p><p>我们在使用COPY时</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">COPY</span><span class="bash"> --chown=myuser:myuser myapp ./</span></span><br><span class="line"><span class="comment">#应改为</span></span><br><span class="line"><span class="keyword">COPY</span><span class="bash">  myapp ./</span></span><br></pre></td></tr></table></figure><hr><h4 id="二、减少攻击面"><a href="#二、减少攻击面" class="headerlink" title="二、减少攻击面"></a>二、减少攻击面</h4><p>避免加载不必要的包、第三方应用或暴露端口以减少攻击面。我们在镜像中包含的组件内容越多，容器暴露的就越多，维护起来就越困难。</p><p><strong>1.采用多阶段构建</strong></p><p>我们在<a href="">《Dockerfile 多阶段构建实践》</a>中说到采用多阶段构建，可以此降低构建复杂度，同时有效减小镜像尺寸。</p><p>在多阶段构建中，我们创建一个中间容器（阶段），其中包含编译工具及生成最终可执行文件。然后，我们只将生成的工件复制到最终镜像中，而无需额外的开发依赖项、临时构建文件等等。</p><p>精心设计的多阶段构建仅包含最终映像中所需的最少二进制文件和依赖项，而不包含构建工具或中间文件。它更为安全，并且还减小了镜像大小。可以有效减少了攻击面，减少了漏洞。</p><p>多阶段构建的实现请参考上篇文章<a href="">《Dockerfile 多阶段构建实践》</a></p><p><strong>2.使用可信赖的镜像</strong></p><p>假如我们不是从头开始构建镜像，基镜像建立在不受信任或不受维护的镜像之上会将所有问题和漏洞从该镜像继承到您的容器中。</p><p>基础镜像选择的参考：</p><ul><li>我们应该选择<strong>来自受信任仓库</strong>和<strong>经过验证</strong>的官方镜像。</li><li>使用自定义镜像时，我们应该检查镜像源和构建的 Dockerfile。更进一步，我们甚至应该以这个Dockerfile来<strong>构建自己的基础镜像</strong>。因为我们无法保证在dockerhub等公共仓库中发布的映像确实是从指定的 Dockerfile 构建的。也不能保证它是最新的。</li><li>有时候在安全性和极简主义方面考虑，官方镜像可能并不非合适的，最优解是我们自己从头构建属于自己的镜像。</li></ul><p><strong>2.从头开始构建镜像</strong></p><p>假如如果你是从centos镜像开始构建，那么你创建的容器可能将会包含几十个或者上百个漏洞。所以构建一个安全的镜像我们最好需要知道我们的基镜像存在哪些威胁。在生产中通常会从<strong>Scratch</strong>空镜像或<strong>distroless</strong>开始。</p><p><strong>distroless</strong>镜像仅包含应用程序及其运行时依赖项。它们不包括在标准 Linux 发行版中发布应用如包管理器、shell 或任何其他程序。Distroless 镜像<em>非常小</em>。最小的 distroless 图像<code>gcr.io/distroless/static</code>大约为 650 kB。只有<code>alpine</code>(约2.5 MB)大小的 四分之一 ，不到<code>debian</code>(50 MB)大小的 1.5% 。</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">FROM</span> golang:<span class="number">1.13</span>-buster as build</span><br><span class="line"></span><br><span class="line"><span class="keyword">WORKDIR</span><span class="bash"> /go/src/app</span></span><br><span class="line"><span class="keyword">ADD</span><span class="bash"> . /go/src/app</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> go get -d -v ./...</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> go build -o /go/bin/app</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 引用Distroless镜像</span></span><br><span class="line"><span class="keyword">FROM</span> gcr.io/distroless/base-debian10</span><br><span class="line"><span class="keyword">COPY</span><span class="bash"> --from=build /go/bin/app /</span></span><br><span class="line"><span class="keyword">CMD</span><span class="bash"> [<span class="string">&quot;/app&quot;</span>]</span></span><br></pre></td></tr></table></figure><p><code>gcr.io/distroless/base-debian10</code>只包含一组基本的包，如包括只需要的库，如<em>glibc</em>、<em>libssl</em>和<em>openssl</em> 当然对于像 Go 这样不需要<em>libc 的</em>静态编译应用程序我们就可以替换为如下基镜像</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">FROM</span> gcr.io/distroless/static-debian10</span><br></pre></td></tr></table></figure><p>关于distroless基镜像的更多信息可以参考<a href="https://github.com/GoogleContainerTools/distroless">https://github.com/GoogleContainerTools/distroless</a></p><p><strong>3.及时更新镜像</strong></p><p>使用经常更新的基础镜像，在需要时重构你的镜像。随着新的安全漏洞不断被发现，坚持使用最新的安全补丁是一种通用的安全最佳实践。</p><p>版本控制策略：</p><ul><li>坚持使用稳定或长期支持版本，这些版本会迅速提供安全修复程序。</li><li>提前计划。准备好在基本镜像版本达到生命周期结束或停止接收更新之前删除旧版本并迁移。</li><li>定期重建自己的镜像，从基础发行版、Node、Golang、Python 等获取最新的包。 大多数包或依赖项管理器，如<a href="https://docs.npmjs.com/cli/v6/configuring-npm/package-json#dependencies">npm</a>或<a href="https://golang.org/ref/mod">go mod</a>，将提供指定版本最新的安全更新。</li></ul><p><strong>4.端口暴露</strong></p><p>容器中每个打开的端口都是通往系统的大门。我们应该仅公开应用程序需要的端口，并且避免公开 SSH (22) 等端口。</p><p>我们知道 Dockerfile 提供了<code>EXPOSE</code> 命令有暴露端口，但是该命令仅用于提供信息和用于文档目的。运行容器时，容器不会自动允许所有 EXPOSE 端口的连接（除非在启动容器时使用<code>docker run --publish-all</code>）。</p><p>启动容器时，通过<code>-P</code>暴露的端口应与dockerfile中EXPOSE命令指定的端口一致，这样更便于维护。</p><hr><h4 id="三、敏感数据管理"><a href="#三、敏感数据管理" class="headerlink" title="三、敏感数据管理"></a>三、敏感数据管理</h4><p><strong>1.凭证和密钥</strong></p><p>禁止在 Dockerfile 指令（环境变量、参数或其他任何命令中）中放入凭据和密钥。</p><p><strong>在复制文件到镜像时，即使文件在 Dockerfile 的后续指令中被删除，它仍然可以在之前的层上访问。因为镜像分层原理，你的文件并没有真正被删除，只是“隐藏”在最终文件系统中。</strong>因此在构建镜像时，我们应该遵循以下做法：</p><ul><li>如果应用程序支持<strong>通过环境变量进行配置</strong>，我们可以通过docker run 中的 <code>-e</code> 选项配置，或者使用<a href="https://docs.docker.com/engine/swarm/secrets/">Docker secrets</a>、<a href="https://kubernetes.io/docs/concepts/configuration/secret/">Kubernetes secrets</a>提供值作为环境变量。</li><li><strong>使用配置文件</strong>并在<a href="https://kubernetes.io/docs/concepts/storage/volumes/#secret">docker 中</a><a href="https://docs.docker.com/storage/bind-mounts/">绑定挂载</a>配置文件，或者<a href="https://kubernetes.io/docs/concepts/storage/volumes/#secret">使用Kubernetes secret 挂载</a>。</li></ul><p>关于<code>secrets</code>的使用会在后面文章中详细介绍。</p><p><strong>2.ADD、COPY</strong></p><p>ADD 和 COPY 指令在 Dockerfile 中提供类似的功能。但是COPY 更为明确。</p><p>除非我们确实需要 使用ADD 功能，例如从 URL 或从 tar 文件添加文件。不然最好使用 COPY，COPY 的结果更具可预测性且不易出错。</p><p>在某些情况下，最好使用 RUN 指令而不是 ADD 来下载使用<em>curl</em>或<em>wget</em>的包，解压缩然后删除原始文件，减少层数。</p><p><strong>3.构建上下文与dockerignore</strong></p><p>在构建时我们通常使用<code>.</code>作为上下文</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#docker build -t images:v1 .</span></span><br></pre></td></tr></table></figure><p>使用 <code>.</code>作为上下文时我们需要谨慎些，因为docker CLI会将上下文中机密或不必要的文件添加到守护进程，甚至到容器中，例如配置文件、凭据、备份、锁定文件、临时文件、源、子文件夹、点文件等等。</p><p>在比如：</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">COPY</span><span class="bash"> . /server</span></span><br></pre></td></tr></table></figure><p>此时会将目录下所有内容都添加到镜像中，包括Dockfile本身。</p><p>所以正确做法是创建一个包含需要在容器内复制文件的文件夹，将其用作构建上下文，并在可能的情况下明确 COPY 指令（避免使用通配符）。例如：</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#docker build -t images:v1 build_files/</span></span><br></pre></td></tr></table></figure><p>为了排除不必要的文件，我们也可以创建一个<code>.dockerignore</code>文件，在其中明确排除的文件和目录。</p><hr><p>以上是容器构建时常见安全问题与相关处理措施，容器安全涉及面广，遍布整个devops流程中。有兴趣的同学可以另外一个位面介入深究。</p><h4 id="NEXT"><a href="#NEXT" class="headerlink" title="NEXT"></a>NEXT</h4><ul><li>Docker容器secrets详解</li><li>Docker容器减小镜像尺寸实践</li></ul><hr><p><strong>希望小作文对你有些许帮助，如果内容有误请指正。</strong></p><p><strong>您可以随意转载、修改、发布本文章，无需经过本人同意。</strong> </p>]]></content>
    
    
      
      
    <summary type="html">&lt;h4 id=&quot;写在前面&quot;&gt;&lt;a href=&quot;#写在前面&quot; class=&quot;headerlink&quot; title=&quot;写在前面&quot;&gt;&lt;/a&gt;写在前面&lt;/h4&gt;&lt;p&gt;确保容器中服务与应用安全是容器化演进的关键点。容器安全涉及到应用开发与维护的整个生命周期，本文主要从镜像构建的视角来看doc</summary>
      
    
    
    
    <category term="docker" scheme="https://iqsing.github.io/categories/docker/"/>
    
    
    <category term="dockerfile" scheme="https://iqsing.github.io/tags/dockerfile/"/>
    
  </entry>
  
  <entry>
    <title>Dockerfile 多阶段构建实践</title>
    <link href="https://iqsing.github.io/2021/08/25/Dockerfile%20%E5%A4%9A%E9%98%B6%E6%AE%B5%E6%9E%84%E5%BB%BA%E5%AE%9E%E8%B7%B5/"/>
    <id>https://iqsing.github.io/2021/08/25/Dockerfile%20%E5%A4%9A%E9%98%B6%E6%AE%B5%E6%9E%84%E5%BB%BA%E5%AE%9E%E8%B7%B5/</id>
    <published>2021-08-25T04:31:21.000Z</published>
    <updated>2022-02-04T05:16:11.686Z</updated>
    
    <content type="html"><![CDATA[<h4 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h4><p>在Docker Engine 17.05 中引入了多阶段构建，以此降低构建复杂度，同时使缩小镜像尺寸更为简单。这篇小作文我们来学习一下如何编写实现多阶段构建的Dockerfile</p><p>关于dockerfile基础编写可参考之前<a href="">docker容器dockerfile详解</a></p><hr><h4 id="一-、不使用多阶段构建"><a href="#一-、不使用多阶段构建" class="headerlink" title="一 、不使用多阶段构建"></a>一 、不使用多阶段构建</h4><p>我们知道在Dockerfile中每新增一个指令都会在镜像中生产新的层，一个高效的Dockerfile应该在继续下一层之前清除之前所有不需要的资源。</p><p>不使用多阶段构建时，<strong>我们通常会创建两dockerfile文件，一个用于开发及编译应用，另一个用于构建精简的生产镜像。</strong>这样能比较大限度的减小生产镜像的大小。</p><p>我们以一个go应用来看看。我首先会创建一个dockerfile，构建这个镜像的主要目的就是编译我们的应用。</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">FROM</span> golang:<span class="number">1.16</span></span><br><span class="line"><span class="keyword">WORKDIR</span><span class="bash"> /go/src</span></span><br><span class="line"><span class="keyword">COPY</span><span class="bash"> app.go ./</span></span><br><span class="line"><span class="comment">#go编译</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> go build  -o myapp app.go</span></span><br></pre></td></tr></table></figure><p>构建镜像</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost dockerfiles]<span class="comment"># docker build -t builder_app:v1 .</span></span><br><span class="line">Sending build context to Docker daemon  3.072kB</span><br><span class="line">Step 1/4 : FROM golang:1.16</span><br><span class="line"> ---&gt; 019c7b2e3cb8</span><br><span class="line">Step 2/4 : WORKDIR /go/src</span><br><span class="line"> ---&gt; Using cache</span><br><span class="line"> ---&gt; 15362720e897</span><br><span class="line">Step 3/4 : COPY app.go ./</span><br><span class="line"> ---&gt; Using cache</span><br><span class="line"> ---&gt; 8f14ac97a68a</span><br><span class="line">Step 4/4 : RUN go build  -o myapp app.go</span><br><span class="line"> ---&gt; Running <span class="keyword">in</span> 4368cc4617a7</span><br><span class="line">Removing intermediate container 4368cc4617a7</span><br><span class="line"> ---&gt; 631f67587803</span><br><span class="line">Successfully built 631f67587803</span><br><span class="line">Successfully tagged builder_app:v1</span><br></pre></td></tr></table></figure><p>这样在这个镜像中就包含了我们编译后的应用myapp，现在我们可以创建容器将myapp拷贝到宿主机等待后续使用。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># docker create --name builder builder_app:v1</span></span><br><span class="line">fafc1cf7ffa42e06d19430b807d24eafe0bf731fc45ff0ecf31ada5a6075f1d5</span><br><span class="line"><span class="comment"># docker cp builder:/go/src/myapp ./</span></span><br></pre></td></tr></table></figure><p>我们有了应用，下一步就是构建生产镜像</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">FROM</span> scratch</span><br><span class="line"><span class="keyword">WORKDIR</span><span class="bash"> /server</span></span><br><span class="line"><span class="keyword">COPY</span><span class="bash"> myapp ./</span></span><br><span class="line"><span class="keyword">CMD</span><span class="bash"> [<span class="string">&quot;./myapp&quot;</span>]</span></span><br></pre></td></tr></table></figure><p>由于此时我们不需要其他依赖环境，所以我们采用scratch这个空镜像，不仅可以减小容器尺寸，还可以提高安全性。</p><p>构建镜像</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#docker build  --no-cache -t server_app:v1 .</span></span><br></pre></td></tr></table></figure><p>我们看一次构建的两个镜像大小</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># docker images </span></span><br><span class="line">REPOSITORY            TAG       IMAGE ID       CREATED          SIZE</span><br><span class="line">server_app            v1        6ebc0833cad0   6 minutes ago    1.94MB</span><br><span class="line">builder_app           v1        801f0b615004   23 minutes ago   921MB</span><br></pre></td></tr></table></figure><p>显然在不使用多阶段构建时，我们也可以构建出生产镜像，<strong>但是我们需要维护两个dockerfile，需要将app遗留到本地，并且带来了更多存储空间开销。</strong>在使用多阶段构建时能比较好的解决以上问题。</p><hr><h4 id="二、使用多阶段构建"><a href="#二、使用多阶段构建" class="headerlink" title="二、使用多阶段构建"></a>二、使用多阶段构建</h4><p>在一个Dockerfile中使用多个<code>FROM</code>指令，每个<code>FROM</code>都可以使用不同的基镜像，并且每条指令都将开始新阶段构建。在多阶段构建中，我们可以将资源从一个阶段复制到另一个阶段，在最终镜像中只保留我们所需要的内容。</p><p>我们将上面实例的两个Dockerfile合并为如下：</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#阶段1</span></span><br><span class="line"><span class="keyword">FROM</span> golang:<span class="number">1.16</span></span><br><span class="line"><span class="keyword">WORKDIR</span><span class="bash"> /go/src</span></span><br><span class="line"><span class="keyword">COPY</span><span class="bash"> app.go ./</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> go build app.go -o myapp</span></span><br><span class="line"><span class="comment">#阶段2</span></span><br><span class="line"><span class="keyword">FROM</span> scratch</span><br><span class="line"><span class="keyword">WORKDIR</span><span class="bash"> /server</span></span><br><span class="line"><span class="keyword">COPY</span><span class="bash"> --from=0 /go/src/myapp ./</span></span><br><span class="line"><span class="keyword">CMD</span><span class="bash"> [<span class="string">&quot;./myapp&quot;</span>]</span></span><br></pre></td></tr></table></figure><p>构建镜像</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># docker build --no-cache  -t server_app:v2 .</span></span><br></pre></td></tr></table></figure><p>查看构建好的镜像</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># docker images</span></span><br><span class="line">REPOSITORY            TAG       IMAGE ID       CREATED              SIZE</span><br><span class="line">server_app            v2        20225cb1ea6b   12 seconds ago       1.94MB</span><br></pre></td></tr></table></figure><p>这样我们无需创建额外镜像，以更简单的方式构建出了同样微小的目标镜像。可以看到在多阶段构建dockerfile中最关键的是<code>COPY --from=0 /go/src/myapp ./</code>  通过<code> --from=0</code>指定我们资源来源，这里的0即是指第一阶段。</p><h5 id="命令构建阶段"><a href="#命令构建阶段" class="headerlink" title="命令构建阶段"></a>命令构建阶段</h5><p>默认情况下构建阶段没有名称，我们可以通过整数0~N来引用，即第一个from从0开始。其实我们还可以在<code>FROM</code>指令中添加<code>AS &lt;NAME&gt;</code> 来命名构建阶段，接着在COPY指令中通过<code>&lt;NAME&gt;</code>引用。我们对上面dockerfile修改如下：</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#阶段1命名为builder</span></span><br><span class="line"><span class="keyword">FROM</span> golang:<span class="number">1.16</span> as builder</span><br><span class="line"><span class="keyword">WORKDIR</span><span class="bash"> /go/src</span></span><br><span class="line"><span class="keyword">COPY</span><span class="bash"> app.go ./</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> go build app.go -o myapp</span></span><br><span class="line"><span class="comment">#阶段2</span></span><br><span class="line"><span class="keyword">FROM</span> scratch</span><br><span class="line"><span class="keyword">WORKDIR</span><span class="bash"> /server</span></span><br><span class="line"><span class="comment">#通过名称引用</span></span><br><span class="line"><span class="keyword">COPY</span><span class="bash"> --from=builder /go/src/myapp ./</span></span><br><span class="line"><span class="keyword">CMD</span><span class="bash"> [<span class="string">&quot;./myapp&quot;</span>]</span></span><br></pre></td></tr></table></figure><h5 id="只构建某个阶段"><a href="#只构建某个阶段" class="headerlink" title="只构建某个阶段"></a>只构建某个阶段</h5><p>构建镜像时，您不一定需要构建整个 Dockerfile，我们可以通过<code>--target</code>参数指定某个目标阶段构建，比如我们开发阶段我们只构建builder阶段进行测试。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#docker build --target builder -t builder_app:v2 .</span></span><br></pre></td></tr></table></figure><h5 id="使用外部镜像"><a href="#使用外部镜像" class="headerlink" title="使用外部镜像"></a>使用外部镜像</h5><p>使用多阶段构建时，我们局限于从之前在 Dockerfile 中创建的阶段进行复制。还可以使用<code>COPY --from</code>指令从单独的镜像复制，如本地镜像名称、本地或 Dockerhub上可用的标签或标签 ID。Docker 客户端在必要时会拉取需要的镜像到本地。</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">COPY</span><span class="bash"> --from  httpd:latest /usr/<span class="built_in">local</span>/apache2/conf/httpd.conf ./httpd.conf</span></span><br></pre></td></tr></table></figure><h5 id="从上一阶段创建新的阶段"><a href="#从上一阶段创建新的阶段" class="headerlink" title="从上一阶段创建新的阶段"></a>从上一阶段创建新的阶段</h5><p>我们可以通过FROM指令来引用上一阶段作为新阶段的开始</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#阶段1命名为builder</span></span><br><span class="line"><span class="keyword">FROM</span> golang:<span class="number">1.16</span> as builder</span><br><span class="line"><span class="keyword">WORKDIR</span><span class="bash"> /go/src</span></span><br><span class="line"><span class="keyword">COPY</span><span class="bash"> app.go ./</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> go build app.go -o myapp</span></span><br><span class="line"><span class="comment">#阶段2</span></span><br><span class="line"><span class="keyword">FROM</span> builder as builder_ex</span><br><span class="line"><span class="keyword">ADD</span><span class="bash"> dest.tar ./</span></span><br><span class="line">...</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>通过上面我们对dockerfile多阶段构建有了一个整体的了解。</p><hr><h4 id="NEXT"><a href="#NEXT" class="headerlink" title="NEXT"></a>NEXT</h4><ul><li>Dockerfile 与Docker容器安全实践</li></ul><p><strong>希望小作文对你有些许帮助，如果内容有误请指正。</strong></p><p><strong>您可以随意转载、修改、发布本文章，无需经过本人同意。</strong> 个人blog：<a href="https://iqsing.github.io/">iqsing.github.io</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h4 id=&quot;写在前面&quot;&gt;&lt;a href=&quot;#写在前面&quot; class=&quot;headerlink&quot; title=&quot;写在前面&quot;&gt;&lt;/a&gt;写在前面&lt;/h4&gt;&lt;p&gt;在Docker Engine 17.05 中引入了多阶段构建，以此降低构建复杂度，同时使缩小镜像尺寸更为简单。这篇小作文我们</summary>
      
    
    
    
    <category term="docker" scheme="https://iqsing.github.io/categories/docker/"/>
    
    
    <category term="dockerfile" scheme="https://iqsing.github.io/tags/dockerfile/"/>
    
  </entry>
  
  <entry>
    <title>dockerfile中ENTRYPOINT与CMD的结合</title>
    <link href="https://iqsing.github.io/2021/08/23/dockerfile%E4%B8%ADENTRYPOINT%E4%B8%8ECMD%E7%9A%84%E7%BB%93%E5%90%88/"/>
    <id>https://iqsing.github.io/2021/08/23/dockerfile%E4%B8%ADENTRYPOINT%E4%B8%8ECMD%E7%9A%84%E7%BB%93%E5%90%88/</id>
    <published>2021-08-22T17:30:21.000Z</published>
    <updated>2022-02-04T05:16:11.745Z</updated>
    
    <content type="html"><![CDATA[<h4 id="一、写在前面"><a href="#一、写在前面" class="headerlink" title="一、写在前面"></a>一、写在前面</h4><p>我们在上篇小作文<a href="">docker容器dockerfile详解</a>对中dockerfile有了比较全面的认识，我们也提到<code>ENTRYPOINT</code>和<code>CMD</code>都可以指定容器启动命令。因为这两个命令是掌握dockerfile编写的核心，所以这边还是单独拿出来再讲一讲。</p><hr><h4 id="二、CMD-与-ENTRYPOINT主要区别"><a href="#二、CMD-与-ENTRYPOINT主要区别" class="headerlink" title="二、CMD 与 ENTRYPOINT主要区别"></a>二、CMD 与 ENTRYPOINT主要区别</h4><p>我们直接进入主题，CMD 与 ENTRYPOINT都是用于指定启动容器执行的命令，区别在于：</p><ul><li>当docker run 命令中有参数时，守护进程会忽略CMD命令。</li><li>使用ENTRYPOINT指令不会忽略，并且会接收docker run 参数附加到命令行中。</li></ul><p>为了使构建的容器可以正常启动，我们编写的dockerfile文件必须包含一个CMD或ENTRYPOINT指令。</p><hr><h4 id="三、CMD-与-ENTRYPOINT的结合使用"><a href="#三、CMD-与-ENTRYPOINT的结合使用" class="headerlink" title="三、CMD 与 ENTRYPOINT的结合使用"></a>三、CMD 与 ENTRYPOINT的结合使用</h4><h5 id="1-CMD"><a href="#1-CMD" class="headerlink" title="1.CMD"></a>1.CMD</h5><p><code>CMD</code>指令有三种形式：</p><ul><li><code>CMD [&quot;executable&quot;,&quot;param1&quot;,&quot;param2&quot;]</code>（<em>exec</em>形式，这是首选形式）</li><li><code>CMD [&quot;param1&quot;,&quot;param2&quot;]</code>（作为<em>ENTRYPOINT 的默认参数</em>）</li><li><code>CMD command param1 param2</code>（shell形式）</li></ul><p>dockerfile文件中包含多个CMD时，只有最后一个被加载使用。</p><p>我们在dockerhub中搜索centos官方镜像，看一下的官方dockerfile文件。</p><p><img src="https://markdown-1257692304.cos.ap-nanjing.myqcloud.com/markdown_img/image-20210822142847209.png" alt="image-20210822142847209"></p><p>基本上每一个官方镜像都会为我们提供各自版本的dockerfile链接，如下：</p><p><img src="https://markdown-1257692304.cos.ap-nanjing.myqcloud.com/markdown_img/image-20210822143135366.png" alt="image-20210822143135366"></p><p>我们查看<code>latest</code>标签的dockerfile </p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">FROM</span> scratch</span><br><span class="line"><span class="keyword">ADD</span><span class="bash"> centos-8-x86_64.tar.xz /</span></span><br><span class="line"><span class="keyword">LABEL</span><span class="bash"> org.label-schema.schema-version=<span class="string">&quot;1.0&quot;</span>     org.label-schema.name=<span class="string">&quot;CentOS Base Image&quot;</span>     org.label-schema.vendor=<span class="string">&quot;CentOS&quot;</span>     org.label-schema.license=<span class="string">&quot;GPLv2&quot;</span>     org.label-schema.build-date=<span class="string">&quot;20201204&quot;</span></span></span><br><span class="line"><span class="keyword">CMD</span><span class="bash"> [<span class="string">&quot;/bin/bash&quot;</span>]</span></span><br></pre></td></tr></table></figure><p>只有四行，这就是构建一个<code>latest</code>版本<em>centos8.3.2011</em>镜像的dockerfile全部内容。指定基镜像（这里从scratch这个空镜像开始构建），添加rootfs内容，打标签，通过CMD指定启动命令。</p><p>不止centos，其他debian、ubuntu、busybox等镜像都只需通过CMD指定启动命令。比如busybox更为简约：</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">FROM</span> scratch</span><br><span class="line"><span class="keyword">ADD</span><span class="bash"> busybox.tar.xz /</span></span><br><span class="line"><span class="keyword">CMD</span><span class="bash"> [<span class="string">&quot;sh&quot;</span>]</span></span><br></pre></td></tr></table></figure><p><strong>这种基础类、工具类镜像的构建我们只需要指定一个必要CMD来启动容器即可。但是我们编写一个dockerfile并不是为了启动容器而编写，大多数时候我们要在容器运行我们的app，运行我们的服务。</strong></p><p>当然通过CMD也可以启动，可是如此一来有一个缺陷，我们上面说到的<strong>CMD的启动命令会被docker run 参数代替。</strong></p><p>我们有下面Dockerfile</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost dockerfiles]<span class="comment"># cat Dockerfile </span></span><br><span class="line"><span class="keyword">FROM</span> centos</span><br><span class="line"><span class="keyword">CMD</span><span class="bash"> [<span class="string">&quot;/bin/top&quot;</span>,<span class="string">&quot;-b&quot;</span>]</span></span><br></pre></td></tr></table></figure><p>构建后，使用参数ps启动容器。</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost dockerfiles]<span class="comment"># docker run  -it  centos_top:v1  ps</span></span><br><span class="line">  PID TTY          TIME <span class="keyword">CMD</span><span class="bash"></span></span><br><span class="line"><span class="bash">    1 pts/0    00:00:00 ps</span></span><br></pre></td></tr></table></figure><p>可看看到启动容器后<code>top -b</code> 已经被替换为ps，<strong>并非实现参数的替换</strong>。显然这不是我们想要的。<strong>有没有什么办法既可以默认启动应用，又可以加载到docker run 参数？</strong>这就是接下来ENTRYPOINT与CMD的妙用。</p><h5 id="2-ENTRYPOINT结合CMD"><a href="#2-ENTRYPOINT结合CMD" class="headerlink" title="2.ENTRYPOINT结合CMD"></a>2.ENTRYPOINT结合CMD</h5><p><code>ENTRYPOINT</code>的exec和shell形式： </p><ul><li><code>ENTRYPOINT [&quot;executable&quot;, &quot;param1&quot;, &quot;param2&quot;]</code></li><li><code>ENTRYPOINT command param1 param2</code></li></ul><p>上面我们提到<code>CMD [&quot;param1&quot;,&quot;param2&quot;]</code>形式可以作为ENTRYPOINT参数，同时ENTRYPOINT 指定的命令无法被docker run 参数取代。<strong>假如我们把CMD和ENTRYPOINT两个指令相结合，这样我们就可以通过CMD来接收docker run 参数，然后把参数传递给ENTRYPOINT执行。</strong></p><p>我们以nginx官方dockerfile latest版本<em>1.21</em>为例</p><p><img src="https://markdown-1257692304.cos.ap-nanjing.myqcloud.com/markdown_img/image-20210823005357483.png" alt="image-20210823005357483"></p><p>首先我们查看<code>Dockerfile</code>，这里我们只关注启动命令，如下：</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line"><span class="keyword">COPY</span><span class="bash"> docker-entrypoint.sh /</span></span><br><span class="line"><span class="keyword">COPY</span><span class="bash"> 10-listen-on-ipv6-by-default.sh /docker-entrypoint.d</span></span><br><span class="line"><span class="keyword">COPY</span><span class="bash"> 20-envsubst-on-templates.sh /docker-entrypoint.d</span></span><br><span class="line"><span class="keyword">COPY</span><span class="bash"> 30-tune-worker-processes.sh /docker-entrypoint.d</span></span><br><span class="line"><span class="keyword">ENTRYPOINT</span><span class="bash"> [<span class="string">&quot;/docker-entrypoint.sh&quot;</span>]</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">EXPOSE</span> <span class="number">80</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">STOPSIGNAL</span> SIGQUIT</span><br><span class="line"></span><br><span class="line"><span class="keyword">CMD</span><span class="bash"> [<span class="string">&quot;nginx&quot;</span>, <span class="string">&quot;-g&quot;</span>, <span class="string">&quot;daemon off;&quot;</span>]</span></span><br></pre></td></tr></table></figure><p>从上面我们可以看到，在启动nginx容器时首先运行<code>docker-entrypoint.sh</code>脚本并把CMD命令中的参数<code>nginx -g &quot;daemon off;&quot;</code>传递进来。即docker run不添加参数时启动容器相当于执行如下脚本与默认参数。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#docker-entrypoint.sh nginx -g &quot;daemon off;&quot;</span></span><br></pre></td></tr></table></figure><p><strong>当我们使用docker run 传入参数会怎样？</strong></p><p>我启动nginx-debug</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#docker run -dt nginx nginx-debug -g &quot;daemon off;&quot;</span></span><br></pre></td></tr></table></figure><p>此时启动容器相当于执行如下脚本与参数</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#docker-entrypoint.sh nginx-debug -g &quot;daemon off;&quot;</span></span><br></pre></td></tr></table></figure><p>我们通过ps来看一下我们启动的容器</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost dockerfiles]<span class="comment"># ps -ef|grep nginx</span></span><br><span class="line">root      6327  6306  0 Aug12 pts/0    00:00:00 nginx: master process nginx -g daemon off;</span><br><span class="line">101       6384  6327  0 Aug12 pts/0    00:00:00 nginx: worker process</span><br><span class="line">101       6385  6327  0 Aug12 pts/0    00:00:00 nginx: worker process</span><br><span class="line">root     16800 16780  3 12:51 pts/0    00:00:00 nginx: master process nginx-debug -g daemon off;</span><br><span class="line">101      16857 16800  0 12:51 pts/0    00:00:00 nginx: worker process</span><br><span class="line">101      16858 16800  0 12:51 pts/0    00:00:00 nginx: worker process</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>显然我们两种参数nginx、nginx-debug的容器都启动成功！</p><p><strong>也就是说我们通过<code>ENTRYPOINT [&quot;/docker-entrypoint.sh&quot;]</code>指定的命令在启动时无论如何都会执行，并且可以接收到了docker run 的参数。</strong></p><p><strong>docker-entrypoint.sh</strong>是什么？docker-entrypoint.sh这是一个预处理脚本通常用来过滤命令行参数或者执行exec 来启动容器为1的进程。</p><hr><p>通过ENTRYPOINT+CMD实现命令默认参数或接收docker run 参数是一种非常流行并且有用的dockerfile编写方式。</p><p><strong>希望小作文对你有些许帮助，如果内容有错误请指正。</strong></p><p><strong>您可以随意转载、修改、发布本文章，无需经过本人同意。</strong> 个人blog：<a href="https://iqsing.github.io/">iqsing.github.io</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h4 id=&quot;一、写在前面&quot;&gt;&lt;a href=&quot;#一、写在前面&quot; class=&quot;headerlink&quot; title=&quot;一、写在前面&quot;&gt;&lt;/a&gt;一、写在前面&lt;/h4&gt;&lt;p&gt;我们在上篇小作文&lt;a href=&quot;&quot;&gt;docker容器dockerfile详解&lt;/a&gt;对中dockerfil</summary>
      
    
    
    
    <category term="docker" scheme="https://iqsing.github.io/categories/docker/"/>
    
    
    <category term="dockerfile" scheme="https://iqsing.github.io/tags/dockerfile/"/>
    
  </entry>
  
  <entry>
    <title>docker容器dockerfile详解</title>
    <link href="https://iqsing.github.io/2021/08/19/docker%E5%AE%B9%E5%99%A8dockerfile%E8%AF%A6%E8%A7%A3/"/>
    <id>https://iqsing.github.io/2021/08/19/docker%E5%AE%B9%E5%99%A8dockerfile%E8%AF%A6%E8%A7%A3/</id>
    <published>2021-08-19T02:57:21.000Z</published>
    <updated>2022-02-04T05:16:11.762Z</updated>
    
    <content type="html"><![CDATA[<p>docker公司在容器技术发展中提出了<strong>镜像分层</strong>的理念，可以说也是这个革命性的理念让原本只不过是整合linux内核特性的容器，开始野蛮生长。</p><p>docker通过UnionFS联合文件系统将镜像的分层实现合并,关于镜像相关知识有兴趣的同学可参考我们之前文章《docker容器技术基础之联合文件系统OverlayFS》</p><p>本文是对docker官方文档<a href="https://docs.docker.com/engine/reference/builder/">Dockerfile reference</a>学习与实践，在学习docker容器相关技术的同学别光收藏，你要动起来！实践起来！</p><p><strong>提示：没有人比docker公司更懂docker，本小作文含部分自己的理解，有英文阅读习惯的同学，建议直接阅读官方文档哈。</strong></p><hr><h4 id="docker-build"><a href="#docker-build" class="headerlink" title="docker build"></a>docker build</h4><p>Dockerfile是一个镜像构建命令集合的文本文件，下面是我们最常见的Dockerfile构建,假如我们目录下有一个文件Dockerfile</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost nginx_project]<span class="comment"># ls</span></span><br><span class="line">Dockerfile</span><br><span class="line">[root@localhost nginx_project]<span class="comment"># docker build -t nginx:v1 .</span></span><br></pre></td></tr></table></figure><p>通过build指定了目标镜像的<strong>标签</strong>为nginx:v1，以及Dockerfile的<strong>上下文context .</strong> </p><p><strong>什么是docker上下文？</strong></p><p><strong>一个面向服务端的目录夹结构，除了Dockerfile，你的一切构建资源都应该在这个目录（指定的上下文）中。</strong></p><p>上下文是递归处理的。因此， 如果是<code>PATH</code>则包含任何子目录，如果是一个<code>URL</code>则包含存储库及其子模块。</p><p>关键点，构建是由 Docker 守护程序运行，而不是由 CLI 运行，所以docker会把上下文资源打包传输给守护进程进行构建，为了减少不必要的臃肿，最好从一个空目录作为上下文开始，并将 Dockerfile 保存在该目录中。仅添加构建 Dockerfile 所需的文件。</p><p>我们可以使用<code>-f</code>选项指定dockerfile</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost folder]<span class="comment"># docker build -f ../Dockerfile -t nginx:v1 .</span></span><br></pre></td></tr></table></figure><p>使用多个<code>-t</code>选项保持多个tag</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost folder]<span class="comment"># docker build  -t nginx:v1 -t dockerhub.com/nginx:v2 .</span></span><br><span class="line">Sending build context to Docker daemon  1.583kB</span><br><span class="line">Step 1/2 : FROM nginx</span><br><span class="line"> ---&gt; 08b152afcfae</span><br><span class="line">Step 2/2 : run <span class="built_in">echo</span> 123</span><br><span class="line"> ---&gt; Using cache</span><br><span class="line"> ---&gt; 3b636c79fbfa</span><br><span class="line">Successfully built 3b636c79fbfa</span><br><span class="line">Successfully tagged nginx:v1</span><br><span class="line">Successfully tagged dockerhub.com/nginx:v2</span><br></pre></td></tr></table></figure><p>这样就构建两个不同tag的同一ID镜像</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost folder]<span class="comment"># docker images</span></span><br><span class="line">REPOSITORY            TAG       IMAGE ID       CREATED          SIZE</span><br><span class="line">dockerhub.com/nginx   v2        3b636c79fbfa   23 minutes ago   133MB</span><br><span class="line">nginx                 v1        3b636c79fbfa   23 minutes ago   133MB</span><br></pre></td></tr></table></figure><h4 id="BuildKit"><a href="#BuildKit" class="headerlink" title="BuildKit"></a>BuildKit</h4><p>buildkit将 Dockerfile 变成了 Docker 镜像。它不只是构建 Docker 镜像；它可以构建 OCI 图像和其他几种输出格式。</p><p>从版本18.09开始，Docker支持由<a href="https://github.com/moby/buildkit">moby / buildkit</a>项目提供的用于执行构建的新后端。与旧的实现相比，BuildKit后端提供了许多好处。例如，BuildKit可以：</p><ul><li>检测并跳过执行未使用的构建阶段。</li><li>平行构建独立的构建阶段。</li><li>在不同的构建过程中,只增加传输构建上下文中的更改文件。</li><li>在构建上下文中检测并跳过传输未使用的文件。</li><li>使用外部Dockerfile实现许多新功能。</li><li>避免与API的其他部分(中间镜像和容器)产生副作用。</li><li>优先处理您的构建缓存,以便自动修剪。</li></ul><p>要使用BuildKit后端，只需要在调用 <code>DOCKER_BUILDKIT=1</code> <code>docker build</code> 之前在CLI上设置环境变量DOCKER_BUILDKIT = 1。或者配置/etc/docker/daemon.json启用。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost folder]<span class="comment">#  DOCKER_BUILDKIT=1 docker build -f ../Dockerfile -t nginx:v1 -t dockerhub.com/nginx:v2 .</span></span><br><span class="line">[+] Building 5.2s (6/6) FINISHED                                                                           </span><br><span class="line"> =&gt; [internal] load build definition from Dockerfile                                                  0.7s</span><br><span class="line"> =&gt; =&gt; transferring dockerfile: 118B                                                                  0.0s</span><br><span class="line"> =&gt; [internal] load .dockerignore                                                                     0.6s</span><br><span class="line"> =&gt; =&gt; transferring context: 2B                                                                       0.0s</span><br><span class="line"> =&gt; [internal] load metadata <span class="keyword">for</span> docker.io/library/nginx:latest                                       0.0s</span><br><span class="line"> =&gt; [1/2] FROM docker.io/library/nginx                                                                2.2s</span><br><span class="line"> =&gt; [2/2] RUN <span class="built_in">echo</span> 123                                                                                1.3s</span><br><span class="line"> =&gt; exporting to image                                                                                0.5s </span><br><span class="line"> =&gt; =&gt; exporting layers                                                                               0.2s</span><br><span class="line"> =&gt; =&gt; writing image sha256:813b09c58322dce98ee28e717baeb9f3593ce3e46a032488949250f761004495          0.0s</span><br><span class="line"> =&gt; =&gt; naming to docker.io/library/nginx:v1                                                           0.0s</span><br><span class="line"> =&gt; =&gt; naming to dockerhub.com/nginx:v2 </span><br></pre></td></tr></table></figure><hr><h4 id="dockerfile格式"><a href="#dockerfile格式" class="headerlink" title="dockerfile格式"></a>dockerfile格式</h4><h5 id="1、注释"><a href="#1、注释" class="headerlink" title="1、注释"></a>1、注释</h5><p>一个标准的dockerfile，注释是必须的。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#这是dockerfile注释,dockerfile中指令以&quot;CMD args&quot;格式出现</span></span><br><span class="line">CMD args</span><br><span class="line">CMD args</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>一个<code>Dockerfile</code> <strong>第一个指令必须是<code>FROM</code>指令</strong>，用于指定基础镜像，那么基础镜像的父镜像从哪里来？答案是<code>scratch</code>带有该<code>FROM scratch</code>指令的 Dockerfile会创建一个<strong>基本映像</strong>。</p><h5 id="2-解析器指令"><a href="#2-解析器指令" class="headerlink" title="2.解析器指令"></a>2.解析器指令</h5><p>解析器指令是可选的，会影响 a<code>Dockerfile</code>中后续行的处理方式。解析器指令不会向构建添加层，也不会显示为构建步骤，单个指令只能使用一次。</p><p>dockerfile目前支持以下两个解析器指令：</p><ul><li><code>syntax</code></li><li><code>escape</code></li></ul><h5 id="2-1syntax"><a href="#2-1syntax" class="headerlink" title="2.1syntax"></a>2.1syntax</h5><p>此功能仅在使用<a href="https://docs.docker.com/engine/reference/builder/#buildkit">BuildKit</a>后端时可用，在使用经典构建器后端时会被忽略。</p><p>我们可以在dockerfile文件开头指定此dockerfile语法解析器，如下：</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># syntax=docker/dockerfile:1</span></span><br><span class="line"><span class="comment"># syntax=docker.io/docker/dockerfile:1</span></span><br><span class="line"><span class="comment"># syntax=example.com/user/repo:tag@sha256:abcdef...</span></span><br></pre></td></tr></table></figure><p>通过syntax自定义 Dockerfile 语法解析器可以实现如下：</p><ul><li>在不更新 Docker 守护进程的情况下自动修复错误</li><li>确保所有用户都使用相同的解析器来构建您的 Dockerfile</li><li>无需更新 Docker 守护程序即可使用最新功能</li><li>在将新功能或第三方功能集成到 Docker 守护进程之前试用它们</li><li>使用<a href="https://github.com/moby/buildkit#exploring-llb">替代的构建定义，或创建自己的定义</a></li></ul><p>官方dockerfile解析器：</p><ul><li><code>docker/dockerfile:1</code>  不断更新最新的<code>1.x.x</code>次要<em>和</em>补丁版本</li><li><code>docker/dockerfile:1.2</code>  保持更新最新的<code>1.2.x</code>补丁版本，一旦版本<code>1.3.0</code>发布就停止接收更新。</li><li><code>docker/dockerfile:1.2.1</code>  不可变：从不更新1.2版本</li></ul><p>比如我们使用1.2最新补丁版本，我们的Dockerfile如下：</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#syntax=docker/dockerfile:1.2</span></span><br><span class="line"><span class="keyword">FROM</span> busybox</span><br><span class="line"><span class="keyword">run</span><span class="bash"> <span class="built_in">echo</span> 123</span></span><br></pre></td></tr></table></figure><p>我们启用buildkit构建</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># DOCKER_BUILDKIT=1 docker build -t busybox:v1 .</span></span><br><span class="line">[+] Building 5.8s (8/8) FINISHED                                                                           </span><br><span class="line"> =&gt; [internal] load build definition from Dockerfile                                                  0.3s</span><br><span class="line"> =&gt; =&gt; transferring dockerfile: 150B                                                                  0.0s</span><br><span class="line"> =&gt; [internal] load .dockerignore                                                                     0.4s</span><br><span class="line"> =&gt; =&gt; transferring context: 2B                                                                       0.0s</span><br><span class="line"> =&gt; resolve image config <span class="keyword">for</span> docker.io/docker/dockerfile:1.2                                          2.6s</span><br><span class="line"> =&gt; CACHED docker-image://docker.io/docker/dockerfile:1.2@sha256:e2a8561e419ab1ba6b2fe6cbdf49fd92b95  0.0s</span><br><span class="line"> =&gt; [internal] load metadata <span class="keyword">for</span> docker.io/library/busybox:latest                                     0.0s</span><br><span class="line"> =&gt; [1/2] FROM docker.io/library/busybox                                                              0.3s</span><br><span class="line"> =&gt; [2/2] RUN <span class="built_in">echo</span> 123                                                                                1.1s</span><br><span class="line"> =&gt; exporting to image                                                                                0.3s</span><br><span class="line"> =&gt; =&gt; exporting layers                                                                               0.3s</span><br><span class="line"> =&gt; =&gt; writing image sha256:bd66a3db9598d942b68450a7ac08117830b4d66b68180b6e9d63599d01bc8a04          0.0s</span><br><span class="line"> =&gt; =&gt; naming to docker.io/library/busybox:v1</span><br></pre></td></tr></table></figure><h5 id="2-2-escape"><a href="#2-2-escape" class="headerlink" title="2.2 escape"></a>2.2 escape</h5><p>通过escape定义dockerfile的换行拼接转义符</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># escape=\   </span></span><br></pre></td></tr></table></figure><p>如果要构建一个window镜像就有大用处了，我们看下面dockerfile</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">FROM</span> microsoft/nanoserver</span><br><span class="line"><span class="keyword">COPY</span><span class="bash"> testfile.txt c:\\</span></span><br><span class="line"><span class="bash">RUN dir c:\</span></span><br></pre></td></tr></table></figure><p>由于默认转义符为<code>\</code>，则在构建的第二步step2会是这样<code>COPY testfile.txt c:\RUN dir c:</code>显然与我们的预期不符。</p><p>我们把转义符换成`号即可</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># escape=`</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">FROM</span> microsoft/nanoserver</span><br><span class="line"><span class="keyword">COPY</span><span class="bash"> testfile.txt c:\ `</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> dir c:\</span></span><br></pre></td></tr></table></figure><h5 id="3-类bash的环境变量"><a href="#3-类bash的环境变量" class="headerlink" title="3.类bash的环境变量"></a>3.类bash的环境变量</h5><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">FROM</span> busybox</span><br><span class="line"><span class="keyword">ENV</span> FOO=/bar</span><br><span class="line"><span class="keyword">WORKDIR</span><span class="bash"> <span class="variable">$&#123;FOO&#125;</span>   <span class="comment"># WORKDIR /bar</span></span></span><br><span class="line"><span class="keyword">ADD</span><span class="bash"> . <span class="variable">$FOO</span>       <span class="comment"># ADD . /bar</span></span></span><br><span class="line"><span class="keyword">COPY</span><span class="bash"> \<span class="variable">$FOO</span> /quux <span class="comment"># COPY $FOO /quux</span></span></span><br></pre></td></tr></table></figure><p><code>$&#123;variable_name&#125;</code>语法还支持<code>bash</code> 指定的一些标准修饰符：</p><ul><li><code>$&#123;variable:-word&#125;</code>表示如果<code>variable</code>变量被设置（存在），则结果将是该值。如果<code>variable</code>未设置，<code>word</code>则将是结果。</li><li><code>$&#123;variable:+word&#125;</code>表示如果<code>variable</code>被设置则为<code>word</code>结果，否则为空字符串。</li></ul><h5 id="4-dockerignore"><a href="#4-dockerignore" class="headerlink" title="4. .dockerignore"></a>4. .dockerignore</h5><p>.dockerignore用于忽略CLI发送到docker守护进程的文件或目录。以下是一个<code>.dockerignore</code>文件</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">#.dockeringre可以有注释</span><br><span class="line">*.md</span><br><span class="line">!README.md</span><br><span class="line">temp?</span><br><span class="line">*/temp*</span><br><span class="line">*/*/temp*</span><br></pre></td></tr></table></figure><table><thead><tr><th align="left">规则</th><th align="left">行为</th></tr></thead><tbody><tr><td align="left"><code>*/temp*</code></td><td align="left">排除名称以<code>temp</code>根目录的任何直接子目录开头的文件和目录。例如，纯文件<code>/somedir/temporary.txt</code>被排除在外，目录<code>/somedir/temp</code>.</td></tr><tr><td align="left"><code>*/*/temp*</code></td><td align="left">排除<code>temp</code>从根目录下两级的任何子目录开始的文件和目录。例如，<code>/somedir/subdir/temporary.txt</code>被排除在外。</td></tr><tr><td align="left"><code>temp?</code></td><td align="left">排除根目录中名称为一个字符扩展名的文件和目录<code>temp</code>。例如，<code>/tempa</code>和<code>/tempb</code>被排除在外。</td></tr><tr><td align="left"><em>！</em></td><td align="left">不排除到文件</td></tr></tbody></table><hr><h4 id="dockerfile命令"><a href="#dockerfile命令" class="headerlink" title="dockerfile命令"></a>dockerfile命令</h4><h5 id="1-FROM"><a href="#1-FROM" class="headerlink" title="1.FROM"></a>1.FROM</h5><p>指定基础镜像。一般格式如下，<code>[]</code>括号内容可省略：</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">FROM</span> [--platform=&lt;platform&gt;] &lt;image&gt;[:&lt;tag&gt;] [AS &lt;name&gt;]</span><br></pre></td></tr></table></figure><p>特别需要注意的是<code>FROM</code>在一个dockerfile中可以多次出现，以实现多阶段构建。并且可以和ARG 参数交互。如下：</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">ARG</span>  CODE_VERSION=latest</span><br><span class="line"><span class="keyword">FROM</span> base:$&#123;CODE_VERSION&#125;</span><br><span class="line"><span class="keyword">CMD</span><span class="bash">  /code/run-app</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">FROM</span> extras:$&#123;CODE_VERSION&#125;</span><br><span class="line"><span class="keyword">CMD</span><span class="bash">  /code/run-extras</span></span><br></pre></td></tr></table></figure><p>我们加载了两个通过arg参数指定的不同版本基础镜像。</p><h5 id="2-RUN"><a href="#2-RUN" class="headerlink" title="2.RUN"></a>2.RUN</h5><p>RUN的两种形式</p><ul><li>RUN <command>        首选， (命令在shell中运行,即默认为/bin/sh -c )</li><li>RUN [“exec”,param1,param2]      </li></ul><p>RUN命令主要是在镜像构建时执行，形成新层。比如我们经常会看到在构建镜像时安装相关软件。</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">RUN</span><span class="bash"> yum install -y gcc </span></span><br></pre></td></tr></table></figure><p>当我们不想使用默认shell是可以采用exec形式实现</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">RUN</span><span class="bash"> [<span class="string">&quot;/bin/bash&quot;</span>,<span class="string">&quot;-c&quot;</span>,<span class="string">&quot;yum install -y gcc&quot;</span>]</span></span><br></pre></td></tr></table></figure><p>当然，exec形式可以不使用shell</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">RUN</span><span class="bash"> [<span class="string">&quot;yum&quot;</span>,<span class="string">&quot;install&quot;</span>,<span class="string">&quot;-y&quot;</span>,<span class="string">&quot;gcc&quot;</span>]</span></span><br></pre></td></tr></table></figure><p><em>EXEC</em>形式被解析为一个JSON阵列，所以必须使用双引号</p><h5 id="3-CMD"><a href="#3-CMD" class="headerlink" title="3.CMD"></a>3.CMD</h5><p><code>CMD</code>指令有三种形式：</p><ul><li><code>CMD [&quot;executable&quot;,&quot;param1&quot;,&quot;param2&quot;]</code>（<em>exec</em>形式，这是首选形式）</li><li><code>CMD [&quot;param1&quot;,&quot;param2&quot;]</code>（作为<em>ENTRYPOINT 的默认参数</em>）</li><li><code>CMD command param1 param2</code>（shell形式）</li></ul><p>一个dockerfile中，应该只写一个CMD，如果有多个只有最后一个生效。在实际编写dockerfie时CMD命令常常用于为<em>ENTRYPOINT</em>提供默认值，后面我们会讲到。</p><p><strong>与RUN相比，CMD在构建时不会执行任何操作，主要用于指定镜像的启动命令。CMD的启动命令可以被docker run 参数代替。</strong></p><p>我们在dockerfile中添加如下CMD命令</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CMD</span><span class="bash"> <span class="built_in">echo</span> hello</span></span><br></pre></td></tr></table></figure><p>构建镜像后，docker run 不添加参数，启动容器</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost dockerfiles]<span class="comment"># docker run centos:v1</span></span><br><span class="line">hello</span><br></pre></td></tr></table></figure><p>当我们在docker run 添加参数后</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost dockerfiles]<span class="comment"># docker run centos_env:v1 echo container</span></span><br><span class="line">container </span><br></pre></td></tr></table></figure><p>显然我们CMD命令echo hello已被docker run中的参数echo container取代。</p><h5 id="4-LABEL"><a href="#4-LABEL" class="headerlink" title="4. LABEL"></a>4. LABEL</h5><p>label用于添加镜像的元数据，采用key-value的形式。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">LABEL &lt;key&gt;=&lt;value&gt;</span><br></pre></td></tr></table></figure><p>比如我们添加如下LABEL</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">LABEL</span><span class="bash"> <span class="string">&quot;miantainer&quot;</span>=<span class="string">&quot;iqsing.github.io&quot;</span></span></span><br><span class="line"><span class="keyword">LABEL</span><span class="bash"> <span class="string">&quot;version&quot;</span>=<span class="string">&quot;v1.2&quot;</span></span></span><br><span class="line"><span class="keyword">LABEL</span><span class="bash"> <span class="string">&quot;author&quot;</span>=<span class="string">&quot;waterman&amp;&amp;iqsing&quot;</span></span></span><br></pre></td></tr></table></figure><p>为了防止创建三层，我们最好通过一个标签来写。</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">LABEL</span><span class="bash"> <span class="string">&quot;miantainer&quot;</span>=<span class="string">&quot;iqsing.github.io&quot;</span> \</span></span><br><span class="line"><span class="bash">      <span class="string">&quot;version&quot;</span>=<span class="string">&quot;v1.2&quot;</span> \</span></span><br><span class="line"><span class="bash">      <span class="string">&quot;author&quot;</span>=<span class="string">&quot;waterman&amp;&amp;iqsing&quot;</span></span></span><br></pre></td></tr></table></figure><p>我们通过docker inspect 来查看镜像label信息</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">#docker inspect centos_labels:v1</span><br><span class="line"></span><br><span class="line"><span class="string">&quot;Labels&quot;</span>: &#123;</span><br><span class="line">    <span class="attr">&quot;author&quot;</span>: <span class="string">&quot;waterman&amp;&amp;iqsing&quot;</span>,</span><br><span class="line">    <span class="attr">&quot;miantainer&quot;</span>: <span class="string">&quot;iqsing.github.io&quot;</span>,</span><br><span class="line">    <span class="attr">&quot;org.label-schema.build-date&quot;</span>: <span class="string">&quot;20201204&quot;</span>,</span><br><span class="line">    <span class="attr">&quot;org.label-schema.license&quot;</span>: <span class="string">&quot;GPLv2&quot;</span>,</span><br><span class="line">    <span class="attr">&quot;org.label-schema.name&quot;</span>: <span class="string">&quot;CentOS Base Image&quot;</span>,</span><br><span class="line">    <span class="attr">&quot;org.label-schema.schema-version&quot;</span>: <span class="string">&quot;1.0&quot;</span>,</span><br><span class="line">    <span class="attr">&quot;org.label-schema.vendor&quot;</span>: <span class="string">&quot;CentOS&quot;</span>,</span><br><span class="line">    <span class="attr">&quot;version&quot;</span>: <span class="string">&quot;v1.2&quot;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h5 id="5-EXPOSE"><a href="#5-EXPOSE" class="headerlink" title="5.EXPOSE"></a>5.EXPOSE</h5><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">EXPOSE</span> <span class="number">80</span>/tcp</span><br><span class="line"><span class="keyword">EXPOSE</span> <span class="number">161</span>/udp</span><br></pre></td></tr></table></figure><p>注意，EXPOSE只是告诉dockerfile的阅读者，我们构建的镜像需要暴露哪些端口，只是一个信息。在容器中还是需要通过<code>-p</code>选项来暴露端口。</p><h5 id="6-ENV"><a href="#6-ENV" class="headerlink" title="6.ENV"></a>6.ENV</h5><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">ENV</span> &lt;key&gt;=&lt;value&gt; ... 首先方式</span><br><span class="line">或</span><br><span class="line"><span class="keyword">ENV</span> &lt;key&gt;  &lt;value&gt;</span><br></pre></td></tr></table></figure><p>通过ENV指定环境变量，将作用于在构建阶段的所有后续指令的环境中。</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">ENV</span> username=<span class="string">&quot;iqsing&quot;</span></span><br></pre></td></tr></table></figure><p>这样当我们启动这个容器后可以查看到容器信息已经附带了<code>ENV</code>环境变量</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&quot;Env&quot;: [</span><br><span class="line">&quot;PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin&quot;,</span><br><span class="line">&quot;username=iqsing&quot;</span><br><span class="line">],</span><br></pre></td></tr></table></figure><p>当然我们也可以在启动容器时添加环境变量</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run --env &lt;key&gt;=&lt;value&gt;</span><br></pre></td></tr></table></figure><p>另外如果只需要在镜像构建期间使用环境变量，更好的选择是使用<code>ARG</code>参数来处理</p><h5 id="7-ADD-amp-amp-COPY"><a href="#7-ADD-amp-amp-COPY" class="headerlink" title="7.ADD &amp;&amp; COPY"></a>7.ADD &amp;&amp; COPY</h5><p>ADD和COPY格式相似，有两种形式,包含空格的路径需要后一种形式：</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">ADD</span><span class="bash"> [--chown=&lt;user&gt;:&lt;group&gt;] &lt;src&gt;... &lt;dest&gt;</span></span><br><span class="line"><span class="keyword">ADD</span><span class="bash"> [--chown=&lt;user&gt;:&lt;group&gt;] [<span class="string">&quot;&lt;src&gt;&quot;</span>,... <span class="string">&quot;&lt;dest&gt;&quot;</span>]</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">COPY</span><span class="bash"> [--chown=&lt;user&gt;:&lt;group&gt;] &lt;src&gt;... &lt;dest&gt;</span></span><br><span class="line"><span class="keyword">COPY</span><span class="bash"> [--chown=&lt;user&gt;:&lt;group&gt;] [<span class="string">&quot;&lt;src&gt;&quot;</span>,... <span class="string">&quot;&lt;dest&gt;&quot;</span>]</span></span><br></pre></td></tr></table></figure><p>在linux平台中可以对添加到远程目录或文件设置所属用户和组。</p><p><code>&lt;SRC&gt; </code>指复制新文件、目录或远程文件 URL，每<code>&lt;src&gt;</code>可以包含通配符，如下：</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">ADD</span><span class="bash"> hom* /mydir/</span></span><br><span class="line"><span class="keyword">ADD</span><span class="bash"> hom?.txt /mydir/</span></span><br></pre></td></tr></table></figure><p>一般使用中，ADD、COPY都遵守以下规则：</p><ul><li><p><code>&lt;src&gt;</code>路径必须是内部<em>语境</em>的构建; 你不能<code>COPY ../something /something</code>，因为 <code>docker build</code>是将上下文目录（和子目录）发送到 docker 守护进程。</p></li><li><p>如果<code>&lt;src&gt;</code>是目录，则复制目录的全部内容，包括文件系统元数据。</p></li><li><p>如果<code>&lt;src&gt;</code>是任何其他类型的文件，则将其与其元数据一起单独复制。在这种情况下，如果<code>&lt;dest&gt;</code>以斜杠结尾<code>/</code>，它将被视为一个目录，其内容<code>&lt;src&gt;</code>将被写入<code>&lt;dest&gt;/base(&lt;src&gt;)</code>。</p></li><li><p>如果<code>&lt;src&gt;</code>直接指定了多个资源，或者由于使用了通配符，则<code>&lt;dest&gt;</code>必须是目录，并且必须以斜杠结尾<code>/</code>。</p></li><li><p>如果<code>&lt;dest&gt;</code>不以斜杠结尾，则将其视为常规文件，并将其内容<code>&lt;src&gt;</code>写入<code>&lt;dest&gt;</code>.</p></li><li><p>如果<code>&lt;dest&gt;</code>不存在，则在其路径中创建所有丢失的目录。</p></li></ul><p><strong>特别的，当<src>是可识别的压缩包如gzip、bzip2等tar包时，首先会将包添加到镜像中，然后自动解压。这可以说是与COPY命令在使用中的最大的区别。</strong></p><h5 id="8-ENTRYPOINT"><a href="#8-ENTRYPOINT" class="headerlink" title="8.ENTRYPOINT"></a>8.ENTRYPOINT</h5><p>exec首选和shell形式:</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">ENTRYPOINT</span><span class="bash"> [<span class="string">&quot;executable&quot;</span>, <span class="string">&quot;param1&quot;</span>, <span class="string">&quot;param2&quot;</span>]</span></span><br><span class="line"><span class="keyword">ENTRYPOINT</span><span class="bash"> <span class="built_in">command</span> param1 param2</span></span><br></pre></td></tr></table></figure><p><strong>ENTRYPOINT 和CMD很相似，都是指定启动命令，不同之处在于ENTRYPOINT 指定的命令无法被docker run 参数取代。</strong></p><p>我们在dockerfile中添加ENTRYPOINT</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">ENTRYPOINT</span><span class="bash"> <span class="built_in">echo</span> hello container</span></span><br></pre></td></tr></table></figure><p>构建镜像并启动容器，可以看到docker run 中的参数并未取代ENTRYPOINT</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost dockerfiles]<span class="comment"># docker run centos_entrtpoint:v1 echo hello docker</span></span><br><span class="line">hello container</span><br></pre></td></tr></table></figure><p><strong>这指令优秀的另一个地方在于可以和CMD指令做交互。让容器以应用或者服务运行。</strong></p><p>经典操作：<code>ENTRYPOINT</code> + <code>CMD</code> = 默认容器命令参数</p><p>ENTRYPOINT是dockerfile中非常重要的指令，有必要另写一篇小作文深入学习一下这东西。</p><h5 id="9-VOLUME"><a href="#9-VOLUME" class="headerlink" title="9.VOLUME"></a>9.VOLUME</h5><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">VOLUME</span><span class="bash"> [<span class="string">&quot;/data&quot;</span>]</span></span><br></pre></td></tr></table></figure><p>volume指令可以用于创建存储卷，我来看一下实例：</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">FROM</span> centos</span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> mkdir /volume</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> <span class="built_in">echo</span> <span class="string">&quot;hello world&quot;</span> &gt; /volume/greeting</span></span><br><span class="line"><span class="keyword">VOLUME</span><span class="bash"> /volume</span></span><br></pre></td></tr></table></figure><p>构建镜像后，创建一个容器</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost dockerfiles]# docker create   --name centos_volume  centos_volue:v1</span><br><span class="line">[root@localhost dockerfiles]# docker inspect centos_volume </span><br><span class="line"></span><br><span class="line"> <span class="string">&quot;Mounts&quot;</span>: [</span><br><span class="line">            &#123;</span><br><span class="line">                <span class="attr">&quot;Type&quot;</span>: <span class="string">&quot;volume&quot;</span>,</span><br><span class="line">                <span class="attr">&quot;Name&quot;</span>: <span class="string">&quot;494cdb193984680045c36a16bbc2b759cf568b55c7e9b0852ccf6dff8bf79c46&quot;</span>,</span><br><span class="line">                <span class="attr">&quot;Source&quot;</span>: <span class="string">&quot;/var/lib/docker/volumes/494cdb193984680045c36a16bbc2b759cf568b55c7e9b0852ccf6dff8bf79c46/_data&quot;</span>,</span><br><span class="line">                <span class="attr">&quot;Destination&quot;</span>: <span class="string">&quot;/volume&quot;</span>,</span><br><span class="line">                <span class="attr">&quot;Driver&quot;</span>: <span class="string">&quot;local&quot;</span>,</span><br><span class="line">                <span class="attr">&quot;Mode&quot;</span>: <span class="string">&quot;&quot;</span>,</span><br><span class="line">                <span class="attr">&quot;RW&quot;</span>: <span class="literal">true</span>,</span><br><span class="line">                <span class="attr">&quot;Propagation&quot;</span>: <span class="string">&quot;&quot;</span></span><br><span class="line">            &#125;</span><br><span class="line">        ],</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>这样我们就通过VOLUME指令创建一个存储卷，你可以通过<code>--volumes-from</code>共享这个容器，可参考我之前的小作文《docker容器存储》</p><h5 id="10-USER"><a href="#10-USER" class="headerlink" title="10.USER"></a>10.USER</h5><p>指定指令集所属用户和组。组默认为root。可以作用于<code>RUN</code>，<code>CMD</code>和 <code>ENTRYPOINT</code>它们后面的指令。</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">USER</span> &lt;<span class="keyword">user</span>&gt;[:&lt;group&gt;]</span><br><span class="line">或</span><br><span class="line"><span class="keyword">USER</span> &lt;UID&gt;[:&lt;GID&gt;]</span><br></pre></td></tr></table></figure><h5 id="11-WORKDIR"><a href="#11-WORKDIR" class="headerlink" title="11.WORKDIR"></a>11.WORKDIR</h5><p>指定指令集所在的工作目录，若目录不存在将会自动创建。可作用于<code>RUN</code>，<code>CMD</code>， <code>ENTRYPOINT</code>，<code>COPY</code>和<code>ADD</code></p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">WORKDIR</span><span class="bash"> /path/to/workdir</span></span><br></pre></td></tr></table></figure><h5 id="12-ARG"><a href="#12-ARG" class="headerlink" title="12.ARG"></a>12.ARG</h5><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">ARG</span> &lt;name&gt;[=&lt;default value&gt;]</span><br></pre></td></tr></table></figure><p><code>ARG</code>指令定义了一个变量，我们可以在<code>docker build</code>通过使用<code>--build-arg &lt;varname&gt;=&lt;value&gt;</code> 标志的命令将其传递给构建器。</p><ul><li><p>如果<code>ARG</code>指令具有默认值并且在构建时没有传递任何值，则构建器使用默认值。</p></li><li><p>在多阶段构建应该添加多个ARG</p></li><li><p>ENV变量会覆盖ARG变量</p></li><li><p>与ENV变量相比，ARG变量多用于构建，无法驻留在镜像中。</p></li></ul><h5 id="13-STOPSIGNAL"><a href="#13-STOPSIGNAL" class="headerlink" title="13.STOPSIGNAL"></a>13.STOPSIGNAL</h5><p>配置容器退出时的系统调用</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">STOPSIGNAL</span> signal</span><br></pre></td></tr></table></figure><h5 id="14-HEALTHCHECK"><a href="#14-HEALTHCHECK" class="headerlink" title="14.HEALTHCHECK"></a>14.HEALTHCHECK</h5><p><code>HEALTHCHECK</code>指令有两种形式：</p><ul><li><code>HEALTHCHECK [OPTIONS] CMD command</code> （通过在容器内运行命令来检查容器健康状况）</li><li><code>HEALTHCHECK NONE</code> （禁用从基础镜像继承的任何健康检查）</li></ul><p>OPTIONS支持如下参数：</p><ul><li><code>--interval=DURATION</code>（默认值：<code>30s</code>）</li><li><code>--timeout=DURATION</code>（默认值：<code>30s</code>）</li><li><code>--start-period=DURATION</code>（默认值：<code>0s</code>）</li><li><code>--retries=N</code>（默认值：<code>3</code>）</li></ul><p>比如我们可以添加如下参数用于检查web服务：</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">HEALTHCHECK</span><span class="bash"> --interval=5m --timeout=3s \</span></span><br><span class="line"><span class="bash">  CMD curl -f http://localhost/ || <span class="built_in">exit</span> 1</span></span><br></pre></td></tr></table></figure><p>每五分钟左右检查一次web服务器能否在3s内响应。如果失败则返回状态码1</p><p>命令的退出状态指示容器的健康状态。可能的值为：</p><ul><li>0：成功 - 容器运行良好，可以使用</li><li>1：不健康 - 容器无法正常工作</li><li>2：reserved - 不要使用这个退出代码</li></ul><hr><p>编写一个优质的Dockerfile并不容易，你需要考虑所构建镜像的迭代、服务稳定运行、启动与停止、安全等等问题，希望这篇小作文可以帮助你对Dockerfile有多一点了解。</p><p><strong>您可以随意转载、修改、发布本文章，无需经过本人同意。</strong> 个人blog：<a href="https://iqsing.github.io/">iqsing.github.io</a></p><hr><h4 id="NEXT"><a href="#NEXT" class="headerlink" title="NEXT"></a>NEXT</h4><ul><li>Dockerfile 理解ENTRYPOINT与CMD结合</li><li>Dockerfile 多阶段构建实践</li><li>Dockerfile 与docker容器安全实践</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;docker公司在容器技术发展中提出了&lt;strong&gt;镜像分层&lt;/strong&gt;的理念，可以说也是这个革命性的理念让原本只不过是整合linux内核特性的容器，开始野蛮生长。&lt;/p&gt;
&lt;p&gt;docker通过UnionFS联合文件系统将镜像的分层实现合并,关于镜像相关知识有兴趣</summary>
      
    
    
    
    <category term="docker" scheme="https://iqsing.github.io/categories/docker/"/>
    
    
    <category term="dockerfile" scheme="https://iqsing.github.io/tags/dockerfile/"/>
    
  </entry>
  
  <entry>
    <title>docker容器存储</title>
    <link href="https://iqsing.github.io/2021/08/12/docker%E5%AE%B9%E5%99%A8%E5%AD%98%E5%82%A8/"/>
    <id>https://iqsing.github.io/2021/08/12/docker%E5%AE%B9%E5%99%A8%E5%AD%98%E5%82%A8/</id>
    <published>2021-08-12T04:47:21.000Z</published>
    <updated>2022-02-04T05:16:11.773Z</updated>
    
    <content type="html"><![CDATA[<h4 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h4><p>我们在上篇学习了容器网络，对容器网络驱动bridge工作原理做了较为详细的介绍，今天小作文一起看看容器中另一个关键域-存储。</p><hr><p>容器的存储可以分为两大类：</p><p>一种是与镜像相关的即我们在《docker容器技术基础之联合文件系统OverlayFS》一文提到的容器层<code>Copy-On-Write</code>特性。默认情况下，在容器内创建的所有文件都存储在可写容器层上，这种直接将文件存储在容器层的方式数据难以持久化和共享，由于依赖存储驱动与使用直接写入主机文件系统的<em>数据卷</em>相比，这种额外的抽象会降低性能 。</p><p>另一中是宿主机存储即通过将宿主机目录绑定或挂在到容器中使用，容器停止后数据也能持久化。小作文主要介绍后者。</p><hr><h4 id="几种存储挂载方式"><a href="#几种存储挂载方式" class="headerlink" title="几种存储挂载方式"></a>几种存储挂载方式</h4><p>这里我们根据数据存储在 Docker 主机上的不同位置绘制如下图：</p><p><img src="https://markdown-1257692304.cos.ap-nanjing.myqcloud.com/markdown_img/image-20210812145828327.png" alt="image-20210812145828327"></p><h5 id="1-bind-mounts"><a href="#1-bind-mounts" class="headerlink" title="1.bind mounts"></a>1.bind mounts</h5><p>绑定挂载与卷相比，功能有限。使用绑定挂载时，<em>主机</em>上的文件或目录会挂载到容器中。文件或目录由其在主机上的完整路径引用。<strong>目录不需要已经存在于 Docker 主机上，如果不存在，docker会帮我们创建。</strong>注意一下，只能自动创建目录哦。</p><p>我们通过 -v 选项绑定挂载一个目录 /nginx/html 到容器中看看</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -dt -v /nginx/html:/usr/share/nginx/html --name nginx nginx</span><br></pre></td></tr></table></figure><p>通过docker inspect nginx 查看容器 Mounts字段</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;Mounts&quot;</span>: [</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="attr">&quot;Type&quot;</span>: <span class="string">&quot;bind&quot;</span>,</span><br><span class="line">        <span class="attr">&quot;Source&quot;</span>: <span class="string">&quot;/nginx/html&quot;</span>,</span><br><span class="line">        <span class="attr">&quot;Destination&quot;</span>: <span class="string">&quot;/usr/share/nginx/html&quot;</span>,</span><br><span class="line">        <span class="attr">&quot;Mode&quot;</span>: <span class="string">&quot;&quot;</span>,</span><br><span class="line">        <span class="attr">&quot;RW&quot;</span>: <span class="literal">true</span>,</span><br><span class="line">        <span class="attr">&quot;Propagation&quot;</span>: <span class="string">&quot;rprivate&quot;</span></span><br><span class="line">    &#125;</span><br><span class="line">],</span><br></pre></td></tr></table></figure><p>接着我们在docker主机上创建一个index.html并写入hello nginx，然后访问容器IP，显然我们的挂载已经生效了。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]<span class="comment"># echo &quot;hello nginx&quot; &gt;  /nginx/html/index.html</span></span><br><span class="line">[root@localhost ~]<span class="comment"># curl 172.17.0.4</span></span><br><span class="line">hello nginx</span><br></pre></td></tr></table></figure><p>这里有一个问题，我们可以通过docker主机修改文件使容器内文件生效，反过来也一样，容器可以修改、创建和删除主机文件系统上的内容。处理这个问题我们可以在创建容器的时候配置挂载目录的权限，比如下面的只读权限：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -dt -v /nginx/html:/usr/share/nginx/html:ro --name nginx nginx</span><br></pre></td></tr></table></figure><p>所以在我们使用绑定挂载的时候，你操作的是主机文件系统，你必须清楚如下：</p><ul><li>你挂载的目录包含哪些内容，以免对其他应用造成影响。</li><li>你的容器是否应该有权操作这些目录。</li></ul><hr><h5 id="2-volumes"><a href="#2-volumes" class="headerlink" title="2.volumes"></a>2.volumes</h5><p>volume存储卷由 Docker 创建和管理，我们可以使用该<code>docker volume create</code>命令显式的创建卷，或者在容器创建时创建卷。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]<span class="comment"># docker volume create nginx_volume</span></span><br><span class="line">nginx_volume</span><br><span class="line">[root@localhost volumes]<span class="comment"># docker inspect  nginx_volume</span></span><br><span class="line">[</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="string">&quot;CreatedAt&quot;</span>: <span class="string">&quot;2021-08-12T01:58:04-04:00&quot;</span>,</span><br><span class="line">        <span class="string">&quot;Driver&quot;</span>: <span class="string">&quot;local&quot;</span>,</span><br><span class="line">        <span class="string">&quot;Labels&quot;</span>: &#123;&#125;,</span><br><span class="line">        <span class="string">&quot;Mountpoint&quot;</span>: <span class="string">&quot;/var/lib/docker/volumes/nginx_volume/_data&quot;</span>,</span><br><span class="line">        <span class="string">&quot;Name&quot;</span>: <span class="string">&quot;nginx_volume&quot;</span>,</span><br><span class="line">        <span class="string">&quot;Options&quot;</span>: &#123;&#125;,</span><br><span class="line">        <span class="string">&quot;Scope&quot;</span>: <span class="string">&quot;local&quot;</span></span><br><span class="line">    &#125;</span><br><span class="line">]</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>可以看到挂载点处于docker的根目录/var/lib/docker/volumes下</p><p>通过<code>docker volume rm/prune</code> 清除单个或所有未再使用的卷，可以通过docker 命令来管理卷是对比绑定挂载的一个优势。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]<span class="comment"># docker volume ls</span></span><br><span class="line">DRIVER    VOLUME NAME</span><br><span class="line"><span class="built_in">local</span>     owncloud-docker-server_files</span><br><span class="line"><span class="built_in">local</span>     owncloud-docker-server_mysql</span><br><span class="line"><span class="built_in">local</span>     owncloud-docker-server_redis</span><br><span class="line">[root@localhost ~]<span class="comment"># docker volume prune</span></span><br><span class="line">WARNING! This will remove all <span class="built_in">local</span> volumes not used by at least one container.</span><br><span class="line">Are you sure you want to <span class="built_in">continue</span>? [y/N] y</span><br><span class="line">Deleted Volumes:</span><br><span class="line">owncloud-docker-server_files</span><br><span class="line">owncloud-docker-server_mysql</span><br><span class="line">owncloud-docker-server_redis</span><br><span class="line"></span><br><span class="line">Total reclaimed space: 199.4MB</span><br></pre></td></tr></table></figure><p>在创建容器时如果未指定容器挂载的源则docker会自动为我们创建一个匿名卷，同样位于docker根目录下。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost volumes]<span class="comment"># docker run -dt -v /usr/share/nginx/html --name nginx_with_volume nginx</span></span><br><span class="line">d25bdfce9c7ac7bde5ae35067f6d9cf9f0cd2c9cbea6d1bbd7127b3949ef5ac6</span><br><span class="line">[root@localhost volumes]<span class="comment"># docker volume ls </span></span><br><span class="line">DRIVER    VOLUME NAME</span><br><span class="line"><span class="built_in">local</span>     d8e943f57d17a255f8a4ac3ecbd6471a735aa64cc7a606c52f61319a6c754980</span><br><span class="line"><span class="built_in">local</span>     nginx_volume</span><br><span class="line">[root@localhost volumes]<span class="comment"># ls /var/lib/docker/volumes/</span></span><br><span class="line">backingFsBlockDev  d8e943f57d17a255f8a4ac3ecbd6471a735aa64cc7a606c52f61319a6c754980  metadata.db  nginx_volume</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>当我们创建挂载卷之后，此时的存储与bind mounts是一致，不过当 docker 主机不能保证具有给定的目录或文件结构时，卷可帮助我们将 docker 主机的配置与容器运行时分离。这样一来当我们需要将数据从一台 Docker 主机备份、还原或迁移到另一台时，卷就很方便了，可以脱离host path的限制。</p><p><strong>在使用绑定挂载和卷时我们要注意下面传播覆盖原则：</strong></p><p><img src="https://markdown-1257692304.cos.ap-nanjing.myqcloud.com/markdown_img/image-20210812144256025.png" alt="image-20210812144256025"></p><p>挂载一个空卷时：容器内目录的内容会传播（复制）到卷中。</p><p>绑定挂载或非空卷时：容器内目录的内容会被卷或绑定的主机目录覆盖。</p><hr><h5 id="3-tmpfs-mount"><a href="#3-tmpfs-mount" class="headerlink" title="3.tmpfs mount"></a>3.tmpfs mount</h5><p><code>tmpfs</code>挂载仅适用于linux主机，当我们使用<code>tmpfs</code>挂载创建容器时，容器可以在容器的可写层之外创建文件。将数据保留在内存中，当容器停止时，写入的数据也将被移除。主要用于临时存储不想保留在主机或容器可写层中的敏感文件。</p><p>通过<code>--tmpfs</code>选项挂载一个内存块。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -dt --name busybox_tmpfs --tmpfs /etc/running busybox</span><br></pre></td></tr></table></figure><p>通过<code>--mount</code>的方式带上参数,指定临时存储大小。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -dt --name busybox_tmpfs2 --mount <span class="built_in">type</span>=tmpfs,tmpfs-size=2048,destination=/etc/running busybox</span><br></pre></td></tr></table></figure><hr><h4 id="存储数据共享"><a href="#存储数据共享" class="headerlink" title="存储数据共享"></a>存储数据共享</h4><p>在容器之间共享数据主要有两种方法，第一种比较简单，只需要将目录或者volume挂载到多个容器中即可。这里不做赘述，我们来看一下通过<code>中间容器</code>实现共享的方式。</p><p>我们创建一个中间容器,包含绑定挂载目录和一个卷。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker create -v /share:/volume1 -v /volume2  --name volume_share  busybox</span><br></pre></td></tr></table></figure><p>在我们需要共享的容器中通过选项<code>--volumes-from</code>拿过来用即可</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -d -t --volumes-from volume_share  --name container1  busybox</span><br></pre></td></tr></table></figure><p>我们inspect检查一下Mounts字段，此时container1已经挂载到了一个<code>bind</code>目录和一个<code>volume</code></p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;Mounts&quot;</span>: [</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="attr">&quot;Type&quot;</span>: <span class="string">&quot;bind&quot;</span>,</span><br><span class="line">        <span class="attr">&quot;Source&quot;</span>: <span class="string">&quot;/share&quot;</span>,</span><br><span class="line">        <span class="attr">&quot;Destination&quot;</span>: <span class="string">&quot;/volume1&quot;</span>,</span><br><span class="line">        <span class="attr">&quot;Mode&quot;</span>: <span class="string">&quot;&quot;</span>,</span><br><span class="line">        <span class="attr">&quot;RW&quot;</span>: <span class="literal">true</span>,</span><br><span class="line">        <span class="attr">&quot;Propagation&quot;</span>: <span class="string">&quot;rprivate&quot;</span></span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="attr">&quot;Type&quot;</span>: <span class="string">&quot;volume&quot;</span>,</span><br><span class="line">        <span class="attr">&quot;Name&quot;</span>: <span class="string">&quot;21605e49a0ba90a1b952a32c1b3f0d42735da8bfe718f0dc76c37e91f1e51c0e&quot;</span>,</span><br><span class="line">        <span class="attr">&quot;Source&quot;</span>: <span class="string">&quot;/var/lib/docker/volumes/21605e49a0ba90a1b952a32c1b3f0d42735da8bfe718f0dc76c37e91f1e51c0e/_data&quot;</span>,</span><br><span class="line">        <span class="attr">&quot;Destination&quot;</span>: <span class="string">&quot;/volume2&quot;</span>,</span><br><span class="line">        <span class="attr">&quot;Driver&quot;</span>: <span class="string">&quot;local&quot;</span>,</span><br><span class="line">        <span class="attr">&quot;Mode&quot;</span>: <span class="string">&quot;&quot;</span>,</span><br><span class="line">        <span class="attr">&quot;RW&quot;</span>: <span class="literal">true</span>,</span><br><span class="line">        <span class="attr">&quot;Propagation&quot;</span>: <span class="string">&quot;&quot;</span></span><br><span class="line">    &#125;</span><br><span class="line">],</span><br><span class="line"></span><br></pre></td></tr></table></figure><hr><p>关于docker容器存储我们先学习到这，希望这篇小作文在你需要时对你有点用。</p><p>blog：<a href="https://iqsing.github.io/">iqsing.github.io</a></p><p><strong>您可以随意转载、修改、发布本文章，无需经过本人同意。</strong></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h4 id=&quot;写在前面&quot;&gt;&lt;a href=&quot;#写在前面&quot; class=&quot;headerlink&quot; title=&quot;写在前面&quot;&gt;&lt;/a&gt;写在前面&lt;/h4&gt;&lt;p&gt;我们在上篇学习了容器网络，对容器网络驱动bridge工作原理做了较为详细的介绍，今天小作文一起看看容器中另一个关键域-存储。</summary>
      
    
    
    
    <category term="docker" scheme="https://iqsing.github.io/categories/docker/"/>
    
    
    <category term="storage" scheme="https://iqsing.github.io/tags/storage/"/>
    
  </entry>
  
</feed>
